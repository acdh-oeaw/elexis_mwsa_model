{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f9d5789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 11 12:15:19 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   46C    P0    59W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   72C    P8    76W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   46C    P0    62W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   69C    P0    76W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla K80           Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   43C    P0    55W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla K80           Off  | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   66C    P0    74W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla K80           Off  | 00000000:00:0A.0 Off |                    0 |\n",
      "| N/A   45C    P0    65W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla K80           Off  | 00000000:00:0B.0 Off |                    0 |\n",
      "| N/A   66C    P0    91W / 149W |      0MiB / 11441MiB |     93%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "ln: failed to create symbolic link '/usr/bin/nvidia-smi': Permission denied\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: gputil in /opt/conda/lib/python3.7/site-packages (1.4.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (5.8.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: humanize in /opt/conda/lib/python3.7/site-packages (3.5.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from humanize) (49.6.0.post20210108)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Gen RAM Free: 14.6 GB  I Proc size: 184.6 MB\n",
      "GPU RAM Free: 11438MB | Used: 3MB | Util   0% | Total 11441MB\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize    \n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn't guaranteed\n",
    "gpu = GPUs[0]\n",
    "#gpu2 = GPUs[1]\n",
    "\n",
    "def printm():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "#  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu2.memoryFree, gpu2.memoryUsed, gpu2.memoryUtil*100, gpu2.memoryTotal))\n",
    "    \n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ec48e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.5.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.49.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Installing collected packages: filelock\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Successfully installed filelock-3.0.12\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.6.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.49.0)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.0.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.0.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install datasets\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "if int(pyarrow.__version__.split('.')[1]) < 16 and int(pyarrow.__version__.split('.')[0]) == 0:\n",
    "    import os\n",
    "\n",
    "    \n",
    "    os.kill(os.getpid(), 9)\n",
    "from datasets import load_dataset, Dataset\n",
    "from datasets import ClassLabel, Features, Value\n",
    "# Tensorflow classification with imbalanced data https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights\n",
    "# How to choose loss function https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "#https://colab.research.google.com/drive/1kEg0SnYNtw_IJwu_kl5y3qRVs-BKBmNO#scrollTo=W64yQeCyl8sC\n",
    "#https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb\n",
    "#https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb\n",
    "#https://huggingface.co/transformers/master/custom_datasets.html\n",
    "#https://huggingface.co/transformers/custom_datasets.html#sequence-classification-with-imdb-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b0d149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=256\n",
    "model_name='dbmdz/bert-base-german-cased'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e683f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(file_path):\n",
    "    loaded_data = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "    return loaded_data\n",
    "\n",
    "\n",
    "def reverse_multihot(val):\n",
    "    encoding = {0:'none', 1:'exact', 2:'broader', 3:'narrower', 4:'related'}\n",
    "    return encoding[val]\n",
    "\n",
    "def split_data(data, testset_ratio):\n",
    "    train_df, remaining = train_test_split(data, random_state=42, train_size=0.75, stratify=data.labels.values)\n",
    "    return train_df, remaining\n",
    "    #data = data.sample(frac=1)\n",
    "    #f = int(len(data) * testset_ratio)\n",
    "    #return data[f:], data[:f]\n",
    "\n",
    "def multihot(val):\n",
    "    encoding = {'none':0, 'exact':1, 'broader':2, 'narrower':3, 'related':4}\n",
    "    return encoding[val]\n",
    "\n",
    "\n",
    "def encode(data):\n",
    "  return tokenizer(data['text_a'], data['text_b'], truncation=True, max_length=max_length, padding='max_length')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74099025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = 'german.tsv'\n",
    "en_data = load_data(folder)\n",
    "en_data = en_data[[2,3,4]]\n",
    "en_data.columns =  ['text_a','text_b','labels']\n",
    "en_data['labels'].value_counts()\n",
    "#en_data['labels'] = en_data['labels'].map(lambda val: multihot(val))\n",
    "\n",
    "test_file = 'german_reference.tsv'\n",
    "test_data_orig = load_data(test_file)\n",
    "test_data = test_data_orig[[2,3,4]]\n",
    "test_data.columns = ['text_a', 'text_b', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "903c6dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      4\n",
       "2      4\n",
       "3      4\n",
       "4      0\n",
       "      ..\n",
       "564    4\n",
       "565    0\n",
       "566    4\n",
       "567    2\n",
       "568    4\n",
       "Name: labels, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = ['broader','narrower','exact','related','none']\n",
    "en_data['labels'].apply(label_list.index)\n",
    "test_data['labels'].apply(label_list.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc087f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Helligkeit', 'verheiratete Frau, Ehefrau',\n",
       "       'die höchste Augenzahl auf einem Würfel', ...,\n",
       "       'Maschine zum strecken|Strecken von Kardenband|Kardenbändern in der Textilindustrie',\n",
       "       'Laut der Sprache, bei dem der Luftstrom relativ ungehindert durch den offenen Mund oder die Nase austritt und die Stimmbänder schwingen',\n",
       "       'Aufstellung militärischer Einheiten'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, valset = split_data(en_data, 0.2)\n",
    "trainset.shape, valset.shape\n",
    "trainset.text_a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b2267a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34a5abf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'broader', 1: 'exact', 2: 'narrower', 3: 'none', 4: 'related'}\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(en_data['labels'].to_list())\n",
    "\n",
    "labels = le.classes_\n",
    "labelMap = {v: k for v, k in enumerate(labels)}\n",
    "    \n",
    "print(labelMap)\n",
    "\n",
    "def onehot_encode(data, encoder):\n",
    "\n",
    "  integer_encoded = encoder.transform(data['labels'].to_list())\n",
    "  onehot_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "  \n",
    "  return onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b471b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded_train = onehot_encode(trainset, le)\n",
    "onehot_encoded_val = onehot_encode(valset, le)\n",
    "onehot_encoded_test = onehot_encode(test_data, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "078f169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['none'], dtype='<U8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = le.inverse_transform([numpy.argmax(onehot_encoded_val[2, :])])\n",
    "val_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "447c7d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0 1 2 3 4], y=[3 1 3 ... 3 3 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "y_integers = np.argmax(onehot_encoded_train, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "sample_weights = compute_sample_weight('balanced', onehot_encoded_train)\n",
    "sample_weights_val = compute_sample_weight('balanced', onehot_encoded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6f7fd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05361500022988054,\n",
       " 1.7272945791805907,\n",
       " 2.0803419016605824,\n",
       " 2.3993672862712545,\n",
       " 6.681576372868168}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "891d12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = trainset['text_a'].to_list()\n",
    "train_b = trainset['text_b'].to_list()\n",
    "train_labels = onehot_encoded_train\n",
    "\n",
    "val_a = valset['text_a'].to_list()\n",
    "val_b = valset['text_b'].to_list()\n",
    "val_labels = onehot_encoded_val\n",
    "\n",
    "test_a = test_data['text_a'].to_list()\n",
    "test_b = test_data['text_b'].to_list()\n",
    "test_labels = onehot_encoded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4f8602a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ae91a366784872b6c0e7a42307359f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=239836.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fa6c9ad1004378b18b8fe82f7fb42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=59.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c572b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_a, train_b, truncation=True, padding='longest',max_length=max_length, return_tensors='tf')\n",
    "val_encodings = tokenizer(val_a, val_b, truncation=True, padding='longest', max_length=max_length, return_tensors='tf')\n",
    "test_encodings = tokenizer(test_a, test_b, truncation=True,padding='longest', max_length=max_length,return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94b09323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "    #sample_weights\n",
    "))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "    #sample_weights_val\n",
    "))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    "))\n",
    "# Oversampling\n",
    "# https://github.com/tensorflow/tensorflow/issues/14451\n",
    "#https://keras.io/api/models/model_training_apis/  \n",
    "# https://stackoverflow.com/questions/53653485/training-with-tf-data-api-and-sample-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7156b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair {'input_ids': array([  102, 10373,  1015,   103,  4246,   818,  8213,  1322,  3392,\n",
      "         394, 11618,   186,   818,   556,  3903,  7893,   566,   103,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0], dtype=int32), 'token_type_ids': array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int32), 'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "      dtype=int32)} [0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "for pair, label in tfds.as_numpy(train_dataset.take(1)):\n",
    "    print('pair', pair, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd0cfe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.10.29)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.15)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.15.8)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.0 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n"
     ]
    }
   ],
   "source": [
    "train_labels[0]\n",
    "le.inverse_transform([0])\n",
    "!pip install wandb\n",
    "!wandb login 8d2052d6ffc37b0b4398c538a9604fe6b18e0cf9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0f1da7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: Keras==2.4.3 in /opt/conda/lib/python3.7/site-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from Keras==2.4.3) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from Keras==2.4.3) (1.6.3)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras==2.4.3) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras==2.4.3) (1.19.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras==2.4.3) (1.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: tensorflow-addons==0.8.3 in /opt/conda/lib/python3.7/site-packages (0.8.3)\n",
      "Requirement already satisfied: typeguard in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons==0.8.3) (2.12.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras==2.4.3\n",
    "!pip install tensorflow-addons==0.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5e1ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#https://www.tensorflow.org/guide/keras/custom_callback#an_overview_of_callback_methods\n",
    "class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(\"For batch {}, loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print(\"For batch {}, loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\n",
    "            \"The average loss for epoch {} is {:7.2f} \".format(\n",
    "                epoch, logs[\"loss\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "class LRLogger(keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LRLogger, self).__init__()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        wandb.log({'epoch': epoch, 'learning_rate': lr})\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        #scheduled_lr = self.schedule(epoch, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        #tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        #print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64ec1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import wandb\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "#from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import TFBertForSequenceClassification,AdamWeightDecay\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "seed=7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "#wandb.config.globalseed=seed\n",
    "#wandb.config.nr_gpus=len(GPU.getGPUs())\n",
    "#wandb.config.lr = 4e-5\n",
    "#wandb.config.weight_decay_rate=0.2\n",
    "#wandb.config.epoch=10\n",
    "#wandb.config.batch=32\n",
    "#wandb.config.max_length=max_length\n",
    "#wandb.config.lr_scheduler='ReduceLROnPlateau'\n",
    "#wandb.config.seed=seed\n",
    "#wandb.config.model=model_name\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d044fec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0)\n",
    "\n",
    "# Define multi-gpu strategy \n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "# Update batch size value\n",
    "#wandb.config.batch *= mirrored_strategy.num_replicas_in_sync\n",
    "# Create strategy scope to perform training\n",
    "\n",
    "# Transformer and Batchsize\n",
    "#https://dmitry.ai/t/topic/100/2\n",
    "\n",
    "\n",
    "class RemoveGarbaseCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af9ce371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_dict={}\n",
    "for i in range(len(class_weights)):\n",
    "    class_weights_dict[i]=class_weights[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f76b922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization_tf import WarmUp\n",
    "warmup_scheduler = WarmUp(1e-5, reduce_lr, warmup_steps=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a65bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    hyperparameter_defaults = dict(\n",
    "        nr_gpus=len(GPU.getGPUs()),\n",
    "        lr_scheduler=warmup_scheduler,\n",
    "        model=model_name,\n",
    "        globalseed=seed,\n",
    "        weight_decay_rate=0.3,\n",
    "        epoch=10,\n",
    "        batch=32,\n",
    "        max_length=max_length,\n",
    "        seed=seed\n",
    "    )\n",
    "    wandb.init(project=\"mwsa_transformers_de\", config=hyperparameter_defaults)\n",
    "    config = wandb.config\n",
    "\n",
    "        \n",
    "    with mirrored_strategy.scope():\n",
    "        #https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\n",
    "        #loss = {'issue': CategoricalCrossentropy(from_logits = False), 'product': CategoricalCrossentropy(from_logits = True)}\n",
    "        loss = CategoricalCrossentropy(from_logits=True)\n",
    "        metric = [CategoricalAccuracy(), F1Score(num_classes=5, average='weighted')]\n",
    "        # How to choose loss functions https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "        #https://stackoverflow.com/questions/59305514/tensorflow-how-to-use-tf-keras-metrics-in-multiclass-classification\n",
    "        #https://towardsdatascience.com/keras-accuracy-metrics-8572eb479ec7#:~:text=Categorical%20Accuracy%20calculates%20the%20percentage,yTrue%2C%20it%20is%20considered%20accurate.\n",
    "        #optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "        #optimizer = AdamWeightDecay(learning_rate=0.01, weight_decay_rate=0.1)#silvery-plasma-24\n",
    "        optimizer = AdamWeightDecay(learning_rate=1e-5, weight_decay_rate=wandb.config.weight_decay_rate)\n",
    "\n",
    "        model = TFBertForSequenceClassification.from_pretrained(model_name,num_labels=5, return_dict=True)\n",
    "        #model.summary()\n",
    "        model.config.gradient_checkpointing=True\n",
    "\n",
    "        #https://keras.io/api/models/model_training_apis/\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metric, weighted_metrics=metric) # can also use any keras loss fn\n",
    "        history = model.fit(train_dataset.shuffle(1000,seed=wandb.config.seed).batch(wandb.config.batch), \n",
    "              epochs=wandb.config.epoch,\n",
    "              validation_data=val_dataset.shuffle(1000,seed=wandb.config.seed).batch(wandb.config.batch), \n",
    "                            class_weight=class_weights_dict,\n",
    "                            callbacks=[WandbCallback(),reduce_lr,LRLogger(),RemoveGarbaseCallback()])\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "# Steps per epoch\n",
    "# https://datascience.stackexchange.com/questions/47405/what-to-set-in-steps-per-epoch-in-keras-fit-generator\n",
    "\n",
    "#https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "# Increasing Loss and accuracy\n",
    "#Overfitting\n",
    "#https://datascience.stackexchange.com/questions/76527/overfitting-in-huggingfaces-tfbertforsequenceclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30c998b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: jzr3r2yi\n",
      "Sweep URL: https://wandb.ai/sbyim/uncategorized/sweeps/jzr3r2yi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2iahho3o) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2475<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jupyter/wandb/run-20210511_123536-2iahho3o/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jupyter/wandb/run-20210511_123536-2iahho3o/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">glowing-snow-1</strong>: <a href=\"https://wandb.ai/sbyim/mwsa_transformers_de/runs/2iahho3o\" target=\"_blank\">https://wandb.ai/sbyim/mwsa_transformers_de/runs/2iahho3o</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2iahho3o). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.29<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">effortless-rain-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sbyim/mwsa_transformers_de\" target=\"_blank\">https://wandb.ai/sbyim/mwsa_transformers_de</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sbyim/mwsa_transformers_de/runs/29bzc7q1\" target=\"_blank\">https://wandb.ai/sbyim/mwsa_transformers_de/runs/29bzc7q1</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/wandb/run-20210511_123816-29bzc7q1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019d7ec870ad452fa85127f34c98c1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a5b2a939794a7081ba47a64b994d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=539615304.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f33c45dfc20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f33c45dfc20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:batch_all_reduce: 198 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7').\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:batch_all_reduce: 198 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7').\n",
      "104/104 [==============================] - ETA: 0s - loss: 1.6295 - weighted_categorical_accuracy: 0.2604 - weighted_f1_score: 0.3516WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "104/104 [==============================] - 317s 1s/step - loss: 1.6287 - weighted_categorical_accuracy: 0.2614 - weighted_f1_score: 0.3533 - val_loss: 1.0825 - val_weighted_categorical_accuracy: 0.6700 - val_weighted_f1_score: 0.7067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "104/104 [==============================] - 81s 776ms/step - loss: 1.3357 - weighted_categorical_accuracy: 0.5475 - weighted_f1_score: 0.6904 - val_loss: 0.8598 - val_weighted_categorical_accuracy: 0.6954 - val_weighted_f1_score: 0.7232\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 80s 769ms/step - loss: 1.2024 - weighted_categorical_accuracy: 0.6099 - weighted_f1_score: 0.7286 - val_loss: 0.9046 - val_weighted_categorical_accuracy: 0.6881 - val_weighted_f1_score: 0.7322\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 81s 775ms/step - loss: 0.9780 - weighted_categorical_accuracy: 0.7042 - weighted_f1_score: 0.7773 - val_loss: 0.7899 - val_weighted_categorical_accuracy: 0.7180 - val_weighted_f1_score: 0.7471\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 81s 775ms/step - loss: 0.7885 - weighted_categorical_accuracy: 0.7651 - weighted_f1_score: 0.8178 - val_loss: 0.8782 - val_weighted_categorical_accuracy: 0.6963 - val_weighted_f1_score: 0.7403\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 80s 772ms/step - loss: 0.6175 - weighted_categorical_accuracy: 0.8164 - weighted_f1_score: 0.8370 - val_loss: 0.9000 - val_weighted_categorical_accuracy: 0.7135 - val_weighted_f1_score: 0.7503\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 79s 763ms/step - loss: 0.4674 - weighted_categorical_accuracy: 0.8708 - weighted_f1_score: 0.8740 - val_loss: 0.8444 - val_weighted_categorical_accuracy: 0.7316 - val_weighted_f1_score: 0.7570\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 79s 759ms/step - loss: 0.3189 - weighted_categorical_accuracy: 0.9111 - weighted_f1_score: 0.9046 - val_loss: 0.8476 - val_weighted_categorical_accuracy: 0.7325 - val_weighted_f1_score: 0.7574\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 79s 761ms/step - loss: 0.2771 - weighted_categorical_accuracy: 0.9171 - weighted_f1_score: 0.9036 - val_loss: 0.8597 - val_weighted_categorical_accuracy: 0.7271 - val_weighted_f1_score: 0.7564\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 79s 762ms/step - loss: 0.2720 - weighted_categorical_accuracy: 0.9197 - weighted_f1_score: 0.9096 - val_loss: 0.8384 - val_weighted_categorical_accuracy: 0.7416 - val_weighted_f1_score: 0.7631\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"MWSA Sweep\",\n",
    "  \"method\": \"grid\",\n",
    "  \"parameters\": {\n",
    "        \"lr\": {\n",
    "            \"values\": [5e-5,5e-4,5e-6]\n",
    "        },\n",
    "        \"weight_decay_rate\":{\n",
    "            \"values\": [0.1,0.2,0.3]\n",
    "        },\n",
    "        \"batch\": {\n",
    "            \"values\": [32]\n",
    "        }\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)\n",
    "\n",
    "model = train()\n",
    "#wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ebc0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label=labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "239ee35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109927680 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  3845      \n",
      "=================================================================\n",
      "Total params: 109,931,525\n",
      "Trainable params: 109,931,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "18/18 [==============================] - 33s 153ms/step - loss: 0.8686 - weighted_categorical_accuracy: 0.7241 - weighted_f1_score: 0.7517\n",
      "['loss', 'weighted_categorical_accuracy', 'weighted_f1_score', 'weighted_categorical_accuracy', 'weighted_f1_score']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8686318397521973,\n",
       " 0.7240773439407349,\n",
       " 0.7517008781433105,\n",
       " 0.7240773439407349,\n",
       " 0.7517008781433105]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "test_result = model.evaluate(test_dataset.batch(32))\n",
    "print(model.metrics_names)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c856e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_path = os.path.join(\"mwsa\",\"mwsa_best_de\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed49e21d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d1db022c0c30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save_pretrained(save_path, saved_model=True)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e16eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at mwsa/mwsa_best_de.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# In order to use GCP for trained models, we have to save the model as TF Saved_Model format.\n",
    "# Just calling model.save() doesn't work.\n",
    "# https://colab.research.google.com/drive/1p1Nifh1P-vqAZ1gHsNSCXAHzVWzl5YPP\n",
    "# https://github.com/huggingface/transformers/issues/2021\n",
    "import os \n",
    "\n",
    "from transformers import TFBertForSequenceClassification\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ba0066c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-89c805c802cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"only me\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"only me\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m data = tf.data.Dataset.from_tensor_slices((\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m ))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained(save_path)\n",
    "input_encodings = loaded_tokenizer([\"only me\"],[\"only me\"], max_length=256, truncation=True, padding='max_length', return_tensors=\"tf\")\n",
    "data = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(input_encodings)\n",
    "))\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8798b398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 256), dtype=int32, numpy=\n",
       "array([[  102, 21692,  6501,   103, 21692,  6501,   103,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 256), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 256), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c912ce97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-45cc4be04051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#predict_input = (test_encodings,  truncation=True, max_length=128, padding='max_length')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m data = tf.data.Dataset.from_tensor_slices((\n\u001b[1;32m      5\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#predict_input = (test_encodings,  truncation=True, max_length=128, padding='max_length')\n",
    "result = loaded_model.predict(test_dataset.batch(32))\n",
    "probabilities = tf.nn.softmax(result.logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6e530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a39a4990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'broader', 1: 'exact', 2: 'narrower', 3: 'none', 4: 'related'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50c308ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.6.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ill (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eras (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.41      0.52      0.46        33\n",
      "           2       0.20      0.31      0.24        29\n",
      "           3       0.95      0.82      0.88       444\n",
      "           4       0.17      0.05      0.08        20\n",
      "\n",
      "    accuracy                           0.72       569\n",
      "   macro avg       0.39      0.44      0.40       569\n",
      "weighted avg       0.80      0.72      0.75       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#import numpy\n",
    "!pip install scikit-learn\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "numpy.set_printoptions(threshold=200)\n",
    "\n",
    "preds = tf.argmax(result.logits, axis=1).numpy()\n",
    "print(classification_report(np.argmax(test_labels,axis=1),preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6915bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.Series(preds)\n",
    "result_df = result_df.map(lambda res: le.inverse_transform([res])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4deb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig[4]=result_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0da6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig.to_csv(\"german/bert_german_20210511\", sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615d8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
