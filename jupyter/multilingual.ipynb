{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import spacy\n",
    "#from codalab_shared_task import add_column_names, sort_dataset, load_data, undersample_dataset\n",
    "import pandas as pd\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "\n",
    "\n",
    "from spacy.lookups import Lookups\n",
    "lookups = Lookups()\n",
    "lemmatizer = Lemmatizer(lookups)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import stop_words\n",
    "\n",
    "import nltk\n",
    "import stanfordnlp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "languages = ['basque','bulgarian','danish','dutch','estonian',\n",
    "             'german','hungarian','italian','irish','portuguese',\n",
    "             'russian','serbian','slovene']\n",
    "\n",
    "folder = 'data/train'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stopwords for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basque 98\n",
      "bulgarian 259\n",
      "danish 94\n",
      "dutch 101\n",
      "estonian 35\n",
      "german 232\n",
      "hungarian 199\n",
      "italian 308\n",
      "irish 109\n",
      "portuguese 203\n",
      "russian 421\n",
      "serbian 389\n",
      "slovene 446\n"
     ]
    }
   ],
   "source": [
    "stopwords = {}\n",
    "folder_st = 'data/stopwords/'\n",
    "\n",
    "for lang in languages:\n",
    "    if lang in ['basque', 'estonian','irish','slovene','serbian']:\n",
    "        filename = folder_st+lang+'.txt'\n",
    "        #print(filename)\n",
    "        file = open(filename,'r')\n",
    "        st = file.read()\n",
    "        if lang=='serbian':\n",
    "            st_list = st.split('\\n')\n",
    "        else:\n",
    "            st_list = st.replace('[','').replace(']','').replace('\"','').split(',')\n",
    "    else:\n",
    "\n",
    "        st_list = stop_words.get_stop_words(lang)\n",
    "              \n",
    "    print(lang, len(st_list))\n",
    "    stopwords[lang] = st_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    loaded_data = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "    add_column_names(loaded_data)\n",
    "\n",
    "    return loaded_data\n",
    "\n",
    "def add_column_names(df):\n",
    "    column_names = ['word', 'pos', 'def1', 'def2', 'relation']\n",
    "    df.columns = column_names\n",
    "\n",
    "def undersample_dataset(imbalanced_set):\n",
    "    none = imbalanced_set[has_label(imbalanced_set, 'none') == True]\n",
    "    second_biggest = imbalanced_set.groupby('relation').count().word.sort_values(ascending=False)[1]\n",
    "    result = imbalanced_set.drop(none.index[second_biggest:])\n",
    "\n",
    "    return result.sample(frac=1, random_state=7)\n",
    "\n",
    "def sort_dataset(all_data, dataset_lang):\n",
    "    lang_data = []\n",
    "    for key in all_data.keys():\n",
    "        if dataset_lang in key:\n",
    "            lang_data.append(all_data[key])\n",
    "    sorted_sets = list(filter(lambda elem: filter_small_length(elem, 100), sort(lang_data)))\n",
    "    return sorted_sets\n",
    "\n",
    "\n",
    "def balance_dataset(sorted_sets, balancing):\n",
    "    if balancing == 'undersampling':\n",
    "        #print(len(sorted_sets))\n",
    "        result = undersample_dataset(sorted_sets)\n",
    "\n",
    "    else:\n",
    "        smallest = sorted_sets[0]\n",
    "        bigger = sorted_sets[1]\n",
    "\n",
    "        smallest_by_label = categorize_by_label(smallest)\n",
    "        bigger_by_label = categorize_by_label(bigger)\n",
    "\n",
    "        result = combine_labels(upsample_from_bigger_set(smallest_by_label, bigger_by_label))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# REMOVE STOPWORDS AND PUNCTUATION\n",
    "\n",
    "def load_and_preprocess(dataset_lang):\n",
    "    data = load_data(folder+'/'+dataset_lang+'.tsv')\n",
    "    balanced = undersample_dataset(data)  \n",
    "    clean = clean_punctuation(balanced)\n",
    "    clean = clean_stopwords(clean, dataset_lang)\n",
    "    \n",
    "    return clean\n",
    "\n",
    "def has_label(df, label):\n",
    "    return df['relation'] == label\n",
    "\n",
    "def remove_punctuation(definition):\n",
    "    cleandef = ''\n",
    "    for word in nltk.tokenize.word_tokenize(definition):\n",
    "        if word.isalpha():\n",
    "            cleandef+=' '+word.lower()\n",
    "            #print(word)\n",
    "    if cleandef == '':\n",
    "        return definition.lower()\n",
    "    return cleandef\n",
    "\n",
    "def clean_punctuation(dataset):\n",
    "    for index, row in dataset.iterrows():\n",
    "        dataset.at[index,'def1_clean']= remove_punctuation(row['def1'])\n",
    "        dataset.at[index,'def2_clean'] = remove_punctuation(row['def2'])        \n",
    "    return dataset\n",
    "    \n",
    "    \n",
    "def remove_stopwords(definition, lang):\n",
    "    cleandef = ''\n",
    "    for word in definition.split():\n",
    "        if word not in stopwords[lang]:\n",
    "            cleandef+=' '+word\n",
    "    if cleandef == '':\n",
    "        return definition\n",
    "    return cleandef\n",
    "        \n",
    "\n",
    "def clean_stopwords(dataset, lang):\n",
    "    for index, row in dataset.iterrows():\n",
    "        dataset.at[index,'def1_stop'] = remove_stopwords(row['def1_clean'], lang)\n",
    "        dataset.at[index,'def2_stop'] = remove_stopwords(row['def2_clean'], lang) \n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basque 1094\n",
      "bulgarian 1623\n",
      "danish 2520\n",
      "dutch 93\n",
      "estonian 2045\n",
      "german 388\n",
      "hungarian 1281\n",
      "italian 781\n",
      "irish 1547\n",
      "portuguese 413\n",
      "russian 709\n",
      "serbian 1156\n",
      "slovene 1551\n"
     ]
    }
   ],
   "source": [
    "balanced_data = {}\n",
    "\n",
    "for lang in languages:\n",
    "    balanced_data[lang] = load_and_preprocess(lang)\n",
    "    print(lang, len(balanced_data[lang]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word embeddings for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished  basque\n",
      "finished  bulgarian\n",
      "finished  danish\n",
      "finished  dutch\n",
      "finished  estonian\n",
      "finished  german\n",
      "finished  hungarian\n",
      "finished  italian\n",
      "finished  irish\n",
      "finished  portuguese\n",
      "finished  russian\n",
      "finished  serbian\n",
      "finished  slovene\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "\n",
    "def make_word_embedding(dataset):\n",
    "    all_definitions = []\n",
    "    for index, row in dataset.iterrows(): \n",
    "        all_definitions.append(nltk.tokenize.word_tokenize(row['def1_stop']))\n",
    "        all_definitions.append(nltk.tokenize.word_tokenize(row['def2_stop']))\n",
    "\n",
    "    model = Word2Vec(all_definitions,\n",
    "                     min_count=1,\n",
    "                     size=200,\n",
    "                     workers=2,\n",
    "                     window=5,\n",
    "                     iter=30) \n",
    "    return model\n",
    "\n",
    "\n",
    "for lang in balanced_data:\n",
    "    embeddings[lang] = make_word_embedding(balanced_data[lang])\n",
    "    print('finished',lang)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize NLP pipelines for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/eu_bdt_models/eu_bdt_tokenizer.pt', 'lang': 'eu', 'shorthand': 'eu_bdt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/eu_bdt_models/eu_bdt_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/eu_bdt_models/eu_bdt.pretrain.pt', 'lang': 'eu', 'shorthand': 'eu_bdt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/eu_bdt_models/eu_bdt_lemmatizer.pt', 'lang': 'eu', 'shorthand': 'eu_bdt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/eu_bdt_models/eu_bdt_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/eu_bdt_models/eu_bdt.pretrain.pt', 'lang': 'eu', 'shorthand': 'eu_bdt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished basque\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/bg_btb_models/bg_btb_tokenizer.pt', 'lang': 'bg', 'shorthand': 'bg_btb', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/bg_btb_models/bg_btb_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/bg_btb_models/bg_btb.pretrain.pt', 'lang': 'bg', 'shorthand': 'bg_btb', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/bg_btb_models/bg_btb_lemmatizer.pt', 'lang': 'bg', 'shorthand': 'bg_btb', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/bg_btb_models/bg_btb_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/bg_btb_models/bg_btb.pretrain.pt', 'lang': 'bg', 'shorthand': 'bg_btb', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished bulgarian\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/da_ddt_models/da_ddt_tokenizer.pt', 'lang': 'da', 'shorthand': 'da_ddt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/da_ddt_models/da_ddt_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/da_ddt_models/da_ddt.pretrain.pt', 'lang': 'da', 'shorthand': 'da_ddt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/da_ddt_models/da_ddt_lemmatizer.pt', 'lang': 'da', 'shorthand': 'da_ddt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/da_ddt_models/da_ddt_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/da_ddt_models/da_ddt.pretrain.pt', 'lang': 'da', 'shorthand': 'da_ddt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished danish\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/nl_alpino_models/nl_alpino_tokenizer.pt', 'lang': 'nl', 'shorthand': 'nl_alpino', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/nl_alpino_models/nl_alpino_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/nl_alpino_models/nl_alpino.pretrain.pt', 'lang': 'nl', 'shorthand': 'nl_alpino', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/nl_alpino_models/nl_alpino_lemmatizer.pt', 'lang': 'nl', 'shorthand': 'nl_alpino', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/nl_alpino_models/nl_alpino_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/nl_alpino_models/nl_alpino.pretrain.pt', 'lang': 'nl', 'shorthand': 'nl_alpino', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished dutch\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/et_edt_models/et_edt_tokenizer.pt', 'lang': 'et', 'shorthand': 'et_edt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/et_edt_models/et_edt_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/et_edt_models/et_edt.pretrain.pt', 'lang': 'et', 'shorthand': 'et_edt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/et_edt_models/et_edt_lemmatizer.pt', 'lang': 'et', 'shorthand': 'et_edt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/et_edt_models/et_edt_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/et_edt_models/et_edt.pretrain.pt', 'lang': 'et', 'shorthand': 'et_edt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished estonian\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/de_gsd_models/de_gsd_tokenizer.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: mwt\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/de_gsd_models/de_gsd_mwt_expander.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/de_gsd_models/de_gsd_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/de_gsd_models/de_gsd.pretrain.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/de_gsd_models/de_gsd_lemmatizer.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/de_gsd_models/de_gsd_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/de_gsd_models/de_gsd.pretrain.pt', 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished german\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/hu_szeged_models/hu_szeged_tokenizer.pt', 'lang': 'hu', 'shorthand': 'hu_szeged', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/hu_szeged_models/hu_szeged_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/hu_szeged_models/hu_szeged.pretrain.pt', 'lang': 'hu', 'shorthand': 'hu_szeged', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/hu_szeged_models/hu_szeged_lemmatizer.pt', 'lang': 'hu', 'shorthand': 'hu_szeged', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/hu_szeged_models/hu_szeged_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/hu_szeged_models/hu_szeged.pretrain.pt', 'lang': 'hu', 'shorthand': 'hu_szeged', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished hungarian\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/it_isdt_models/it_isdt_tokenizer.pt', 'lang': 'it', 'shorthand': 'it_isdt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: mwt\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/it_isdt_models/it_isdt_mwt_expander.pt', 'lang': 'it', 'shorthand': 'it_isdt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/it_isdt_models/it_isdt_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/it_isdt_models/it_isdt.pretrain.pt', 'lang': 'it', 'shorthand': 'it_isdt', 'mode': 'predict'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/it_isdt_models/it_isdt_lemmatizer.pt', 'lang': 'it', 'shorthand': 'it_isdt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/it_isdt_models/it_isdt_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/it_isdt_models/it_isdt.pretrain.pt', 'lang': 'it', 'shorthand': 'it_isdt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished italian\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/ga_idt_models/ga_idt_tokenizer.pt', 'lang': 'ga', 'shorthand': 'ga_idt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/ga_idt_models/ga_idt_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/ga_idt_models/ga_idt.pretrain.pt', 'lang': 'ga', 'shorthand': 'ga_idt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/ga_idt_models/ga_idt_lemmatizer.pt', 'lang': 'ga', 'shorthand': 'ga_idt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/ga_idt_models/ga_idt_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/ga_idt_models/ga_idt.pretrain.pt', 'lang': 'ga', 'shorthand': 'ga_idt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished irish\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/pt_bosque_models/pt_bosque_tokenizer.pt', 'lang': 'pt', 'shorthand': 'pt_bosque', 'mode': 'predict'}\n",
      "---\n",
      "Loading: mwt\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/pt_bosque_models/pt_bosque_mwt_expander.pt', 'lang': 'pt', 'shorthand': 'pt_bosque', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/pt_bosque_models/pt_bosque_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/pt_bosque_models/pt_bosque.pretrain.pt', 'lang': 'pt', 'shorthand': 'pt_bosque', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/pt_bosque_models/pt_bosque_lemmatizer.pt', 'lang': 'pt', 'shorthand': 'pt_bosque', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/pt_bosque_models/pt_bosque_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/pt_bosque_models/pt_bosque.pretrain.pt', 'lang': 'pt', 'shorthand': 'pt_bosque', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished portuguese\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/ru_syntagrus_models/ru_syntagrus_tokenizer.pt', 'lang': 'ru', 'shorthand': 'ru_syntagrus', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/ru_syntagrus_models/ru_syntagrus_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/ru_syntagrus_models/ru_syntagrus.pretrain.pt', 'lang': 'ru', 'shorthand': 'ru_syntagrus', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/ru_syntagrus_models/ru_syntagrus_lemmatizer.pt', 'lang': 'ru', 'shorthand': 'ru_syntagrus', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/ru_syntagrus_models/ru_syntagrus_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/ru_syntagrus_models/ru_syntagrus.pretrain.pt', 'lang': 'ru', 'shorthand': 'ru_syntagrus', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished russian\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/sr_set_models/sr_set_tokenizer.pt', 'lang': 'sr', 'shorthand': 'sr_set', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/sr_set_models/sr_set_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/sr_set_models/sr_set.pretrain.pt', 'lang': 'sr', 'shorthand': 'sr_set', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/sr_set_models/sr_set_lemmatizer.pt', 'lang': 'sr', 'shorthand': 'sr_set', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/sr_set_models/sr_set_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/sr_set_models/sr_set.pretrain.pt', 'lang': 'sr', 'shorthand': 'sr_set', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished serbian\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/sl_ssj_models/sl_ssj_tokenizer.pt', 'lang': 'sl', 'shorthand': 'sl_ssj', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/sl_ssj_models/sl_ssj_tagger.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/sl_ssj_models/sl_ssj.pretrain.pt', 'lang': 'sl', 'shorthand': 'sl_ssj', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/sl_ssj_models/sl_ssj_lemmatizer.pt', 'lang': 'sl', 'shorthand': 'sl_ssj', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/lenka/stanfordnlp_resources/sl_ssj_models/sl_ssj_parser.pt', 'pretrain_path': '/Users/lenka/stanfordnlp_resources/sl_ssj_models/sl_ssj.pretrain.pt', 'lang': 'sl', 'shorthand': 'sl_ssj', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "finished slovene\n"
     ]
    }
   ],
   "source": [
    "nlp_pipelines = {}\n",
    "\n",
    "lang_codes = {'basque':'eu','bulgarian':'bg','danish':'da','dutch':'nl','estonian':'et',\n",
    "             'german':'de','hungarian':'hu','italian':'it','irish':'ga','portuguese':'pt',\n",
    "             'russian':'ru','serbian':'sr','slovene':'sl'}\n",
    "\n",
    "for lang in languages:\n",
    "    #stanfordnlp.download(lang_codes[lang])\n",
    "    nlp_pipelines[lang] = stanfordnlp.Pipeline(lang = lang_codes[lang])\n",
    "    #for definition in balanced_data[lang]['def1_clean'][:10]:\n",
    "    #    doc = nlp_pipeline(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_word_same(row):\n",
    "    return row['def1_clean'].split(' ')[0].lower() == row['def2_clean'].split(' ')[0].lower()\n",
    "\n",
    "\n",
    "def difference_in_length(row):\n",
    "    return abs(len(row['def1_clean'].split(' ')) - len(row['def2_clean'].split(' ')[0]))\n",
    "\n",
    "\n",
    "def jaccard_sim(row):\n",
    "    return get_jaccard_sim(row['def1_clean'], row['def2_clean'])\n",
    "\n",
    "def cos_gensim(row, lang):\n",
    "    return get_cos_gensim(row['def1_stop'], row['def2_stop'], lang)[0,1]\n",
    "\n",
    "\n",
    "#import scipy.spatial as spatial\n",
    "import numpy as np\n",
    "\n",
    "def get_cos_gensim(def1, def2, lang):\n",
    "    avg1=[]\n",
    "    for word in nltk.tokenize.word_tokenize(def1):\n",
    "        avg1.append(embeddings[lang][word])\n",
    "        \n",
    "    avg2=[]\n",
    "    for word in nltk.tokenize.word_tokenize(def2):\n",
    "        avg2.append(embeddings[lang][word])\n",
    "        \n",
    "    v1 = np.array(avg1).reshape(-1,1)\n",
    "    v2 = np.array(avg2).reshape(-1,1)\n",
    "\n",
    "    return cosine_similarity(v1, v2)\n",
    "\n",
    "\n",
    "def wmd(row, lang):\n",
    "    return get_wmd(lang, row['def1_stop'], row['def2_stop'])\n",
    "\n",
    "def get_wmd(lang, def1, def2):\n",
    "    return embeddings[lang].wmdistance(nltk.tokenize.word_tokenize(def1), nltk.tokenize.word_tokenize(def2))\n",
    "\n",
    "def cosine(row):\n",
    "    cos = get_cosine_sim(row['def1_stop'], row['def2_stop'])\n",
    "    return cos[0, 1]\n",
    "\n",
    "def get_cosine_sim(*strs):\n",
    "    vectors = [t for t in get_vectors(*strs)]\n",
    "    return cosine_similarity(vectors)\n",
    "\n",
    "\n",
    "\n",
    "def get_jaccard_sim(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    vectorizer = CountVectorizer(text)\n",
    "    vectorizer.fit(text)\n",
    "    return vectorizer.transform(text).toarray()\n",
    "\n",
    "# TODO LEMMA\n",
    "def root_same(row, lang):\n",
    "    return root_word_same(row['def1_clean'], row['def2_clean'], lang)\n",
    "\n",
    "def root_word_same(def1, def2, lang):\n",
    "    root1 = ''\n",
    "    root2 = ''\n",
    "    \n",
    "    doc1 = nlp_pipelines[lang](def1)\n",
    "    doc2 = nlp_pipelines[lang](def2)\n",
    "\n",
    "    for token in doc1.sentences[0].tokens:\n",
    "        if token.words[0].dependency_relation == 'root':\n",
    "            root1 = token.words[0].lemma\n",
    "            break\n",
    "        \n",
    "    for token in doc2.sentences[0].tokens:\n",
    "        if token.words[0].dependency_relation == 'root':\n",
    "            root2 = token.words[0].lemma\n",
    "            break\n",
    "            \n",
    "    #print(root1, root2, root1==root2)\n",
    "    return root1==root2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf(col1, col2):\n",
    "    tfidf_holder = pd.DataFrame()\n",
    "    tfidf_holder['col1'] = col1\n",
    "    tfidf_holder['col2'] = col2\n",
    "\n",
    "    values = join_definitions(col1, col2)\n",
    "    tfidf_holder['tfidf_1'], tfidf_holder['tfidf_2'] = tfidf_vectors(values)\n",
    "\n",
    "    return tfidf_holder.apply(lambda row: cosine_similarity([row['tfidf_1'], row['tfidf_2']])[0, 1], axis=1)\n",
    "\n",
    "\n",
    "def convert_to_text(token_array):\n",
    "    seperator = ' '\n",
    "    return seperator.join(token_array)\n",
    "\n",
    "\n",
    "def join_definitions(col1, col2):\n",
    "    joined_definitions = pd.concat([col1, col2])\n",
    "    return joined_definitions.apply(lambda tokens: ' '.join(tokens)).values.T\n",
    "\n",
    "\n",
    "def tfidf_vectors(values):\n",
    "    tfidf_matrix = TfidfVectorizer().fit_transform(values)\n",
    "\n",
    "    split_index = int(tfidf_matrix.get_shape()[0] / 2)\n",
    "    tfidf_array = tfidf_matrix.todense()\n",
    "\n",
    "    df_result1 = [row.tolist()[0] for row in tfidf_array[0:split_index]]\n",
    "    df_result2 = [row.tolist()[0] for row in tfidf_array[split_index:]]\n",
    "\n",
    "    return df_result1, df_result2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(data, feats_to_scale, lang):\n",
    "    #def sentence2vec(row):\n",
    "    #    return row['processed_1'].similarity(row['processed_2'])\n",
    "\n",
    "    feat = pd.DataFrame()\n",
    "    #print(data)\n",
    "    #feat['similarities'] = data.apply(lambda row: sentence2vec(row), axis=1)\n",
    "    feat['first_word_same'] = data.apply(lambda row: first_word_same(row), axis=1)\n",
    "    feat['len_diff'] = data.apply(lambda row: difference_in_length(row), axis=1)\n",
    "    feat['jaccard'] = data.apply(lambda row: jaccard_sim(row), axis=1)\n",
    "    feat['cos'] = data.apply(lambda row: cosine(row), axis=1)\n",
    "    feat['wmd'] = data.apply(lambda row: wmd(row, lang), axis=1)\n",
    "    #feat['jaccard_gensim'] = data.apply(lambda row: jaccard_gensim(row, lang), axis=1)\n",
    "    feat['cos_gensim'] = data.apply(lambda row: cos_gensim(row, lang), axis=1)\n",
    "    \n",
    "    feat['root_same'] = data.apply(lambda row: root_same(row, lang), axis=1)\n",
    "    #feat['diff_pos_count'] = data.apply(lambda row: diff_pos_count(row), axis = 1)\n",
    "    #feat['tfidf_similarity'] = tfidf(data['def1_stop'], data['def2_stop'])\n",
    "\n",
    "    for c_name in feats_to_scale:\n",
    "        feat[c_name] = preprocessing.scale(feat[c_name])\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted features for basque\n",
      "extracted features for bulgarian\n",
      "extracted features for danish\n",
      "extracted features for dutch\n",
      "extracted features for estonian\n",
      "extracted features for german\n",
      "extracted features for hungarian\n",
      "extracted features for italian\n",
      "extracted features for irish\n",
      "extracted features for portuguese\n",
      "extracted features for russian\n",
      "extracted features for serbian\n",
      "extracted features for slovene\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "labels = {}\n",
    "\n",
    "for lang in languages:\n",
    "    #balanced_data[lang] = load_and_preprocess(lang)\n",
    "    #print(lang, len(balanced_data[lang]))\n",
    "    features[lang] = extract_features(balanced_data[lang],[], lang)\n",
    "    labels[lang] = balanced_data[lang]['relation']\n",
    "    print('extracted features for', lang)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data, with_testset=False):\n",
    "    #train_and_test_classifiers(data['nltk']['trainset'], data['nltk']['testset'])\n",
    "    trained_models = train_models_sklearn(data['pd']['x_trainset'],\n",
    "                                          data['pd']['y_trainset'])\n",
    "    cross_val_models(trained_models, data['pd']['x_trainset'],\n",
    "                     data['pd']['y_trainset'])\n",
    "\n",
    "    if with_testset:\n",
    "        compare_on_testset(trained_models, data['pd']['x_testset'],\n",
    "                           data['pd']['y_testset'])\n",
    "\n",
    "        \n",
    "\n",
    "def cross_val_models(models, x_train, y_train):\n",
    "    for estimator in models:\n",
    "        run_cv_with_dataset(estimator, x_train, y_train)\n",
    "\n",
    "    \n",
    "def run_cv_with_dataset(model, trainset, y_train):\n",
    "    scores = cross_val_score(model, trainset, y_train, cv=5)\n",
    "    print('Cross validation scores for model' + model.__class__.__name__ + '\\n')\n",
    "    print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2) + '\\n')\n",
    "\n",
    "        \n",
    "def train_models_sklearn(x_train, y_train):\n",
    "    lr = {'estimator': LogisticRegression(solver='lbfgs', multi_class='auto', max_iter = 500), 'parameters': {}}\n",
    "    svm_model = {\n",
    "        'estimator': SVC(),\n",
    "        'parameters': {\n",
    "            'C': [3, 5, 10],\n",
    "            'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        }\n",
    "    }\n",
    "    rf = {\n",
    "        'estimator': RandomForestClassifier(),\n",
    "        'parameters': {\n",
    "            'bootstrap': [True],\n",
    "            'max_depth': [2, 3, 5, 7, 10],\n",
    "            'max_features': [2, 3],\n",
    "            'min_samples_leaf': [3, 4, 5],\n",
    "            'min_samples_split': [2, 5, 8, 10, 12],\n",
    "            'n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    }\n",
    "    dt = {'estimator': DecisionTreeClassifier(), 'parameters': {}}\n",
    "\n",
    "    models = {'unscaled': [lr, rf]}\n",
    "\n",
    "    tuned_models = tune_hyperparams(models, x_train, y_train)\n",
    "\n",
    "    return tuned_models\n",
    "\n",
    "\n",
    "def tune_hyperparams(estimators, x_train, y_train):\n",
    "    result = []\n",
    "    for estimator in estimators['unscaled']:\n",
    "        params = estimator['parameters']\n",
    "\n",
    "        scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "        for score in scores:\n",
    "            print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "            print()\n",
    "\n",
    "            grid_search = GridSearchCV(estimator=estimator['estimator'], param_grid=params,\n",
    "                                       scoring='%s_weighted' % score, cv=5,\n",
    "                                       n_jobs=-1, verbose=1)\n",
    "\n",
    "            print(\"Performing grid search...\")\n",
    "            print(\"parameters:\")\n",
    "            pprint(params)\n",
    "            grid_search.fit(x_train, y_train)\n",
    "            print()\n",
    "\n",
    "            means = grid_search.cv_results_['mean_test_score']\n",
    "            stds = grid_search.cv_results_['std_test_score']\n",
    "            print('Precision: \\n')\n",
    "            #for mean, std, parameters in zip(means, stds, grid_search.cv_results_['params']):\n",
    "            #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            #                      % (mean, std * 2, parameters) + '\\n')\n",
    "\n",
    "            print(\"Best score: %0.3f\" % grid_search.best_score_ + '\\n')\n",
    "            print(\"Best parameters set:\\n\")\n",
    "            best_parameters = grid_search.best_estimator_.get_params()\n",
    "            for param_name in sorted(params.keys()):\n",
    "                print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]) + '\\n')\n",
    "\n",
    "            result.append(grid_search.best_estimator_)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "basque\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.458\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.522\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.420\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 808 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1158 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1608 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2158 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.476\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 5\n",
      "\n",
      "\tmin_samples_split: 10\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2133 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.528\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 5\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 817 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1167 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2167 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.454\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5220 (+/- 0.0261)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5220 (+/- 0.0261)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5220 (+/- 0.0261)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5201 (+/- 0.0223)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5201 (+/- 0.0261)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5155 (+/- 0.0356)\n",
      "\n",
      "*************************\n",
      "bulgarian\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.316\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.475\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.374\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 303 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 553 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 903 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1353 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1903 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.418\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 8\n",
      "\n",
      "\tn_estimators: 200\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1262 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1712 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.487\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 5\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done 604 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done 954 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1404 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.401\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4751 (+/- 0.0234)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4751 (+/- 0.0234)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4751 (+/- 0.0234)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.4683 (+/- 0.0393)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.4837 (+/- 0.0343)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.4701 (+/- 0.0205)\n",
      "\n",
      "*************************\n",
      "danish\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.506\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.627\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.558\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1257 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1707 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.608\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1038 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1488 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2038 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.650\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=-1)]: Done 531 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=-1)]: Done 881 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1331 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1881 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.582\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 5\n",
      "\n",
      "\tmin_samples_split: 10\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6273 (+/- 0.0373)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6273 (+/- 0.0373)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6273 (+/- 0.0373)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6468 (+/- 0.0185)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6420 (+/- 0.0281)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6444 (+/- 0.0255)\n",
      "\n",
      "*************************\n",
      "dutch\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.747\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.742\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.736\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.858\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 2\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1413 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1863 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.860\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 2\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 5\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.854\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 2\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 8\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.7429 (+/- 0.1518)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.7429 (+/- 0.1518)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.7429 (+/- 0.1518)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.8508 (+/- 0.2708)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.8111 (+/- 0.2948)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.8508 (+/- 0.2708)\n",
      "\n",
      "*************************\n",
      "estonian\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.623\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.680\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.646\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1301 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1751 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.675\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 10\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1198 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1648 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2198 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.685\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 5\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.650\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6797 (+/- 0.0224)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6797 (+/- 0.0224)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6797 (+/- 0.0224)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6743 (+/- 0.0230)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6782 (+/- 0.0210)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6807 (+/- 0.0265)\n",
      "\n",
      "*************************\n",
      "german\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.483\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.482\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.453\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.628\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 3\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 12\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.580\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 10\n",
      "\n",
      "\tn_estimators: 200\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1298 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1748 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.568\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4822 (+/- 0.1274)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4822 (+/- 0.1274)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4822 (+/- 0.1274)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5411 (+/- 0.1120)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5594 (+/- 0.0877)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5672 (+/- 0.0786)\n",
      "\n",
      "*************************\n",
      "hungarian\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.537\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.597\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.542\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.649\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 3\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 5\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 200\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1291 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1741 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.614\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 5\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 200\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.571\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5971 (+/- 0.0527)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5971 (+/- 0.0527)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5971 (+/- 0.0527)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5988 (+/- 0.0219)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6096 (+/- 0.0486)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5986 (+/- 0.0499)\n",
      "\n",
      "*************************\n",
      "italian\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.464\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.557\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.470\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2083 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.484\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 8\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 791 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1141 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1591 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2141 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.560\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 3\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.478\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 8\n",
      "\n",
      "\tn_estimators: 200\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5569 (+/- 0.0191)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5569 (+/- 0.0191)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5569 (+/- 0.0191)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5455 (+/- 0.0146)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5556 (+/- 0.0386)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5494 (+/- 0.0334)\n",
      "\n",
      "*************************\n",
      "irish\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.644\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.745\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.688\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.713\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 12\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.771\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 8\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.725\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.7441 (+/- 0.0211)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.7441 (+/- 0.0211)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.7441 (+/- 0.0211)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.7609 (+/- 0.0315)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.7667 (+/- 0.0267)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.7635 (+/- 0.0250)\n",
      "\n",
      "*************************\n",
      "portuguese\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.713\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.823\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.764\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  6.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.765\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 1341.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed: 1341.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.838\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 7\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.793\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 7\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.8239 (+/- 0.0535)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.8239 (+/- 0.0535)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.8239 (+/- 0.0535)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.8335 (+/- 0.0487)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.8239 (+/- 0.0477)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.8305 (+/- 0.0238)\n",
      "\n",
      "*************************\n",
      "russian\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.473\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.612\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.527\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1406 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1856 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.566\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.616\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 2\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 12\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.541\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6122 (+/- 0.0523)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6122 (+/- 0.0523)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.6122 (+/- 0.0523)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5980 (+/- 0.0260)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6079 (+/- 0.0560)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6051 (+/- 0.0414)\n",
      "\n",
      "*************************\n",
      "serbian\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.349\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.482\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.400\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 872 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1222 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1672 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2222 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.498\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 200\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.492\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 2\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 10\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 620 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=-1)]: Done 970 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1420 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1970 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.430\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4826 (+/- 0.0273)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4818 (+/- 0.0258)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.4826 (+/- 0.0273)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.4879 (+/- 0.0166)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.4835 (+/- 0.0258)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.4870 (+/- 0.0287)\n",
      "\n",
      "*************************\n",
      "slovene\n",
      "*************************\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.468\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.521\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.478\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1284 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1834 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.598\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2225 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.603\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 2\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 750 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1100 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1550 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2100 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.568\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 3\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 8\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5204 (+/- 0.0666)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5204 (+/- 0.0666)\n",
      "\n",
      "Cross validation scores for modelLogisticRegression\n",
      "\n",
      "Accuracy: 0.5204 (+/- 0.0666)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5990 (+/- 0.0317)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.6010 (+/- 0.0395)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5925 (+/- 0.0345)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "def split_data(featuresets):\n",
    "    f = int(len(featuresets) / 5)\n",
    "    return featuresets[f:], featuresets[:f]\n",
    "\n",
    "\n",
    "\n",
    "for lang in features:\n",
    "    \n",
    "    print('*************************')\n",
    "    print(lang)\n",
    "    print('*************************')\n",
    "    #train_set, test_set = split_data(features[lang])\n",
    "    \n",
    "    data = {'pd':{}}\n",
    "    \n",
    "    data['pd']['x_trainset'] = features[lang]\n",
    "    data['pd']['y_trainset'] = labels[lang]\n",
    "    \n",
    "    train(data)\n",
    "    \n",
    "    #print(len(features[lang]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
