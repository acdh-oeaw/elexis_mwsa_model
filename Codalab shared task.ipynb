{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Task\n",
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/seungbinyim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pprint import pprint\n",
    "from spacy import displacy\n",
    "from enum import Enum\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "def print_all_rows(df):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = 'data/train'\n",
    "\n",
    "def has_label(df, label):\n",
    "    return df['relation'] == label\n",
    "\n",
    "\n",
    "def filter_small_length(dataset, threshold):\n",
    "    return len(dataset.index) > threshold\n",
    "\n",
    "\n",
    "def sort(lst):\n",
    "    return sorted(lst, key=len)\n",
    "\n",
    "\n",
    "def upsample_from_bigger_set(smallest_by_label, bigger_by_label):\n",
    "    biggeset_label, biggest_label_size = find_biggest_label_and_size(smallest_by_label)\n",
    "\n",
    "    return upsample_by_diff(bigger_by_label, biggeset_label, biggest_label_size, smallest_by_label)\n",
    "\n",
    "\n",
    "def upsample_by_diff(bigger_by_label, biggeset_label, biggest_label_size, smallest_by_label):\n",
    "    for key in smallest_by_label:\n",
    "        if key != biggeset_label:\n",
    "            diff = biggest_label_size - len(smallest_by_label[key].index)\n",
    "            if diff > 0:\n",
    "                new_data = bigger_by_label[key].sample(n=diff, random_state=7, replace=True)\n",
    "                smallest_by_label[key] = smallest_by_label[key].append(new_data)\n",
    "\n",
    "    return smallest_by_label\n",
    "\n",
    "\n",
    "def find_biggest_label_and_size(smallest_by_label):\n",
    "    largest_label = None\n",
    "    largest_label_size = 0\n",
    "\n",
    "    for key in smallest_by_label:\n",
    "        if len(smallest_by_label[key].index) > largest_label_size:\n",
    "            largest_label_size = len(smallest_by_label[key].index)\n",
    "            largest_label = key\n",
    "\n",
    "    return largest_label, largest_label_size\n",
    "\n",
    "\n",
    "def combine_labels(dict_by_label):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for key in dict_by_label:\n",
    "        df = df.append(dict_by_label[key])\n",
    "\n",
    "    return df.sample(frac=1, random_state=7)\n",
    "\n",
    "\n",
    "def sort_dataset(all_data, dataset_lang):\n",
    "    lang_data = []\n",
    "    for key in all_data.keys():\n",
    "        if dataset_lang in key:\n",
    "            lang_data.append(all_data[key])\n",
    "    sorted_sets = list(filter(lambda elem: filter_small_length(elem, 100), sort(lang_data)))\n",
    "    return sorted_sets\n",
    "\n",
    "\n",
    "def categorize_by_label(df):\n",
    "    relation_labels = df['relation'].unique()\n",
    "    smallest_by_label = {}\n",
    "    for relation in relation_labels:\n",
    "        smallest_by_label[relation] = df[has_label(df, relation)]\n",
    "\n",
    "    return smallest_by_label\n",
    "\n",
    "def load_and_preprocess(dataset_lang, balancing = 'oversampling'):\n",
    "    all_data = load_training_data()\n",
    "\n",
    "    sorted_sets = sort_dataset(all_data, dataset_lang)\n",
    "\n",
    "    balanced = balance_dataset(sorted_sets, balancing)\n",
    "\n",
    "    balanced['processed_1'] = balanced['def1'].map(nlp)\n",
    "    balanced['processed_2'] = balanced['def2'].map(nlp)\n",
    "\n",
    "    balanced['lemmatized_1'] = balanced['processed_1'].map(lemmatizer)\n",
    "    balanced['stopwords_removed_1'] = balanced['lemmatized_1'].map(remove_stopwords)\n",
    "\n",
    "    balanced['lemmatized_2'] = balanced['processed_2'].map(lemmatizer)\n",
    "    balanced['stopwords_removed_2'] = balanced['lemmatized_2'].map(remove_stopwords)\n",
    "\n",
    "    return balanced\n",
    "\n",
    "def load_training_data():\n",
    "    combined_set = {}\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".tsv\"):\n",
    "            combined_set[filename.split('.')[0]] = load_data(folder + '/' + filename)\n",
    "\n",
    "    return combined_set\n",
    "\n",
    "def load_data(file_path):\n",
    "    loaded_data = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "    add_column_names(loaded_data)\n",
    "\n",
    "    return loaded_data\n",
    "\n",
    "def add_column_names(df):\n",
    "    column_names = ['word', 'pos', 'def1', 'def2', 'relation']\n",
    "    df.columns = column_names\n",
    "\n",
    "def undersample_dataset(imbalanced_set):\n",
    "    none = imbalanced_set[has_label(imbalanced_set, 'none') == True]\n",
    "    second_biggest = imbalanced_set.groupby('relation').count().word.sort_values(ascending=False)[1]\n",
    "    result = imbalanced_set.drop(none.index[second_biggest:])\n",
    "\n",
    "    return result.sample(frac=1, random_state=7)\n",
    "\n",
    "\n",
    "def balance_dataset(sorted_sets, balancing):\n",
    "    if balancing == 'undersampling':\n",
    "        result = undersample_dataset(sorted_sets[0])\n",
    "\n",
    "    else:\n",
    "        smallest = sorted_sets[0]\n",
    "        bigger = sorted_sets[1]\n",
    "\n",
    "        smallest_by_label = categorize_by_label(smallest)\n",
    "        bigger_by_label = categorize_by_label(bigger)\n",
    "\n",
    "        result = combine_labels(upsample_from_bigger_set(smallest_by_label, bigger_by_label))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def is_not_none(df):\n",
    "    return df['relation'] != 'none'\n",
    "\n",
    "\n",
    "def is_none(df):\n",
    "    return df['relation'] == 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_en_data = load_and_preprocess('english', balancing = 'oversampling')\n",
    "balanced_en_data_undersampled = load_and_preprocess('english', balancing = 'undersampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Feature Extraction related functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word          pos  \\\n",
      "20    off        adverb        \n",
      "3025  superior   adjective     \n",
      "382   on         preposition   \n",
      "4438  domestic   adjective     \n",
      "256   open       adjective     \n",
      "...    ...             ...     \n",
      "3120  calamus    noun          \n",
      "8052  fireball   noun          \n",
      "102   offensive  adjective     \n",
      "4107  work       verb          \n",
      "5048  follow     verb          \n",
      "\n",
      "                                                                           def1  \\\n",
      "20    away from a place                                                           \n",
      "3025  (often followed by `to') above being affected or influenced by              \n",
      "382   touching the surface of sth                                                 \n",
      "4438  of or involving the home or family                                          \n",
      "256   (of a store, business, etc.) available for business or to provide service   \n",
      "...                                                                         ...   \n",
      "3120  perennial marsh plant having swordlike leaves and aromatic roots            \n",
      "8052  a ball of fire (such as the sun or a ball-shaped discharge of lightning)    \n",
      "102   in sports, relating to actions or team members that score points            \n",
      "4107  make something, usually for a specific function                             \n",
      "5048  come as a logical consequence; follow logically                             \n",
      "\n",
      "                                                                                                                                                                                                                                                             def2  \\\n",
      "20    (of food) rotten                                                                                                                                                                                                                                              \n",
      "3025  beyond the power or influence of; too great or firm to be subdued or affected by; -- with .                                                                                                                                                                   \n",
      "382   when (something is, or has been, done)                                                                                                                                                                                                                        \n",
      "4438  remaining much at home; devoted to home duties or pleasures; .                                                                                                                                                                                                \n",
      "256   not kept secret                                                                                                                                                                                                                                               \n",
      "...               ...                                                                                                                                                                                                                                               \n",
      "3120  a species of Acorus (corus calamus), commonly called calamus, or sweet flag. the root has a pungent, aromatic taste, and is used in medicine as a stomachic; the leaves have an aromatic odor, and were formerly used instead of rushes to strew on floors.   \n",
      "8052  a large mass of fire caused by a large explosion, as of inflammable liquids or a nuclear device.  the larger , as of nuclear explosions, rise seemingly intact into the air and may reach high altitudes while still glowing.                                 \n",
      "102   insulting                                                                                                                                                                                                                                                     \n",
      "4107  to produce or form by labor; to bring forth by exertion or toil; to accomplish; to originate; to effect;                                                                                                                                                      \n",
      "5048  to result from, as an effect from a cause, or an inference from a premise.                                                                                                                                                                                    \n",
      "\n",
      "      relation  \\\n",
      "20    none       \n",
      "3025  narrower   \n",
      "382   none       \n",
      "4438  broader    \n",
      "256   none       \n",
      "...    ...       \n",
      "3120  narrower   \n",
      "8052  broader    \n",
      "102   none       \n",
      "4107  exact      \n",
      "5048  narrower   \n",
      "\n",
      "                                                                                           processed_1  \\\n",
      "20    (away, from, a, place)                                                                             \n",
      "3025  ((, often, followed, by, `, to, ', ), above, being, affected, or, influenced, by)                  \n",
      "382   (touching, the, surface, of, sth)                                                                  \n",
      "4438  (of, or, involving, the, home, or, family)                                                         \n",
      "256   ((, of, a, store, ,, business, ,, etc, ., ), available, for, business, or, to, provide, service)   \n",
      "...                                                                                                ...   \n",
      "3120  (perennial, marsh, plant, having, swordlike, leaves, and, aromatic, roots)                         \n",
      "8052  (a, ball, of, fire, (, such, as, the, sun, or, a, ball, -, shaped, discharge, of, lightning, ))    \n",
      "102   (in, sports, ,, relating, to, actions, or, team, members, that, score, points)                     \n",
      "4107  (make, something, ,, usually, for, a, specific, function)                                          \n",
      "5048  (come, as, a, logical, consequence, ;, follow, logically)                                          \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                       processed_2  \\\n",
      "20    ((, of, food, ), rotten)                                                                                                                                                                                                                                                                                                       \n",
      "3025  (beyond, the, power, or, influence, of, ;, too, great, or, firm, to, be, subdued, or, affected, by, ;, --, with, .)                                                                                                                                                                                                            \n",
      "382   (when, (, something, is, ,, or, has, been, ,, done, ))                                                                                                                                                                                                                                                                         \n",
      "4438  (remaining, much, at, home, ;, devoted, to, home, duties, or, pleasures, ;, .)                                                                                                                                                                                                                                                 \n",
      "256   (not, kept, secret)                                                                                                                                                                                                                                                                                                            \n",
      "...                   ...                                                                                                                                                                                                                                                                                                            \n",
      "3120  (a, species, of, Acorus, (, corus, calamus, ), ,, commonly, called, calamus, ,, or, sweet, flag, ., the, root, has, a, pungent, ,, aromatic, taste, ,, and, is, used, in, medicine, as, a, stomachic, ;, the, leaves, have, an, aromatic, odor, ,, and, were, formerly, used, instead, of, rushes, to, strew, on, floors, .)   \n",
      "8052  (a, large, mass, of, fire, caused, by, a, large, explosion, ,, as, of, inflammable, liquids, or, a, nuclear, device, .,  , the, larger, ,, as, of, nuclear, explosions, ,, rise, seemingly, intact, into, the, air, and, may, reach, high, altitudes, while, still, glowing, .)                                                \n",
      "102   (insulting)                                                                                                                                                                                                                                                                                                                    \n",
      "4107  (to, produce, or, form, by, labor, ;, to, bring, forth, by, exertion, or, toil, ;, to, accomplish, ;, to, originate, ;, to, effect, ;)                                                                                                                                                                                         \n",
      "5048  (to, result, from, ,, as, an, effect, from, a, cause, ,, or, an, inference, from, a, premise, .)                                                                                                                                                                                                                               \n",
      "\n",
      "                                                                                          lemmatized_1  \\\n",
      "20    (away, from, a, place)                                                                             \n",
      "3025  ((, often, follow, by, `, to, ', ), above, be, affect, or, influence, by)                          \n",
      "382   (touch, the, surface, of, sth)                                                                     \n",
      "4438  (of, or, involve, the, home, or, family)                                                           \n",
      "256   ((, of, a, store, ,, business, ,, etc, ., ), available, for, business, or, to, provide, service)   \n",
      "...                                                                                                ...   \n",
      "3120  (perennial, marsh, plant, have, swordlike, leave, and, aromatic, root)                             \n",
      "8052  (a, ball, of, fire, (, such, as, the, sun, or, a, ball, -, shape, discharge, of, lightning, ))     \n",
      "102   (in, sport, ,, relate, to, action, or, team, member, that, score, point)                           \n",
      "4107  (make, something, ,, usually, for, a, specific, function)                                          \n",
      "5048  (come, as, a, logical, consequence, ;, follow, logically)                                          \n",
      "\n",
      "                                                stopwords_removed_1  \\\n",
      "20    [away, place]                                                   \n",
      "3025  [follow, `, affect, influence]                                  \n",
      "382   [touch, surface, sth]                                           \n",
      "4438  [involve, home, family]                                         \n",
      "256   [store, business, etc, available, business, provide, service]   \n",
      "...                                                             ...   \n",
      "3120  [perennial, marsh, plant, swordlike, leave, aromatic, root]     \n",
      "8052  [ball, fire, sun, ball, shape, discharge, lightning]            \n",
      "102   [sport, relate, action, team, member, score, point]             \n",
      "4107  [usually, specific, function]                                   \n",
      "5048  [come, logical, consequence, follow, logically]                 \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                             lemmatized_2  \\\n",
      "20    ((, of, food, ), rotten)                                                                                                                                                                                                                                                                                              \n",
      "3025  (beyond, the, power, or, influence, of, ;, too, great, or, firm, to, be, subdue, or, affect, by, ;, --, with, .)                                                                                                                                                                                                      \n",
      "382   (when, (, something, be, ,, or, have, be, ,, do, ))                                                                                                                                                                                                                                                                   \n",
      "4438  (remain, much, at, home, ;, devote, to, home, duty, or, pleasure, ;, .)                                                                                                                                                                                                                                               \n",
      "256   (not, keep, secret)                                                                                                                                                                                                                                                                                                   \n",
      "...                   ...                                                                                                                                                                                                                                                                                                   \n",
      "3120  (a, species, of, Acorus, (, corus, calamus, ), ,, commonly, call, calamus, ,, or, sweet, flag, ., the, root, have, a, pungent, ,, aromatic, taste, ,, and, be, use, in, medicine, as, a, stomachic, ;, the, leave, have, an, aromatic, odor, ,, and, be, formerly, use, instead, of, rush, to, strew, on, floor, .)   \n",
      "8052  (a, large, mass, of, fire, cause, by, a, large, explosion, ,, as, of, inflammable, liquid, or, a, nuclear, device, .,   , the, large, ,, as, of, nuclear, explosion, ,, rise, seemingly, intact, into, the, air, and, may, reach, high, altitude, while, still, glow, .)                                              \n",
      "102   (insult)                                                                                                                                                                                                                                                                                                              \n",
      "4107  (to, produce, or, form, by, labor, ;, to, bring, forth, by, exertion, or, toil, ;, to, accomplish, ;, to, originate, ;, to, effect, ;)                                                                                                                                                                                \n",
      "5048  (to, result, from, ,, as, an, effect, from, a, cause, ,, or, an, inference, from, a, premise, .)                                                                                                                                                                                                                      \n",
      "\n",
      "                                                                                                                                                                       stopwords_removed_2  \n",
      "20    [food, rotten]                                                                                                                                                                        \n",
      "3025  [power, influence, great, firm, subdue, affect]                                                                                                                                       \n",
      "382   []                                                                                                                                                                                    \n",
      "4438  [remain, home, devote, home, duty, pleasure]                                                                                                                                          \n",
      "256   [secret]                                                                                                                                                                              \n",
      "...        ...                                                                                                                                                                              \n",
      "3120  [species, Acorus, corus, calamus, commonly, calamus, sweet, flag, root, pungent, aromatic, taste, use, medicine, stomachic, leave, aromatic, odor, use, instead, rush, strew, floor]  \n",
      "8052  [large, mass, fire, cause, large, explosion, inflammable, liquid, nuclear, device,   , large, nuclear, explosion, rise, seemingly, intact, air, reach, high, altitude, glow]          \n",
      "102   [insult]                                                                                                                                                                              \n",
      "4107  [produce, form, labor, bring, forth, exertion, toil, accomplish, originate, effect]                                                                                                   \n",
      "5048  [result, effect, cause, inference, premise]                                                                                                                                           \n",
      "\n",
      "[2240 rows x 11 columns]\n",
      "           word          pos  \\\n",
      "20    off        adverb        \n",
      "3025  superior   adjective     \n",
      "382   on         preposition   \n",
      "4438  domestic   adjective     \n",
      "256   open       adjective     \n",
      "...    ...             ...     \n",
      "3120  calamus    noun          \n",
      "8052  fireball   noun          \n",
      "102   offensive  adjective     \n",
      "4107  work       verb          \n",
      "5048  follow     verb          \n",
      "\n",
      "                                                                           def1  \\\n",
      "20    away from a place                                                           \n",
      "3025  (often followed by `to') above being affected or influenced by              \n",
      "382   touching the surface of sth                                                 \n",
      "4438  of or involving the home or family                                          \n",
      "256   (of a store, business, etc.) available for business or to provide service   \n",
      "...                                                                         ...   \n",
      "3120  perennial marsh plant having swordlike leaves and aromatic roots            \n",
      "8052  a ball of fire (such as the sun or a ball-shaped discharge of lightning)    \n",
      "102   in sports, relating to actions or team members that score points            \n",
      "4107  make something, usually for a specific function                             \n",
      "5048  come as a logical consequence; follow logically                             \n",
      "\n",
      "                                                                                                                                                                                                                                                             def2  \\\n",
      "20    (of food) rotten                                                                                                                                                                                                                                              \n",
      "3025  beyond the power or influence of; too great or firm to be subdued or affected by; -- with .                                                                                                                                                                   \n",
      "382   when (something is, or has been, done)                                                                                                                                                                                                                        \n",
      "4438  remaining much at home; devoted to home duties or pleasures; .                                                                                                                                                                                                \n",
      "256   not kept secret                                                                                                                                                                                                                                               \n",
      "...               ...                                                                                                                                                                                                                                               \n",
      "3120  a species of Acorus (corus calamus), commonly called calamus, or sweet flag. the root has a pungent, aromatic taste, and is used in medicine as a stomachic; the leaves have an aromatic odor, and were formerly used instead of rushes to strew on floors.   \n",
      "8052  a large mass of fire caused by a large explosion, as of inflammable liquids or a nuclear device.  the larger , as of nuclear explosions, rise seemingly intact into the air and may reach high altitudes while still glowing.                                 \n",
      "102   insulting                                                                                                                                                                                                                                                     \n",
      "4107  to produce or form by labor; to bring forth by exertion or toil; to accomplish; to originate; to effect;                                                                                                                                                      \n",
      "5048  to result from, as an effect from a cause, or an inference from a premise.                                                                                                                                                                                    \n",
      "\n",
      "      relation  \\\n",
      "20    none       \n",
      "3025  narrower   \n",
      "382   none       \n",
      "4438  broader    \n",
      "256   none       \n",
      "...    ...       \n",
      "3120  narrower   \n",
      "8052  broader    \n",
      "102   none       \n",
      "4107  exact      \n",
      "5048  narrower   \n",
      "\n",
      "                                                                                           processed_1  \\\n",
      "20    (away, from, a, place)                                                                             \n",
      "3025  ((, often, followed, by, `, to, ', ), above, being, affected, or, influenced, by)                  \n",
      "382   (touching, the, surface, of, sth)                                                                  \n",
      "4438  (of, or, involving, the, home, or, family)                                                         \n",
      "256   ((, of, a, store, ,, business, ,, etc, ., ), available, for, business, or, to, provide, service)   \n",
      "...                                                                                                ...   \n",
      "3120  (perennial, marsh, plant, having, swordlike, leaves, and, aromatic, roots)                         \n",
      "8052  (a, ball, of, fire, (, such, as, the, sun, or, a, ball, -, shaped, discharge, of, lightning, ))    \n",
      "102   (in, sports, ,, relating, to, actions, or, team, members, that, score, points)                     \n",
      "4107  (make, something, ,, usually, for, a, specific, function)                                          \n",
      "5048  (come, as, a, logical, consequence, ;, follow, logically)                                          \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                       processed_2  \\\n",
      "20    ((, of, food, ), rotten)                                                                                                                                                                                                                                                                                                       \n",
      "3025  (beyond, the, power, or, influence, of, ;, too, great, or, firm, to, be, subdued, or, affected, by, ;, --, with, .)                                                                                                                                                                                                            \n",
      "382   (when, (, something, is, ,, or, has, been, ,, done, ))                                                                                                                                                                                                                                                                         \n",
      "4438  (remaining, much, at, home, ;, devoted, to, home, duties, or, pleasures, ;, .)                                                                                                                                                                                                                                                 \n",
      "256   (not, kept, secret)                                                                                                                                                                                                                                                                                                            \n",
      "...                   ...                                                                                                                                                                                                                                                                                                            \n",
      "3120  (a, species, of, Acorus, (, corus, calamus, ), ,, commonly, called, calamus, ,, or, sweet, flag, ., the, root, has, a, pungent, ,, aromatic, taste, ,, and, is, used, in, medicine, as, a, stomachic, ;, the, leaves, have, an, aromatic, odor, ,, and, were, formerly, used, instead, of, rushes, to, strew, on, floors, .)   \n",
      "8052  (a, large, mass, of, fire, caused, by, a, large, explosion, ,, as, of, inflammable, liquids, or, a, nuclear, device, .,  , the, larger, ,, as, of, nuclear, explosions, ,, rise, seemingly, intact, into, the, air, and, may, reach, high, altitudes, while, still, glowing, .)                                                \n",
      "102   (insulting)                                                                                                                                                                                                                                                                                                                    \n",
      "4107  (to, produce, or, form, by, labor, ;, to, bring, forth, by, exertion, or, toil, ;, to, accomplish, ;, to, originate, ;, to, effect, ;)                                                                                                                                                                                         \n",
      "5048  (to, result, from, ,, as, an, effect, from, a, cause, ,, or, an, inference, from, a, premise, .)                                                                                                                                                                                                                               \n",
      "\n",
      "                                                                                          lemmatized_1  \\\n",
      "20    (away, from, a, place)                                                                             \n",
      "3025  ((, often, follow, by, `, to, ', ), above, be, affect, or, influence, by)                          \n",
      "382   (touch, the, surface, of, sth)                                                                     \n",
      "4438  (of, or, involve, the, home, or, family)                                                           \n",
      "256   ((, of, a, store, ,, business, ,, etc, ., ), available, for, business, or, to, provide, service)   \n",
      "...                                                                                                ...   \n",
      "3120  (perennial, marsh, plant, have, swordlike, leave, and, aromatic, root)                             \n",
      "8052  (a, ball, of, fire, (, such, as, the, sun, or, a, ball, -, shape, discharge, of, lightning, ))     \n",
      "102   (in, sport, ,, relate, to, action, or, team, member, that, score, point)                           \n",
      "4107  (make, something, ,, usually, for, a, specific, function)                                          \n",
      "5048  (come, as, a, logical, consequence, ;, follow, logically)                                          \n",
      "\n",
      "                                                stopwords_removed_1  \\\n",
      "20    [away, place]                                                   \n",
      "3025  [follow, `, affect, influence]                                  \n",
      "382   [touch, surface, sth]                                           \n",
      "4438  [involve, home, family]                                         \n",
      "256   [store, business, etc, available, business, provide, service]   \n",
      "...                                                             ...   \n",
      "3120  [perennial, marsh, plant, swordlike, leave, aromatic, root]     \n",
      "8052  [ball, fire, sun, ball, shape, discharge, lightning]            \n",
      "102   [sport, relate, action, team, member, score, point]             \n",
      "4107  [usually, specific, function]                                   \n",
      "5048  [come, logical, consequence, follow, logically]                 \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                             lemmatized_2  \\\n",
      "20    ((, of, food, ), rotten)                                                                                                                                                                                                                                                                                              \n",
      "3025  (beyond, the, power, or, influence, of, ;, too, great, or, firm, to, be, subdue, or, affect, by, ;, --, with, .)                                                                                                                                                                                                      \n",
      "382   (when, (, something, be, ,, or, have, be, ,, do, ))                                                                                                                                                                                                                                                                   \n",
      "4438  (remain, much, at, home, ;, devote, to, home, duty, or, pleasure, ;, .)                                                                                                                                                                                                                                               \n",
      "256   (not, keep, secret)                                                                                                                                                                                                                                                                                                   \n",
      "...                   ...                                                                                                                                                                                                                                                                                                   \n",
      "3120  (a, species, of, Acorus, (, corus, calamus, ), ,, commonly, call, calamus, ,, or, sweet, flag, ., the, root, have, a, pungent, ,, aromatic, taste, ,, and, be, use, in, medicine, as, a, stomachic, ;, the, leave, have, an, aromatic, odor, ,, and, be, formerly, use, instead, of, rush, to, strew, on, floor, .)   \n",
      "8052  (a, large, mass, of, fire, cause, by, a, large, explosion, ,, as, of, inflammable, liquid, or, a, nuclear, device, .,   , the, large, ,, as, of, nuclear, explosion, ,, rise, seemingly, intact, into, the, air, and, may, reach, high, altitude, while, still, glow, .)                                              \n",
      "102   (insult)                                                                                                                                                                                                                                                                                                              \n",
      "4107  (to, produce, or, form, by, labor, ;, to, bring, forth, by, exertion, or, toil, ;, to, accomplish, ;, to, originate, ;, to, effect, ;)                                                                                                                                                                                \n",
      "5048  (to, result, from, ,, as, an, effect, from, a, cause, ,, or, an, inference, from, a, premise, .)                                                                                                                                                                                                                      \n",
      "\n",
      "                                                                                                                                                                       stopwords_removed_2  \n",
      "20    [food, rotten]                                                                                                                                                                        \n",
      "3025  [power, influence, great, firm, subdue, affect]                                                                                                                                       \n",
      "382   []                                                                                                                                                                                    \n",
      "4438  [remain, home, devote, home, duty, pleasure]                                                                                                                                          \n",
      "256   [secret]                                                                                                                                                                              \n",
      "...        ...                                                                                                                                                                              \n",
      "3120  [species, Acorus, corus, calamus, commonly, calamus, sweet, flag, root, pungent, aromatic, taste, use, medicine, stomachic, leave, aromatic, odor, use, instead, rush, strew, floor]  \n",
      "8052  [large, mass, fire, cause, large, explosion, inflammable, liquid, nuclear, device,   , large, nuclear, explosion, rise, seemingly, intact, air, reach, high, altitude, glow]          \n",
      "102   [insult]                                                                                                                                                                              \n",
      "4107  [produce, form, labor, bring, forth, exertion, toil, accomplish, originate, effect]                                                                                                   \n",
      "5048  [result, effect, cause, inference, premise]                                                                                                                                           \n",
      "\n",
      "[2240 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def first_word_same(row):\n",
    "    return row['def1'].split(' ')[0].lower() == row['def2'].split(' ')[0].lower()\n",
    "\n",
    "\n",
    "def difference_in_length(row):\n",
    "    return abs(len(row['def1'].split(' ')) - len(row['def2'].split(' ')[0]))\n",
    "\n",
    "\n",
    "def jaccard_sim(row):\n",
    "    return get_jaccard_sim(row['def1'], row['def2'])\n",
    "\n",
    "\n",
    "def cosine(row):\n",
    "    return get_cosine_sim(row['def1'], row['def2'])[0, 1]\n",
    "\n",
    "\n",
    "\n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    vectorizer = CountVectorizer(text)\n",
    "    vectorizer.fit(text)\n",
    "    return vectorizer.transform(text).toarray()\n",
    "\n",
    "def pos_count(column):\n",
    "    pos = []\n",
    "    \n",
    "    for token in column:\n",
    "        pos.append(token.pos)\n",
    "    return list(set(pos))\n",
    "        \n",
    "    \n",
    "def diff_pos_count(row):\n",
    "    pos_def1 = pos_count(row['processed_1'])\n",
    "    pos_def2 = pos_count(row['processed_2'])\n",
    "    \n",
    "    return  len(pos_def1) - len(pos_def2)\n",
    "    \n",
    "def tfidf(col1, col2):\n",
    "    tfidf_holder = pd.DataFrame()\n",
    "    tfidf_holder['col1'] = col1\n",
    "    tfidf_holder['col2'] = col2\n",
    "\n",
    "    values = join_definitions(col1, col2)\n",
    "    tfidf_holder['tfidf_1'], tfidf_holder['tfidf_2'] = tfidf_vectors(values)\n",
    "\n",
    "    return tfidf_holder.apply(lambda row: cosine_similarity([row['tfidf_1'], row['tfidf_2']])[0, 1], axis=1)\n",
    "\n",
    "\n",
    "def convert_to_text(token_array):\n",
    "    seperator = ' '\n",
    "    return seperator.join(token_array)\n",
    "\n",
    "\n",
    "def join_definitions(col1, col2):\n",
    "    joined_definitions = pd.concat([col1, col2])\n",
    "    return joined_definitions.apply(lambda tokens: ' '.join(tokens)).values.T\n",
    "\n",
    "\n",
    "def tfidf_vectors(values):\n",
    "    tfidf_matrix = TfidfVectorizer().fit_transform(values)\n",
    "\n",
    "    split_index = int(tfidf_matrix.get_shape()[0] / 2)\n",
    "    tfidf_array = tfidf_matrix.todense()\n",
    "\n",
    "    df_result1 = [row.tolist()[0] for row in tfidf_array[0:split_index]]\n",
    "    df_result2 = [row.tolist()[0] for row in tfidf_array[split_index:]]\n",
    "\n",
    "    return df_result1, df_result2\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(data, feats_to_scale):\n",
    "    def sentence2vec(row):\n",
    "        return row['processed_1'].similarity(row['processed_2'])\n",
    "\n",
    "    feat = pd.DataFrame()\n",
    "    print(data)\n",
    "    feat['similarities'] = data.apply(lambda row: sentence2vec(row), axis=1)\n",
    "    feat['first_word_same'] = data.apply(lambda row: first_word_same(row), axis=1)\n",
    "    feat['len_diff'] = data.apply(lambda row: difference_in_length(row), axis=1)\n",
    "    feat['jaccard'] = data.apply(lambda row: jaccard_sim(row), axis=1)\n",
    "    feat['cos'] = data.apply(lambda row: cosine(row), axis=1)\n",
    "    feat['diff_pos_count'] = data.apply(lambda row: diff_pos_count(row), axis = 1)\n",
    "    feat['tfidf_similarity'] = tfidf(data['stopwords_removed_1'], data['stopwords_removed_2'])\n",
    "\n",
    "    for c_name in feats_to_scale:\n",
    "        feat[c_name] = preprocessing.scale(feat[c_name])\n",
    "\n",
    "    return feat\n",
    "\n",
    "\n",
    "def get_cosine_sim(*strs):\n",
    "    vectors = [t for t in get_vectors(*strs)]\n",
    "    return cosine_similarity(vectors)\n",
    "\n",
    "\n",
    "def get_jaccard_sim(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "\n",
    "features = extract_features(balanced_en_data, ['similarities', 'len_diff','diff_pos_count'])\n",
    "features_undersampled = extract_features(balanced_en_data, ['similarities', 'len_diff','diff_pos_count'])\n",
    "#features['diff_pos_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#sns.pairplot(features,hue='class',palette='Dark2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarities</th>\n",
       "      <th>first_word_same</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>cos</th>\n",
       "      <th>diff_pos_count</th>\n",
       "      <th>tfidf_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>-1.360503</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.893043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560154</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>0.858271</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.147546</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.421350</td>\n",
       "      <td>-0.804442</td>\n",
       "      <td>0.438204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>-1.412957</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.893043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.122144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4438</td>\n",
       "      <td>0.666514</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.644544</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>0.219005</td>\n",
       "      <td>0.375248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>-1.089819</td>\n",
       "      <td>False</td>\n",
       "      <td>1.094948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.607049</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.116266</td>\n",
       "      <td>False</td>\n",
       "      <td>0.846449</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.228934</td>\n",
       "      <td>-2.169038</td>\n",
       "      <td>0.258892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8052</td>\n",
       "      <td>0.940398</td>\n",
       "      <td>True</td>\n",
       "      <td>2.088944</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.415775</td>\n",
       "      <td>-0.122144</td>\n",
       "      <td>0.050839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>-3.391493</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.644544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.265900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4107</td>\n",
       "      <td>0.275805</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901304</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5048</td>\n",
       "      <td>0.623860</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100953</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.089087</td>\n",
       "      <td>0.219005</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      similarities  first_word_same  len_diff   jaccard       cos  \\\n",
       "20   -1.360503      False           -0.893043  0.000000  0.000000   \n",
       "3025  0.858271      False           -0.147546  0.083333  0.421350   \n",
       "382  -1.412957      False           -0.893043  0.000000  0.000000   \n",
       "4438  0.666514      False           -0.644544  0.133333  0.384900   \n",
       "256  -1.089819      False            1.094948  0.000000  0.000000   \n",
       "...        ...        ...                 ...       ...       ...   \n",
       "3120  0.116266      False            0.846449  0.069767  0.228934   \n",
       "8052  0.940398      True             2.088944  0.162162  0.415775   \n",
       "102  -3.391493      False           -0.644544  0.000000  0.000000   \n",
       "4107  0.275805      False            0.100953  0.000000  0.000000   \n",
       "5048  0.623860      False            0.100953  0.117647  0.089087   \n",
       "\n",
       "      diff_pos_count  tfidf_similarity  \n",
       "20    0.560154        0.000000          \n",
       "3025 -0.804442        0.438204          \n",
       "382  -0.122144        0.000000          \n",
       "4438  0.219005        0.375248          \n",
       "256   2.607049        0.000000          \n",
       "...        ...             ...          \n",
       "3120 -2.169038        0.258892          \n",
       "8052 -0.122144        0.050839          \n",
       "102   2.265900        0.000000          \n",
       "4107  0.901304        0.000000          \n",
       "5048  0.219005        0.000000          \n",
       "\n",
       "[2240 rows x 7 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_data(df_features, labels):\n",
    "    data_holder = {'nltk': {}, 'pd': {}}\n",
    "\n",
    "    #features_nltk = convert_to_nltk_dataset(df_features, labels)\n",
    "    #data_holder['nltk']['trainset'], data_holder['nltk']['testset'] = split_data(features_nltk)\n",
    "    data_holder['pd']['x_trainset'], data_holder['pd']['x_testset'] = split_data(df_features)\n",
    "    data_holder['pd']['y_trainset'], data_holder['pd']['y_testset'] = split_data(labels)\n",
    "\n",
    "    return data_holder\n",
    "\n",
    "\n",
    "def convert_to_nltk_dataset(feats, labels):\n",
    "    converted = []\n",
    "    for index, row in feats.iterrows():\n",
    "        converted.append((row.to_dict(), labels[index]))\n",
    "    return converted\n",
    "\n",
    "\n",
    "def split_data(featuresets):\n",
    "    f = int(len(featuresets) / 5)\n",
    "    return featuresets[f:], featuresets[:f]\n",
    "\n",
    "all_train_and_testset = prepare_data(features, balanced_en_data['relation'])\n",
    "undersampled_train_and_testset = prepare_data(features_undersampled, balanced_en_data_undersampled['relation'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, with_testset=False):\n",
    "    #train_and_test_classifiers(data['nltk']['trainset'], data['nltk']['testset'])\n",
    "    trained_models = train_models_sklearn(data['pd']['x_trainset'],\n",
    "                                          data['pd']['y_trainset'])\n",
    "    cross_val_models(trained_models, data['pd']['x_trainset'],\n",
    "                     data['pd']['y_trainset'])\n",
    "\n",
    "    if with_testset:\n",
    "        compare_on_testset(trained_models, data['pd']['x_testset'],\n",
    "                           data['pd']['y_testset'])\n",
    "\n",
    "        \n",
    "\n",
    "def cross_val_models(models, x_train, y_train):\n",
    "    for estimator in models:\n",
    "        run_cv_with_dataset(estimator, x_train, y_train)\n",
    "\n",
    "        \n",
    "#def train_and_test_classifiers(train_set, test_set):\n",
    "    #decision_tree = nltk.DecisionTreeClassifier.train(train_set)\n",
    "    #naive_bayes = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    #metrics([decision_tree, naive_bayes], test_set)\n",
    "    # naive_bayes.show_most_informative_features(5)\n",
    "\n",
    "    # quite slow\n",
    "    # max_ent = nltk.MaxentClassifier.train(train_set, trace=-1)\n",
    "    # print(nltk.classify.accuracy(max_ent, test_set))\n",
    "    # max_ent.show_most_informative_features(5)\n",
    "    # print('\\n')\n",
    "\n",
    "    \n",
    "def run_cv_with_dataset(model, trainset, y_train):\n",
    "    scores = cross_val_score(model, trainset, y_train, cv=5)\n",
    "    print('Cross validation scores for model' + model.__class__.__name__ + '\\n')\n",
    "    print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2) + '\\n')\n",
    "\n",
    "        \n",
    "def train_models_sklearn(x_train, y_train):\n",
    "    lr = {'estimator': LogisticRegression(), 'parameters': {}}\n",
    "    svm_model = {\n",
    "        'estimator': SVC(),\n",
    "        'parameters': {\n",
    "            'C': [3, 5, 10],\n",
    "            'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        }\n",
    "    }\n",
    "    rf = {\n",
    "        'estimator': RandomForestClassifier(),\n",
    "        'parameters': {\n",
    "            'bootstrap': [True],\n",
    "            'max_depth': [2, 3, 5, 7, 10],\n",
    "            'max_features': [2, 3],\n",
    "            'min_samples_leaf': [3, 4, 5],\n",
    "            'min_samples_split': [2, 5, 8, 10, 12],\n",
    "            'n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    }\n",
    "    dt = {'estimator': DecisionTreeClassifier(), 'parameters': {}}\n",
    "\n",
    "    models = {'unscaled': [svm_model,rf]}\n",
    "\n",
    "    tuned_models = tune_hyperparams(models, x_train, y_train)\n",
    "\n",
    "    return tuned_models\n",
    "\n",
    "\n",
    "def tune_hyperparams(estimators, x_train, y_train):\n",
    "    result = []\n",
    "    for estimator in estimators['unscaled']:\n",
    "        params = estimator['parameters']\n",
    "\n",
    "        scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "        for score in scores:\n",
    "            print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "            print()\n",
    "\n",
    "            grid_search = GridSearchCV(estimator=estimator['estimator'], param_grid=params,\n",
    "                                       scoring='%s_weighted' % score, cv=5,\n",
    "                                       n_jobs=-1, verbose=1)\n",
    "\n",
    "            print(\"Performing grid search...\")\n",
    "            print(\"parameters:\")\n",
    "            pprint(params)\n",
    "            grid_search.fit(x_train, y_train)\n",
    "            print()\n",
    "\n",
    "            means = grid_search.cv_results_['mean_test_score']\n",
    "            stds = grid_search.cv_results_['std_test_score']\n",
    "            print('Precision: \\n')\n",
    "            #for mean, std, parameters in zip(means, stds, grid_search.cv_results_['params']):\n",
    "            #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            #                      % (mean, std * 2, parameters) + '\\n')\n",
    "\n",
    "            print(\"Best score: %0.3f\" % grid_search.best_score_ + '\\n')\n",
    "            print(\"Best parameters set:\\n\")\n",
    "            best_parameters = grid_search.best_estimator_.get_params()\n",
    "            for param_name in sorted(params.keys()):\n",
    "                print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]) + '\\n')\n",
    "\n",
    "            result.append(grid_search.best_estimator_)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'C': [3, 5, 10], 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    3.4s finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.460\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tC: 3\n",
      "\n",
      "\tkernel: 'rbf'\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'C': [3, 5, 10], 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.8s finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.579\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tC: 3\n",
      "\n",
      "\tkernel: 'rbf'\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'C': [3, 5, 10], 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.9s finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.511\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tC: 3\n",
      "\n",
      "\tkernel: 'rbf'\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  1.2min finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.507\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2075 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.576\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 5\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 10\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  1.1min finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.511\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 5\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 12\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelSVC\n",
      "\n",
      "Accuracy: 0.5787 (+/- 0.0463)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelSVC\n",
      "\n",
      "Accuracy: 0.5787 (+/- 0.0463)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelSVC\n",
      "\n",
      "Accuracy: 0.5787 (+/- 0.0463)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5669 (+/- 0.0364)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5688 (+/- 0.0509)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5737 (+/- 0.0500)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(all_train_and_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      similarities  first_word_same  len_diff   jaccard       cos  \\\n",
      "429   0.217786      False            1.591946  0.000000  0.000000   \n",
      "7507  0.707387      False            3.082939  0.111111  0.134840   \n",
      "7274  1.187363      False            1.343447  0.076923  0.505076   \n",
      "5506  1.115411      False            2.834440  0.086957  0.175682   \n",
      "2806 -0.830424      False           -0.893043  0.000000  0.000000   \n",
      "...        ...        ...                 ...       ...       ...   \n",
      "3120  0.116266      False            0.846449  0.069767  0.228934   \n",
      "8052  0.940398      True             2.088944  0.162162  0.415775   \n",
      "102  -3.391493      False           -0.644544  0.000000  0.000000   \n",
      "4107  0.275805      False            0.100953  0.000000  0.000000   \n",
      "5048  0.623860      False            0.100953  0.117647  0.089087   \n",
      "\n",
      "      diff_pos_count  tfidf_similarity  \n",
      "429   1.583602        0.000000          \n",
      "7507  1.583602        0.178606          \n",
      "7274 -0.463293        0.253634          \n",
      "5506  0.560154        0.000000          \n",
      "2806  0.560154        0.000000          \n",
      "...        ...             ...          \n",
      "3120 -2.169038        0.258892          \n",
      "8052 -0.122144        0.050839          \n",
      "102   2.265900        0.000000          \n",
      "4107  0.901304        0.000000          \n",
      "5048  0.219005        0.000000          \n",
      "\n",
      "[1792 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/yellowbrick/features/rankd.py:216: YellowbrickWarning: RankD plots may be clipped when using matplotlib v3.1.1, upgrade to matplotlib v3.1.2 or later to fix the plots.\n",
      "  warnings.warn(msg, YellowbrickWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAGOCAYAAAAO6NDxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeVyU5fo/8M8MDCADHkUkNUUBI1REBDU5KeZ2NKUsDQUV1zJSUsGFxV0R3NAK0nI9hhvikqW2qKm44IYi4C6SYpagpsIQMMM8vz/8Od84uAzE8MAzn/frNa/jPNt9PUyHubju+7lvmSAIAoiIiMjoyMUOgIiIiMTBJICIiMhIMQkgIiIyUkwCiIiIjBSTACIiIiPFJICIiMhImYodANE/cfv2bfTs2RPOzs66bYIgYNiwYfjggw9EjEw/z4q/oKAADRo0QFRUFJo0aVKh6+7YsQM//fQTvv7661LbDxw4gOTkZEyfPv0fxf0y+fn5+PDDD5GXl4cJEybgP//5j25fSUkJli9fjl9++QUFBQXo0qULwsPDIZPJytzD/Pnz0bhx41Lbx48fj+7du1corri4OLi4uKBHjx4VOp9IapgEUI1nYWGBXbt26d7fvXsXPj4+cHV1hYuLi4iR6ed/4xcEAZGRkVi2bBmWLl1aqW117969wl+g5XHp0iXcv38f+/btK7Pvm2++walTp7B582bI5XIMHToUe/fuRd++fcsc265duzKJzD9x8uRJNG/evNKuR1TTMQkgyXnllVfQtGlT/Prrr3BxcUFiYiI2b94MrVaLOnXqYMaMGXByckJWVhbmzp0LlUqF3NxcuLi44LPPPoO5uTlcXV3RvXt3XL58GUuWLMHBgwexb98+KBQK1K1bF9HR0bCzs8OZM2ewaNEi/PXXX1AoFJg4cSK8vb2xY8cO7Nu3D3K5HDdv3oSFhQUWLlwIJyenl8ZfVFSEnJwc2NraAsAL42zdujXGjBmDY8eOIScnBx9++CEGDx5c6no//vgjlixZgpUrVyI1NVVXIQgICIC7uzvOnj2L33//HV5eXpg3bx7kcjl27NiBlStXwsLCAh07dsQ333yDixcvlol1//79iIuLg1arhVKpRHh4OKysrBAREYG7d++iX79+SEhIgIWFhe6cb7/9FqGhobptsbGxUCgU5f6cy/u5btu2DRkZGVi0aBFMTExw4MABvPbaaxg9ejQAICwsTPe+W7ducHNzw5UrVxASEgI3NzfMnTsXv//+O9RqNfr27YvAwEBoNBrMmzcPZ8+ehUKhQOPGjREdHQ2lUlnu+yEShUBUg2VnZwvu7u6ltp09e1Zo3769cOfOHeHkyZPC4MGDhYKCAkEQBOHIkSNC7969BUEQhAULFgjffvutIAiCUFxcLPj4+Ag//vijIAiC4OzsLOzcuVMQBEG4c+eO4OHhIRQVFQmCIAhr1qwR9u3bJzx48EDw8vISUlNTBUEQhKtXrwodOnQQbt26JWzfvl3w9PQUfv/9d0EQBGHu3LnC1KlTnxm/i4uL8O677wo+Pj6Cl5eX0Lt3b2Hp0qVCfn6+XnHGx8cLgiAI6enpgqurq1BYWChs375dGDNmjPD9998Lffv2Fe7cuSMIgqDbLgiCMHToUGH8+PFCSUmJkJeXJ3Tq1ElITk4Wrl27Jnh5eelij42NFZydncvEfv36deHf//63cOvWLUEQBOH48ePCm2++KeTl5QknTpwQ+vbt+8zPzM3NTVi/fr0wbNgwwcfHR1i6dKmg0WjKHLd9+3bBw8NDePfdd3WvGTNmCIIgVPhzHTp0qPDDDz8IgiAIoaGhwurVq3Xt/f19165dhbi4ON2+gIAA4cCBA4IgCEJhYaEQEBAg7NmzRzh9+rTQu3dvQavVCoIgCIsWLRJSUlKeed9E1RErAVTjFRYWol+/fgCe9DfXrVsXixcvRsOGDREfH4+bN2/Cz89Pd/zjx4/x8OFDTJkyBceOHcOqVavw66+/IicnBwUFBbrj2rVrB+BJZcHFxQXvv/8+vL294e3tDS8vLxw+fBj29vZo06YNAOC1116Dh4cHTp06BZlMhlatWqFBgwYAgJYtWz6zNA6U7g44cuQIpkyZgq5du+r+mnxZnE/L+61atUJxcbFuX3p6Oo4cOYKIiAg0bNjwmW137doVcrkcVlZWaNq0KR49eoTLly/jzTff1MU+dOhQxMbGljn3xIkT6Nixo27cgpeXF2xsbJCRkVGmf//vNBoNzp8/j1WrVqG4uBiffPIJ4uPjMWLEiDLHPq874NChQxX+XPX19PMvKCjA6dOn8ejRI3z++ee6bZcvX0anTp1gYmICX19fdOrUCb169YKbm1u52yISC5MAqvH+t0/977RaLfr164cpU6bo3ufk5OBf//oXgoODUVJSgrfffhtvvfUWfv/9dwh/W0rD0tISACCXy7Fhwwakp6cjOTkZUVFR6Ny5M9q1a1fmy04QBGg0GigUilIlcJlMVuraz9O5c2eMHDkSEyZMwJ49e2BlZYWQkJAXxmlubq5r42kMAGBtbY2YmBhMnDgRb731VpkBdk9/dv8bo4mJSanrm5iYPPdn+6L7fx47Ozv07dsXZmZmMDMzQ+/evXH69OmX/WjKtF3Rz/V/7/cptVpdav/Tz1+r1UIQBGzZsgW1atUCADx48ADm5uZQKpXYtWsXzp49ixMnTmDixIkYPXo0hgwZUq77IRILHxEkSevUqRP27NmDnJwcAMDmzZsxfPhwAMDRo0cxbtw49OnTBwBw/vx5lJSUlLnG5cuX4ePjAycnJ3z88ccYMWIE0tPT4e7ujhs3biAtLQ0AcO3aNZw+fRodOnT4RzGPGjUKSqUSX3zxRbni/F/NmjWDl5cXAgICEBoaCq1Wq1f7nTp1QnJyMu7evQvgSd/7s3h5eeHo0aPIzs4GACQnJ+P333/XVUaep1evXvjuu++g1WqhVqtx8OBBtG7dWq/Y/h5jRT5XExMTaDQaAEDdunWRkZEB4Mlg0lOnTj2zLSsrK7i7u2PdunUAnlQc/P39ceDAARw8eBAjRoxA27Zt8emnn+K9997TXZOoJmAlgCStU6dO+OijjzBq1CjIZDJYWVkhLi4OMpkMwcHBGDduHCwtLWFlZYX27dvj1q1bZa7h4uKCt99+GwMGDIClpSUsLCwwffp02NjY4PPPP8e8efNQWFgImUyG6OhoODg44Ny5cxWOWaFQYMaMGfjwww/xwQcf6B3n8wQGBuKXX37B6tWrdYMNX8TBwQHh4eEYPXo0zMzM0KJFC91fwH/XvHlzzJo1C0FBQSgpKYGFhQW++uorWFtbv/D6EydOxJIlS+Dj44OSkhL8+9//1n2B66uin2u3bt2wdOlSqNVqBAQEYPLkyejVqxcaN26Mjh07Pre9JUuWYN68eXjnnXdQXFwMHx8fvPvuuygpKUFSUhJ8fHxgaWmJf/3rX5g3b1657oVITDJBnxolERmN7Oxs7Nq1C2PHjoVcLsfPP/+MVatWPbciQEQ1FysBRFRKgwYNkJOTg3feeQcmJiawtrZGVFSU2GERkQGwEkBERFQNnD9/HkuWLEF8fHyp7b/88gu+/PJLmJqaYsCAARg4cCAKCwsxZcoU3L9/H0qlEgsXLoSNjU252xRtYOClS5cQFxen17ErV65EWloaduzYgSVLluh1Tm5uLmbPng0AOH36NC5fvgwACAoKqlC8REREhrJq1SpMnz4dRUVFpbar1WpER0dj7dq1iI+PR0JCAnJzc7F582Y4Oztj06ZNeO+997B8+fIKtStad0CLFi3QokULvY4dM2YMAOD69et6X79+/fq6JGD79u3o06cPXFxc9E489KHVaqFSqaBQKF74XDQRERmeIAhQq9VQKpWQy2vWw2/29vaIjY3F1KlTS23PzMyEvb09/vWvfwEAPD09cebMGaSkpODDDz8EAHh7e1f/JCArKwvh4eEwNTWFiYkJBgwYgIMHD2LZsmXo2bMn2rZti5s3b6Jjx47Iy8tDWloaHBwcsHjxYoSFheke93kqJiYGGRkZUKlUcHJyQnR0NGJjY3Hu3DkUFBRg/vz5CA8Px8yZM3HkyBFcuHABzZs3h6+vL44dO4YrV64gMjISAFCnTh1ERUVBrVZj4sSJuv+Q5syZg9dff/2596RSqXD16lWD/tyIiKh8nJ2dX/qUSkUEyppV6LyvhF9fekyvXr1w+/btMtvz8/NL3YtSqUR+fn6p7UqlEnl5eRWKrcqSgOPHj6NVq1YICwvDmTNnkJmZqdv322+/Yf369ahfvz46dOiAxMREzJgxA927d8fjx4/LXCs/Px+1a9fGunXroNVq0bdvX90zzY6Ojpg+fbruh+nq6orOnTujT58+aNSoke4aM2bMQFRUFJo3b47ExESsXr0abdu21U2wcv36deTn57/wnp5OiOLs7AwzM7N//DMiIqKKKy4uxtWrVyu0FoU+TEQo+FpZWUGlUuneq1QqWFtbl9quUqlQu3btCl2/ypKADz74AKtWrcKHH34Ia2trvPnmm7p9derU0X1BW1pa6lb5sra2LtM/AjyZIe3BgwcICQmBpaUlCgoKdLN9OTg46BVPZmYm5syZA+BJn4uDgwO8vb3x66+/YuzYsTA1NcUnn3zywms87QIwMzPTzdpGRETiMlT3rIkI3b5OTk64efMmHj58CEtLS5w5cwajR4/GnTt3cPjwYbi5uSEpKQmenp4Vun6VJQEHDhyAp6cngoKCsHv3bixdulQ3s1h5P7CkpCT8/vvv+Oyzz/DgwQPs27dPN/3ns/qBnjVlq4ODAxYuXIhGjRohJSUFubm5OHnyJOzs7LB27VqcO3cOS5cuLTNKk4iIyNC+//57FBQUYNCgQQgLC8Po0aMhCAIGDBiAV155Bf7+/ggNDYW/vz8UCgViYmIq1E6VJQGurq6YMmUKYmNjIZfLERAQoJtutbzc3NywfPlyDBw4EGZmZmjSpIlu+tBnadOmDZYsWVJq7vTZs2cjNDRUN53o/PnzUadOHQQHB2P9+vWQy+UYN25cheIjIiLpMXR3QOPGjbF161YAwDvvvKPb3q1bN3Tr1q3UsbVq1dJNLf5PcJ6Af6CoqAgZGRlwdXVldwARkcgM/Tt5ssKxQuctUd+o5EgqD2cMJCIi0oMYAwMNjUkAERGRHsQYGGhoTAKIiIj0wEoAERGRkZJiJaBmzatIRERElYaVACIiIj1I8a9mJgFERER6kGJ3AJMAIiIiPXBgIBERkZFiJYCIiMhIsRJARERkpKRYCZDiYEciIiLSAysBREREemB3ABERkZGSYncAkwAiIiI9sBJARERkpJgEEBERGSl2BxARERkpKVYC+IggERGRkWIlgIiISA/sDiAiIjJSUuwOYBJARESkB1YCiIiIjBQrAUREREaKlQB6poLv4qDR/CV2GFVC6T9d7BCIiEQhl2ASwEcEiYiIjBQrAURERHqQSXBQAJMAIiIiPciZBBARERknmYlhetC1Wi1mz56NK1euwMzMDJGRkWjatCkA4NKlS4iKitIdm5qaii+//BJubm7o1asXnJ2dAQA9evTA8OHDy902kwAiIiI9GKo7YP/+/SguLkZCQgJSU1OxYMECrFixAgDQokULxMfHAwB++OEH2NnZwdvbG8ePH4ePjw9mzJjxj9pmEkBERKQHQ3UHpKSkoHPnzgAAd3d3ZGRklDmmoKAAsbGx2LBhAwAgIyMDFy5cwNChQ2FjY4Pp06fDzs6u3G3z6QAiIiIR5efnw8rKSvfexMQEGo2m1DHbtm1D7969YWNjAwBwdHTE+PHjsWHDBvTo0QORkZEVaptJABERkR5kcnmFXi9jZWUFlUqle6/VamFqWrpQ//3338PX11f3vmPHjnjjjTcAAD179sTFixcrdE9MAoiIiPQgN5FV6PUyHh4eSEpKAvBk4N/TwX5P5eXlobi4GA0bNtRtmz59On766ScAQHJyMlq1alWhe+KYACIiIj0YamBgz549cezYMfj5+UEQBERFRWHdunWwt7dH9+7dkZWVhVdffbXUOZMmTUJERAQ2b96MWrVqVbg7QCYIglAZN2GMioqKkJGRAccbh2DGaYOJiET19Heyq6srzM3NK/36h9p5Vei8t84kV3IklYeVACIiIj1wsiAiIiIjJZNLLwngwEAiIiIjxUoAERGRHuQGmjZYTEwCiIiI9MBVBImIiIwUkwAiIiIjxe4AIiIiI8VKABERkZGS8xFBIiIikgpWAoiIiPQg45gAIiIi48Rpg4mIiIwUBwYSEREZKXYHEBERGSl2BxARERkpriIokh07dmDJkiWVes2ioiJ069YNADB//nzcuXMHjx8/xqBBgzBq1ChkZ2ejX79+CA0NrdR2iYiIqgtWAgBMmzYNAHDmzBnY2dkhNjYWu3btgpeXF8LCwkSOjoiIqgNOGyyy+Ph47N69GzKZDH369MGwYcMQFhYGMzMz/Pbbb8jJycGCBQvQqlWrZ56vUqkwefJkPH78GPb29rrtAQEBmDZtGubNm4ecnByEh4fj3LlzKCwshL29PQYPHlxVt0hERNWUFJ8OqDFpTXZ2Nvbu3YtNmzZh06ZN2L9/P27cuAEAaNSoEdasWYOAgAAkJCQ89xo7d+6Es7MzNm7cCD8/v1L7FAoFIiIi0LFjR0RHR2PMmDHw8fFhAkBERACePB1QkVd1VmMqARkZGdBoNBgxYgQA4NGjR7h16xYAoEWLFgCABg0a4OzZs8+9xrVr19C5c2cAQJs2bWBqWmNun4iIRCaTV+8v9IqoMXfk4uKC5s2b45tvvkF8fDz69+8PZ2dnAIBMpl+JxtHREampqQCAixcvQqPRGCxeIiKSFrmJvEKv6qzG/Cns4OCAOnXqwN/fH8XFxXBzc8Mrr7xSrmsMGTIE4eHh8Pf3h6OjIxQKhYGiJSIiqanupf2KkAmCIIgdRE1VVFSEjIwMON44BDPNX2KHUyWU/tPFDoGI6Jme/k52dXWFubl5pV//etDACp3XPG5rJUdSeWpMJaA8Zs+ejczMzDLbV61aBQsLCxEiIiKimk6KlQDJJgFERESVSYoDAyWZBBAREVU2mYmJ2CFUOiYBREREemB3ABERkZGSszuAiIjIOLESQERERJVKq9Vi9uzZuHLlCszMzBAZGYmmTZvq9kdGRuLs2bNQKpUAgOXLl0OtVmPy5MkoLCyEnZ0doqOjUatWrXK3zSSAiIhID4aqBOzfvx/FxcVISEhAamoqFixYgBUrVuj2X7hwAatXr4aNjY1uW2RkJHx8fNC/f3+sXLkSCQkJumn1y0N6tQ0iIiIDkMnlFXq9TEpKim5dG3d3d2RkZOj2abVa3Lx5EzNnzoSfnx+2bdtW5hxvb28cP368QvfESgAREZEeDFUJyM/Ph5WVle69iYkJNBoNTE1NUVBQgKFDh2LkyJEoKSnBsGHD4Orqivz8fFhbWwMAlEol8vLyKtQ2kwAiIiI9GCoJsLKygkql0r3XarW6VW5r1aqFYcOG6fr7O3bsiMuXL+vOsbCwgEqlQu3atSvUNrsDiIiI9GCoVQQ9PDyQlJQEAEhNTdWtkAsAv/76KwYPHoySkhKo1WqcPXsWrVq1goeHBw4fPgwASEpKgqenZ4XuiZUAIiIiPRhq2uCePXvi2LFj8PPzgyAIiIqKwrp162Bvb4/u3bvjnXfewcCBA6FQKNCvXz+89tpr+OSTTxAaGoqtW7eibt26iImJqVDbXEXwH+AqgkRE1YehVxHMWTKhQufZTf68kiOpPKwEEBER6YGTBRERERkpJgFERERGiksJExERGSk5lxImIiIyTuwOICIiMlJSTAKkd0dERESkF1YCiIiI9MCBgUREREZKit0BTAIqQc6pi5DnPxI7DINzmjQZ2usnxA6jSsmbdxQ7BCKqJpgEEBERGSl2BxARERkpmZzzBBARERknCSYB0qttEBERkV5YCSAiItIHxwQQEREZJxnXDiAiIjJSEhwTwCSAiIhIH0wCiIiIjBPnCSAiIjJWEqwESC+tISIiIr2wEkBERKQPCVYCmAQQERHpgWMCiIiIjBUrAUREREaKSQAREZFx4oyBRERExkqCYwKkd0dERESkF1YCiIiI9MExAURERMZJZqAkQKvVYvbs2bhy5QrMzMwQGRmJpk2b6vb/97//xZ49ewAAXbp0QVBQEARBgLe3N5o1awYAcHd3x6RJk8rdNpMAIiIifRhoTMD+/ftRXFyMhIQEpKamYsGCBVixYgUAIDs7G9999x0SExMhk8kwePBg9OjRA7Vq1UKrVq3w1Vdf/aO2OSaAiIhIDzK5SYVeL5OSkoLOnTsDePIXfUZGhm5fgwYNsHr1apiYmEAul0Oj0cDc3BwXLlzA3bt3ERAQgI8++gg3btyo0D2xEkBERKQPA3UH5Ofnw8rKSvfexMQEGo0GpqamUCgUsLGxgSAIWLRoEVq2bAkHBwfcu3cPY8aMwdtvv40zZ85gypQp2L59e7nbZhJARESkDwN1B1hZWUGlUunea7VamJr+39dzUVERIiIioFQqMWvWLACAq6srTP7/vAXt2rXD3bt3IQgCZDJZudpmdwAREZGIPDw8kJSUBABITU2Fs7Ozbp8gCBg7dixef/11zJ07V/fFHxcXh/Xr1wMALl++jEaNGpU7AQBYCSAiItKLoWYM7NmzJ44dOwY/Pz8IgoCoqCisW7cO9vb20Gq1OHXqFIqLi3HkyBEAQEhICMaMGYMpU6bg8OHDMDExQXR0dIXaZhJARESkDwONCZDL5Zg7d26pbU5OTrp/p6enP/O8lStX/vO2//EVqkBSUhISEhKqtM3MzEwEBARUaZtERFSNyU0q9qrGakQlwNvbW+wQiIjIyMkkuHZAjUgCduzYgRs3bkAmkyEjIwMqlQpOTk6Ijo7G/fv3ERYWhry8PAiCgIULF8La2rrMNgsLC8yePRtFRUV4+PAhxo0bhx49esDHxwfNmjWDmZkZwsLCMHnyZAiCgPr164t920REVJ1U87/qK6JGJAEAoFarYWtri3Xr1kGr1aJv3764e/cuVq1ahW7dusHf3x/JyclIS0tDWlpamW22trYYOXIk3njjDZw9exaxsbHo0aMHCgoKMHbsWLRs2RILFy6Ej48PBg4ciL1792Lz5s1i3zYREVUXMlYCRCOTyfDgwQOEhITA0tISBQUFUKvVyMrKwgcffAAA8PLyAgDs2rWrzLZr165hxYoV2LZtG2QyGTQaje7aDg4OumP69esH4MkjG0wCiIhIympMEnDy5Ek0bdoUn332GR48eIB9+/ZBEAQ4OTkhPT0dLi4uOH36NA4dOvTMbTdv3oSvry+6dOmC7du3Y+fOnbpry/9/P4+joyPOnTsHFxeX547GJCIiI8VKgHhat26NCxcuYODAgTAzM0OTJk2Qk5ODwMBARERE4LvvvgMAREVFQalUltl2/vx5zJ8/H19//TUaNmyIP//8s0wbEyZMQHBwMPbu3YvGjRtX6f0REVH1JjAJEIdGo0G9evWeOy/ys1ZR+t9tTZo0gY+PT5njfvnlF92/lUplpTx3SUREEiTBJKDa39Hhw4fxzTff4M033xQ7FCIiMmYyWcVe1Vi1rwR06dIFXbp0ETsMIiIydpwngIiIyDhJcUyA9O6IiIiI9MJKABERkT4kWAlgEkBERKQPJgFERERGikkAERGRcZLiwEAmAURERPpgEkBERGSkqvnEPxUhvbSGiIiI9MJKABERkT7YHUBERGScODCQiIjIWHHtACIiIiPFSgAREZGRYhJARERkpCSYBEjvjoiIiEgvrAQQERHpgU8HEBERGSsmAUREREZKgtMGMwkgIiLSBysBRERExslQYwK0Wi1mz56NK1euwMzMDJGRkWjatKlu/9atW7FlyxaYmprik08+QdeuXfHgwQNMnjwZhYWFsLOzQ3R0NGrVqlXutqWX1hARERmCTF6x10vs378fxcXFSEhIwKRJk7BgwQLdvtzcXMTHx2PLli1Ys2YNli5diuLiYixfvhw+Pj7YtGkTWrZsiYSEhArdEisBleCvPwsge6wSOwyD0z66L3YIVWp9z0lih1ClRj+4LHYIREYpJSUFnTt3BgC4u7sjIyNDty8tLQ1t27aFmZkZzMzMYG9vj8uXLyMlJQUff/wxAMDb2xtLly7FiBEjyt02kwAiIiI9CAYaGJifnw8rKyvdexMTE2g0GpiamiI/Px/W1ta6fUqlEvn5+aW2K5VK5OXlVahtJgFERER6EATDXNfKygoq1f9Vk7VaLUxNTZ+5T6VSwdraWrfdwsICKpUKtWvXrlDbHBNARESkB60gVOj1Mh4eHkhKSgIApKamwtnZWbfPzc0NKSkpKCoqQl5eHjIzM+Hs7AwPDw8cPnwYAJCUlARPT88K3RMrAURERHowUCEAPXv2xLFjx+Dn5wdBEBAVFYV169bB3t4e3bt3R0BAAAYPHgxBEBAcHAxzc3N88sknCA0NxdatW1G3bl3ExMRUqG0mAURERHrQGigLkMvlmDt3bqltTk5Oun8PHDgQAwcOLLXf1tYWa9as+cdtMwkgIiLSg2CoQQEi4pgAIiIiI8VKABERkR4M1R0gJiYBREREepBgDsAkgIiISB+sBBARERkpKQ4MZBJARESkB63YARgAkwAiIiI9SLAQwEcEiYiIjBUrAURERHrgwEAiIiIjxYGBRERERooDA4mIiIyUBAsBTAKIiIj0oZVgFsAkgIiISA/SSwH4iCAREZHRYiWAiIhID3xEkIiIyEhJcEgAkwAiIiJ9aCU4KoBJABERkR5YCSAiIjJSHBNARERkpKRYCeAjgkREREbKaCoBhYWFCA8Px507d6BWqxEREYGEhARkZ2ejpKQEI0eORJ8+fbBx40Z8++23kMvl8PDwQGhoqNihExFRNcCBgTXYli1b8Oqrr2LZsmW4evUq9u/fj7p162Lx4sXIz89H//790bFjR+zYsQMzZsyAu7s7Nm3aBI1GA1NTo/kxERHRc7A7oAa7ceMG3N3dAQDOzs7Izc1F+/btAQBWVlZwcnJCdnY2oqOjsWXLFgwdOhR37tyR5NKRRERUflpBqNCrOjOaJMDJyQnp6ekAgJuOUMkAACAASURBVOzsbOzZswdnzpwBAOTn5+Pq1ato3Lgxtm7dijlz5mDDhg24dOkSzp07J2bYRERUTZRoK/aqzoymzu3n54eIiAgMHToUJSUlWL16NTZu3Ah/f38UFRUhKCgI9erVw+uvv44PPvgAdevWxSuvvII2bdqIHToREVUD1f2v+oowmiTA3NwcMTExpba5ubmVOc7X1xe+vr5VFRYREdUQJUwCiIiIyNAKCwsxZcoU3L9/H0qlEgsXLoSNjU2pYxYuXIizZ89Co9Fg0KBBGDhwIB4+fIhevXrB2dkZANCjRw8MHz78ue0wCSAiItJDVXYHbN68Gc7Ozvj000+xZ88eLF++HNOnT9ftP3HiBG7duoWEhAQUFxejb9++6NWrFy5evAgfHx/MmDFDr3aMZmAgERHRP1GVAwNTUlLQuXNnAIC3tzeSk5NL7W/bti2ioqL+L7aSEpiamiIjIwMXLlzA0KFDMX78eOTk5LywHVYCiIiI9GCoSkBiYiLWr19falu9evVgbW0NAFAqlcjLyyu139zcHObm5lCr1QgLC8OgQYOgVCrh6OgIV1dX/Pvf/8Z3332HyMhIfPHFF89tm0kAERGRHgw1MPBZA9KDgoKgUqkAACqVCrVr1y5z3qNHjzB+/Hh06NABH3/8MQCgY8eOqFWrFgCgZ8+eL0wAAHYHEBER6UUrVOxVER4eHjh8+DAAICkpCZ6enqX2FxYWYsSIERgwYADGjRun2z59+nT89NNPAIDk5GS0atXqhe2wEkBERKSHkipcS9jf3x+hoaHw9/eHQqHQPeK+aNEi9O7dG2fPnkV2djYSExORmJgIAIiKisKkSZMQERGBzZs3o1atWoiMjHxhO0wCiIiIqplatWo9s5Q/depUAE/muRkxYsQzz42Pj9e7HSYBREREeuCMgUREREaqRHo5AJMAIiIifbASQEREZKSqcmBgVWESQEREpAcpVgI4TwAREZGRYiWAiIhIDxwYSEREZKSk2B3AJICIiEgPWg4MJCIiMk7sDiAiIjJS7A4gIiIyUoZaSlhMfESQiIjISLESQEREpAcODCQiIjJSHBhIRERkpDgwkJ7JfG4c5KYKscMwvOJssSOoUgNunRU7hCqjUgv47U+V2GFUqVfrKsUOgWoYKQ4MZBJARESkB64iSEREZKSkmATwEUEiIiIjxUoAERGRHqRYCWASQEREpAcmAUREREaKSQAREZGRYhJARERkpJgEEBERGSkpJgF8RJCIiMhIsRJARESkBylWApgEEBER6YFJABERkZHSVGESUFhYiClTpuD+/ftQKpVYuHAhbGxsSh0TGBiIhw8fQqFQwNzcHKtXr8bNmzcRFhYGmUyG1157DbNmzYJc/vyef44JICIi0kOJVqjQqyI2b94MZ2dnbNq0Ce+99x6WL19e5phbt25h8+bNiI+Px+rVqwEA0dHRmDhxIjZt2gRBEHDgwIEXtsMkgIiISA9VmQSkpKSgc+fOAABvb28kJyeX2n/v3j08fvwYgYGB8Pf3x8GDBwEAFy5cQIcOHXTnHT9+/IXtsDuAiIhIDyWCYboDEhMTsX79+lLb6tWrB2trawCAUqlEXl5eqf1qtRqjRo3CsGHD8OjRI/j7+8PNzQ2CIEAmkz33vP/FJICIiEhEvr6+8PX1LbUtKCgIKpUKAKBSqVC7du1S+21tbeHn5wdTU1PUq1cPLVq0QFZWVqn+/2ed97/YHUBERKSHquwO8PDwwOHDhwEASUlJ8PT0LLX/+PHjmDhxIoAnX/bXrl2Do6MjWrZsiZMnT+rOa9eu3QvbYRJARESkh6pMAvz9/XHt2jX4+/sjISEBQUFBAIBFixYhLS0NXbp0QdOmTTFw4ECMHj0aISEhsLGxQWhoKGJjYzFo0CCo1Wr06tXrhe3IBMFAnRxGoKioCBkZGbBs2AxyU4XY4RicU3G22CFUqfw6DmKHUGVUauP7NfBqXaXYIVAle/o72dXVFebm5pV+/RGbzlbovP8O9qjkSCoPxwQQERHpoUSrFTuESsckgIiISA+cMZCIiMhISTEJ4MBAIiIiI8VKABERkR6qcu2AqsIkgIiISA9S7A5gEkBERKQHKSYB5RoTUFRUhG7dumH+/Pm4c+cOHj9+jEGDBmHUqFHIzs5Gv379EBoaaqhYq1RRURESExPFDoOIiKqJqpwsqKpUaGDgtGnT0KhRI1y9ehV2dnZYu3Ytzp49Cy8vLyxcuLCyYxRFbm4ukwAiItKRYhLw0u4AlUqFyZMn4/Hjx7C3twcABAQEYNq0aZg3bx5ycnIQHh6Oc+fOobCwEPb29hg8eHCZ69y+fRsTJkxA/fr1cffuXXh7eyM4OBi3b9/GtGnToNFoIJPJMH36dLi4uCAsLAy3bt1CUVERRo8ejT59+jwzPq1Wi8jISKSlpUGtVuPTTz9Fjx49sGDBAqSkpAAAfHx8MHz4cISFhaFPnz7w9vZGUlIS9u7diwULFuA///kPPDw8kJWVhXr16iE2NhZfffUVrl+/jri4ON10jUREZLyq+xd6Rbw0Cdi5cyecnZ0RHByM8+fP6xYmUCgUiIiIwJYtWxAdHY0dO3bgxo0bz0wAnvrtt9+wZs0aWFtbY/Dgwbhw4QK+/vprBAQEoEePHrh06RIiIiLwzTff4OTJk9i+fTsA4NixY8+95oEDB/Dnn39i27ZtyM3NxYYNG2BiYoLbt29j69at0Gg0GDx4MDp27Pjca2RnZ2P9+vVo2LAh/Pz8kJ6ejsDAQFy9epUJABERSdZLuwOuXbuG1q1bAwDatGkDU9OKjyV0cXFBnTp1YGJiAjc3N2RlZSEzMxPt27cHALRo0QJ//PEHrKysMGPGDMyYMQPBwcEoLi5+7jWzsrLg7u4OAKhfvz6Cg4ORmZmJdu3aQSaTQaFQoE2bNsjMzCx13t+XTKhbty4aNmwIAGjYsCGKiooqfI9ERCRNglao0Ks6e2kS4OjoiNTUVADAxYsXodFoKtxYZmYm/vrrL5SUlCAtLQ3NmzeHk5MTzpw5AwC4dOkSbG1tkZOTgwsXLuDLL7/EypUrsXjx4ue26+joiPT0dABAXl4eRo8eDScnJ11XgFqtxrlz59C0aVOYmZkhNzdXdy9PyWSyMteVy+XQSnCeaCIiqhitVqjQqzp76Z/1Q4YMQXh4OPz9/eHo6AiFouKr5SkUCkyYMAH37t1D79694eLigqlTp2LGjBlYu3YtNBoN5s+fj/r16yM3NxfvvfceLC0tMWrUqOdWILp3747k5GT4+/ujpKQE48aNQ5cuXXDq1CndUoq9e/dGq1at4Ovri4iICHz//fdo1qzZC2OtV68e1Go1Fi9ejClTplT4nomISBqkuOhulS0lfPv2bYSEhGDr1q1V0VyV4FLC0salhKWNSwlLj6GXEu4Sc6hC5x2e9FalxlGZKn2yoISEBOzevbvM9pCQkH903bi4ON2gxL+LiopCkyZN/tG1iYiIXqa6l/YrosoqAVLESoC0sRIgbawESI+hKwGdFh6s0HlHQ7tWciSVh6sIEhERGSmuHUBERKQHKRbOmQQQERHpQYpjApgEEBER6aG6T/xTEUwCiIiI9MAkgIiIyEhpOSaAiIjIOEmxEsBHBImIiIwUKwFERER6kGIlgEkAERGRHviIIBERkZHiZEFERERGStCKHUHlYxJARESkB3YHEBERGamqHBhYWFiIKVOm4P79+1AqlVi4cCFsbGx0+5OSkrBq1aoncQkCUlJSsHv3bhQWFiIwMBDNmjUDAPj7+6NPnz7PbYdJABERUTWzefNmODs749NPP8WePXuwfPlyTJ8+Xbff29sb3t7eAIDVq1fDw8MDTk5OSExMxMiRIzFq1Ci92uE8AURERHoQtEKFXhWRkpKCzp07A3jyhZ+cnPzM4/744w/s2rULQUFBAICMjAwcOnQIQ4YMQUREBPLz81/YDisBREREejDUtMGJiYlYv359qW316tWDtbU1AECpVCIvL++Z565btw4jRoyAmZkZAMDNzQ2+vr5wdXXFihUr8OWXXyI0NPS5bTMJICIi0oOhxgT4+vrC19e31LagoCCoVCoAgEqlQu3atcucp9VqcejQIQQHB+u29ezZU3dsz549MW/evBe2ze4AIiIiPVRld4CHhwcOHz4M4MkgQE9PzzLHXL16FQ4ODrCwsNBtGz16NNLS0gAAycnJaNWq1QvbYSWAiIhID1X5iKC/vz9CQ0Ph7+8PhUKBmJgYAMCiRYvQu3dvuLm5ISsrC02aNCl13uzZszFv3jwoFArY2tq+tBIgE6Q4BVIVKSoqQkZGBiwbNoPcVCF2OAbnVJwtdghVKr+Og9ghVBmV2vh+DbxaVyl2CFTJnv5OdnV1hbm5eaVfv/nYHRU67/ry/pUcSeVhdwAREZGRYndAJai7JxaKIpXYYRicrK+/2CFUqeyPPhA7hCrzOPvZI4+lqtn3P+K3P6X//9mnWPWoHFxFkIiIyEhx2mAiIiIjJWhLxA6h0jEJICIi0gOTACIiIiPFJICIiMhICSXSSwL4iCAREZGRYiWAiIhID+wOICIiMlJMAoiIiIwUkwAiIiIjxSSAiIjISDEJICIiMlJaCSYBfESQiIjISLESQEREpAd2BxARERkpJgFERERGSorTBjMJICIi0gMrAUREREaKSQAREZGRkmISwEcEiYiIjBQrAURERHoQtFqxQ6h0TAKIiIj0IMXuACYBREREemASQEREZKSkuHYAkwAiIiI9cLIgIiIiIyXF7oByPyJYVFSExMREPH78GIMGDcKoUaOwcuVKpKWllTmuW7duAIC0tDT07dsXMTExereTm5uL2bNn63Xsjh07cODAAZw8eRLBwcF6txEUFAQAuHLlCk6fPq33eURERFJQ7kpAbm4uEhMT4eDgADs7O8TGxr70nKNHj8LPzw8BAQF6t1O/fn29k4D+/fsDAE6ePKn39QEgLi4OAPDzzz/D1tYW7du3L9f5RERkPMSoBOzbtw8//vjjM/+I3rp1K7Zs2QJTU1N88skn6Nq1Kx48eIDJkyejsLAQdnZ2iI6ORq1atZ57/XInAV999RWuXLmCoUOHom7duvjiiy9w584d9OnTB56enpg8eTIeP34Me3t7AE+qANu2bYNCoUCDBg3Qs2fPMtd88OABJk6cCEEQoFarMWfOHCiVSoSEhGDr1q1455130K5dO1y9ehUODg6oV68ezpw5AzMzM6xcuRJfffUVbG1t4ejoqLvmhg0b8PPPP0Oj0cDa2hqxsbHYvXs3tm/fDq1Wi/Hjx2Py5MnYsWMHdu7cCYVCgVatWmHu3LnYtm0bAGDixIkYNWoU3NzcnvmzEAQBAKAxe/4PWEqKSgSxQ6hSQu06YodQZWQ2CrFDqFIadbHYIVSpoiLj6PktLn7yuT793VzZqjoJiIyMxNGjR9GiRYsy+3JzcxEfH4/t27ejqKgIgwcPxptvvonly5fDx8cH/fv3x8qVK5GQkIARI0Y8t41y/5cRGBiIq1evYtKkSdiyZQvGjx+PsLAwAMDOnTvh7OyM4OBgnD9/HidPnoSbmxvef/992NraPjMBAJ4kCtbW1oiJicH169eRn58PpVKp269SqeDj4wNPT0/07t0b4eHhCA4OxtChQ3H9+vUy19NqtXj48CH++9//Qi6XY/To0UhPTwcA1K5dGytWrNAd+8orr+jic3Nzg4WFBa5fvw5bW1vcvn37uQkAAKjVagDAXdce5f0x1ki/PRI7gio2ZpLYEVQZc7EDqGL3sm+IHUKVupctdgRVS61Ww8LCotKvW9VJgIeHB3r06IGEhIQy+9LS0tC2bVuYmZnBzMwM9vb2uHz5MlJSUvDxxx8DALy9vbF06dLKTQJe5Nq1a+jcuTMAoE2bNjA11e/y3t7e+PXXXzF27FhdWeN/tWrVCsCTL3EnJyfdv4uKisocK5fLoVAoEBISAktLS/zxxx/QaDQAAAcHhxfG4uvrix07dqBRo0Z49913X3isUqmEs7MzFAoFZDKZXvdKRESG8bSa/Pc/IitT8bm1BrluYmIi1q9fX2pbVFQU+vTp89xu7vz8fFhbW+veK5VK5Ofnl9quVCqRl5f3wrbLnQTI5XJonzN1oqOjI1JTU9GjRw9cvHhR98X7MidPnoSdnR3Wrl2Lc+fOYenSpYiOji51THm+ZC9fvoz9+/cjMTERf/31F/r3768rD8nlZcdCymQy3T317t0ba9euRZ06dfD555+/sB25XF7qQyAiInEZogJgaL6+vvD19S3XOVZWVlCpVLr3KpUK1tbWuu0WFhZQqVSoXbv2C69T7qcD6tWrB7VajSVLlpTZN2TIENy9exf+/v7YuHEjFAr9+hldXFywdetWDBo0CIsWLdKVMiqqadOmqFWrFvr374+RI0eifv36yMnJee7xrq6u2LhxI06cOAFzc3O0b98e9erVQ506xtMnTERENYebmxtSUlJQVFSEvLw8ZGZmwtnZGR4eHjh8+DAAICkpCZ6eni+8jkww1AiKGmz27Nno1asXvLy8xA6FiIiM2MmTJ7FlyxYsW7YMALBu3TrY29uje/fu2Lp1KxISEiAIAj7++GP06tUL9+7dQ2hoKFQqFerWrYuYmBhYWlo+9/pVmgTExcU9s38jKioKTZo0qaowXmjUqFGws7PDggULxA6FiIjIoFgJICIiMlLlHhNARERE0sAkgIiIyEgZxzRSVKOEh4cjOjoaW7ZsgZ+fn9jhGExAQMBzH3395ptvqjgaon8uIyMDrq6uYodB5cAkoAa5du0a8vPzIZfLsXTpUgQGBkryCYZLly5h4cKF+Omnn3Dnzp1S+0JCQkSKqvLNmTMHAPDll1+ie/fu8PT0RFpaGg4ePChyZIan1WohCALOnTsHNzc3mJmZiR2SwSxfvhxjx47VvY+JicGkSdKcjXLNmjX47bff8O677+Ldd9996TPqJD4ODKxBBg8ejGnTpiE2NhaBgYFYvHgxNm7cKHZYle727dtISUnBV199hTFjxpTa9/7774sUleEMHz681Gxhw4YNk3QlYPHixWjSpAnu3LmDCxcuwNbWFgsXLhQ7rEqXmJiIbdu2ITMzE82bNwcAlJSUQKPRYOfOnSJHZziPHj3C7t27sX//ftjY2GDgwIF44403xA6LnoOVgBrE1NQUr732GtRqNdzd3VFSIr21rQFg1qxZWLNmDU6cOCHJL/1nSUxMhJubG86dO/fCFb+kICUlBVOmTEFAQADi4+MxfPhwsUMyiH79+sHLywtff/01AgMDATyZZbRevXoiR2ZY9+7dw507d/Dnn3/CyckJP/74I7799tsys8BS9cAkoAaRyWSYNGkSvL29sXfvXsl+WahUKowfPx4pKSllyqbPWk6zpluyZAnWrl2Ln3/+GU5OTrpJQaRKq9UiLS0NjRs3RnFxMR48eCB2SAZhZmaGxo0bY86cOcjIyNCtc3L79m3JLlvu6+sLCwsLDBw4EBMmTNB184wePVrkyOh52B1Qgzx48ADp6eno0qULTpw4ARcXF0lObZyXl4crV64gMjISERERpfZ16NBBpKgMZ9KkSZJMbp5n48aN+PbbbxEVFYWtW7fC2dm53POm1yRBQUG4f/8+GjZsCOBJMi/VzzstLa3UyqunTp2S5P9npYRJQA2Sn5+PVatWITc3F2+99RZef/11NG3aVOywKt0ff/yBBg0a4MqVK2UGjL1sFcia6NNPP8W4cePg4OCge1pAygPlAODPP/9EdnY2GjduDBsbG7HDMSg/Pz9s2bJF7DAM6syZM7h+/Tr++9//YuTIkQCejH/YtGkTdu/eLXJ09CLsDqhBIiIi4O3tjdOnT8PW1hbTpk3Dhg0bxA6r0q1duxYRERGIjIwstV0mk0lywNzTZbSfkslkOHDggIgRGdbevXvx+eefw8nJCdeuXUNQUBD69esndlgG4+DggLt37+KVV14ROxSDqV27Nu7du4fi4mLk5uYCePLf8ZQpU0SOjF6GlYAa5Omo8af/O2TIEEk+HUDSNmjQIKxdu1a3/vnw4cOxfft2scMymP/85z+4fft2qYrH0aNHRYzIcHJycmBnZyd2GFQOrATUMJmZmQCelMzlcmlO+NitW7dSk+iYmppCo9HA3Nwce/fuFTEywzhw4AA2bdoEtVoNQRDw8OFDfP/992KHZTAymQxKpRLAkzXRzc3NRY7IsH7++WexQzC48ePH44svvkD//v3L7JNqwiMVrATUIFeuXMHMmTORmZkJR0dHzJo1C61atRI7rEpXXFwMQRAwZ84c+Pn5wc3NDRcvXsSmTZvKdBFIQf/+/TFjxgxs2bIFb7zxBo4dOybZgWMAMHXqVNjY2KBdu3ZISUnBn3/+KelVO8PDw8tsk+rjcsnJyZKcwEzKWAmoQV5//XUkJCSIHYbBPR0Ul52drRtp3LJlS2RlZYkZlsHUrVsXbdu2xZYtW9C/f3/s2LFD7JAMauDAgTh9+jSOHz+OPXv2YPXq1WKHZFB9+vQBAAiCgIsXLyInJ0fkiAwnLi6OSUANwySgBnhaauvUqVOZfVIutVlbW+Ozzz6Dm5sbUlNT8eqrr4odkkEoFAqcPn0aGo0GR44c0Q2skqoFCxZgwYIFaN68OUaOHImwsDBJj23p3Lmz7t/e3t4YNWqUiNEYlkwm0z3p8rS7UkpTfUsRk4Aa4IsvvgDwZFa5p88aA/83PkCqlixZgp07dyIpKQmOjo6YMGECgCfdBVJ6hG7OnDm4ceMGPvnkE3z++ecYP3682CEZlKmpqW4a3SZNmkh2bMtTf0/Uc3Nzce/ePRGjMawBAwaIHQKVE5OAGuDq1au4e/culixZgqlTp0IQBGi1WsTExGDXrl1ih2cwlpaWGDJkSJntH374oaQeFSwqKsL9+/fh5eWFpk2bok2bNmKHZFCNGjXC0qVL4e7ujrS0NMmPJt+zZ4/u32ZmZoiKihIxGsN65513kJ6eDo1GA0EQJN31IRVMAmqAx48fY+/evbh//75u4g2ZTIbBgweLHJk4pDaWderUqQgODgYAvPXWW5g2bVqpBYWkJjo6Gps3b8bhw4fh5ORUao4EKYqOjsbVq1dx/fp1ODg4oEWLFmKHZDBBQUFQq9XIyclBSUkJ7Ozs4OPjI3ZY9AJMAmqAdu3aoV27drhw4YIknwYor78/PigVT1dZa9euHbRarcjRGJa5uTlGjBghdhhVJj4+Hrt374abmxvWrl2Lt99+W7Jz6efn52PDhg2YNm0aZsyYoZs9kKovJgE1wNy5czFz5kzMnTu3zBeg1KcjNQa1a9dGQkKCrjz+9Bl6kobdu3dj48aNMDU1hVqthp+fn2STAFPTJ18pf/31FywsLKBWq0WOiF6GSUAN8LRcGhUVBQsLC5GjEZ/UugMWLFiAFStWYN++fWjevLmk+4yNkSAIui9HhUIBhUIhckSG07NnT8TFxcHFxQUDBw5kQlsDMAmoAWxtbQEA06dPx+bNm0WORnxPR5ZLRX5+Ptq0aYNp06ZhyZIlKCgokPyiOsbE09MT48ePh6enJ1JSUtC2bVuxQzKYvw/k7dKlC5o1ayZeMKQXzhhYg4wePRpOTk6lnsEdNGiQyFEZzqVLl5CQkKBbhx2Q5kxrfn5+CA4OxhtvvIHTp08jLi5O0gMDjdGhQ4eQmZmJ5s2bo0uXLmKHU+lCQkKeO1ZHyrNfSgErATXI078g7t+/L3IkVSMsLAxDhw5FgwYNxA7F4J4ODGzfvr3kBwYam19++QXp6emYMGECRo8eDRMTk2dO/FWT+fn5iR0CVRCTgBokKCgIOTk5RvMMrq2tLXx9fcUOw+A4MFDaYmNjdVMjf/bZZ/joo48klwSoVCp07dr1mdOad+jQQYSISF9MAmqQiIgIpKam4q+//kJhYSGaNGmCrVu3ih2Wwbz66qtYuXIlWrRooSs1Su2XJ8CBgVJnamqKevXqAXgyFbYUZ0h8+PAhAEh+ymspYhJQg9y4cQN79uzBzJkzERwcrJtGV6rUajWysrJKLRwkxSTAxsYGH330ka7Cc/PmTQ4MlBA3NzdMmjQJ7u7uSE9PR8uWLcUOqdK9//77AIDAwEBcv34dxcXFIkdE+mISUIMolUrIZDLd6HGpP4MbHR2NrKws3Lp1C6+//rpkp5cNDw/H+fPnjabCY2ymT5+OAwcO4MaNG+jVqxe6d+8OAPjtt98ktyjWxx9/jOLiYtSuXRvAk4m94uLiRI6KXoRJQA3SqlUrrFmzBnZ2dggODoZGoxE7JIPasGED9u3bh0ePHuH999/HzZs3MXPmTLHDqnRZWVlGVeExNjKZDD169CizPTw8XFJrYABP1sHYsGGD2GFQOTAJqEFCQkKgUqlgbm6OpKQkyS80s2fPHmzatAnDhg3D8OHDJbtCmaWlpVFVeOgJKT6d3a5dOxw5cgROTk66bY0aNRIxInoZJgE1QExMzDOfwU1NTZX0Wt1Pf0k+vXcpLR/8d66urroKT0hICEpKSsQOiaqAFNfAuH//PqKiokp1B3Bq8+qNSUAN4OjoKHYIovDx8cHQoUNx584dfPTRR+jZs6fYIVWqxMRE+Pr6QhAE3Rrzv/76K1q3bo3Y2Fi8+eab8PDwEDlKIv1lZWXhhx9+EDsMKgcmATVA8+bN0bp1axw9elTsUKrE3ysf9evXx927d2Fubq57DEkqnk6C9Pckz9nZGQCg0Wgwa9YsfP/996LERoYnxe4AZ2dnpKamlnoCQqoVPKlgElADnDhxAq1bt8aePXvK7JPiI3N//1J0cHCQ5DSrANC5c2cA//d41f+S6tMQxkyr1ermCejYsaPI0VS+06dP49ChQ7r3MpkMBw4cEC8geimuHVDD5Ofnl5pL/+kkJERUPf3www/QarUoLi7GokWL8OGHH0p2KWGqeVgJqEFCQ0ORkpICa2trCIIAmUyGnTt3ih0WEb3A2rVrxMtxUAAABcZJREFUsXLlSoSEhODw4cMYNWqU5JKAuXPnYubMmRg0aFCZAY8cGFi9MQmoQW7cuIH9+/eLHQYRlYO5uTmAJ5N9mZmZQaVSiRxR5Rs7diwAYOnSpSJHQuUlvUmsJczNzQ03btwQOwwiKofGjRtjwIABGDBgAOLi4uDm5iZ2SJXO1tYWAFBQUICcnBzcu3cPERERuHXrlsiR0ctwTEANsmzZMsTHx8PS0lK3zVieGCCqyVQqFZRKJe7du6f7wpSiwYMHY9q0aYiNjUVgYCAWL16MjRs3ih0WvQC7A2qQkydP4tSpUzA15cdGVFNcuXIFERERuHv3LmxtbREVFSXJRYSAJysmvvbaa1Cr1XB3d+fEVzUAuwNqkGbNmuH+/ftih0FE5RAZGYn58+fj6NGjiI6Oxty5c8UOyWBkMhkmTZoEb29v7N27F7Vq1RI7JHoJ/klZg6SkpKBbt26oW7eubhu7A4iqN0EQ4OLiAgBo0aKFpCt5y5YtQ3p6Ory9vXHy5EksW7YMgDRXTJQK6f7XKEH79u0TOwQiKidTU1McPHgQ7dq1w+nTpyU9g56NjY1ucq+/T4YkxRUTpYJJQA2wfPlyjB07FiEhIWWewY2JiREpKiLSx/z587Fw4UIsXboUjo6OmDdvntghVTmOP6++mATUAN26dQMAdO3aFY8fP4aJiQlWrVqFgIAAkSMjopd59dVXERgYiKysLDRv3twoy+JSXDFRKjgwsAZ42p+4Y8cOODk54fjx4wgJCeGc3EQ1wLJlyzB37lycP38es2bNwurVq8UOiUiHSUANotFo0L59e/y/9u4glP0/juP4K6ydnLS1kgOnpbYcXJSTqylEJrVyUA5ObnOR0y6Ug4uWk8xhaidM7SBafS+LKDWEiMTNwcGG3+HX9Ft+fvz79/Wx756P4z6Xl8t62ff7fn8eHh7U3d2tl5cX05EAfGJ3d1eJREJTU1NaWVlROp02Henb8Tjg56IEVJBCoaBYLKb29nZZlsUMLlABfD7f26rgYrHoyGVBpSmAj9aaO/HGRKdgY2AFubi4UDab1eDgoDKZjAKBgJqamkzHAvAPAwMDurm5kd/v1+npqVwulzwejyTnXK4TCoU0PDys5eVljY6Olp0NDQ0ZSoWvoAQAgI2ur6//+vn9/b3a2tq+OY09Dg4OlM1mlUwm1d/fX3Y2MTFhKBW+ghIAAAZEIhHHzc4fHh4qEAiYjoH/gBFBADDASf9/dXV1lY0B1tXVqVgsyu12a2Njw2AyfIYSAAAGOGl2Pp1O6/X1VTMzMwqHwwoGgzo6OlIikTAdDZ+gBAAA/pfSKuSrqysFg0FJUmtrq87Pz03GwhdQAgDAACc9Diipr6/X/Py8gsGg9vb2qnI7YqVhTwAA2CAajUr6eAywp6fnO+N8i9nZWXk8Hu3s7Mjr9SoWi5mOhE8wHQAANujt7VVHR4e2trYUCoXKziYnJw2lskdpKuBvV5t3dnYaSISv4nEAANhgYWFBuVxO29vbam5uNh3HVpZlKRAIaH19/d0ZJeBnowQAgA2mp6e1tLQky7LU19dnOo6tLMvS2NiYGhsbWQ5UYXgcAAA2CIfD8nq9yuVy73bnz83NGUplj2r6W52GXwIAwAbxeFz5fF6Xl5eO358fj8d1fHysTCajcDgs6ff0AwXg5+OXAACwwe3trXw+n/L5/NscfYnT3hFIJpNaW1tTPp+X3++XJD0/P6tYLCqVShlOh3+hBACADWKxmKLRqCKRyLszp90Z8PT0pLu7Oy0uLmp8fFySVFNTo4aGhncFCD8LJQAAbFDap1/6inW5XCoUCnK73drc3DScDviNdwIAwAYf7dNfXV01HQ14QwkAABt8tE//7OzMZCygDCUAAGz05z79/f199unjR+GdAACw0ePjo1KplE5OTtTS0qKRkRHV1taajgVIogQAAFC1uEUQAIAqRQkAAKBKUQIAAKhSlAAAAKrUL5/o8FWGixW/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe1cbabff50>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.features import Rank2D\n",
    "from yellowbrick.datasets import load_credit\n",
    "\n",
    "# Instantiate the visualizer with the Pearson ranking algorithm\n",
    "visualizer = Rank2D(algorithm='pearson')\n",
    "\n",
    "X = all_train_and_testset['pd']['x_trainset']\n",
    "print(X)\n",
    "X = X[['similarities','len_diff','jaccard','cos','diff_pos_count','tfidf_similarity']]\n",
    "\n",
    "visualizer.fit(X, all_train_and_testset['pd']['y_trainset'])  \n",
    "visualizer.transform(X) \n",
    "visualizer.show()\n",
    "# Fit the data to the visualizer\n",
    "#visualizer.transform(X)        # Transform the data\n",
    "#visualizer.show()              # Finalize and render the figure         # Finalize and render the figure\n",
    "\n",
    "#visualizer = Rank2D(algorithm=\"pearson\")\n",
    "#visualizer.fit_transform(all_train_and_testset['pd']['x_trainset'])\n",
    "#visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [32, 448]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-6b317e666626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvisualizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_train_and_testset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_trainset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_train_and_testset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_trainset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundersampled_train_and_testset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_testset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mundersampled_train_and_testset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_testset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/yellowbrick/classifier/classification_report.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \"\"\"\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Call super to check if fitted and to compute self.score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassificationReport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/yellowbrick/classifier/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# This method implements ScoreVisualizer (do not call super).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\"\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [32, 448]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = RandomForestClassifier(max_depth=15, max_features='auto', min_samples_leaf=3, min_samples_split=2, n_estimators=500)\n",
    "visualizer = ClassificationReport(model)\n",
    "visualizer.fit(all_train_and_testset['pd']['x_trainset'], all_train_and_testset['pd']['y_trainset'])\n",
    "visualizer.score(undersampled_train_and_testset['pd']['x_testset'], undersampled_train_and_testset['pd']['y_testset'])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'narrower', 'exact', 'related', 'none', 'broader'}\n"
     ]
    }
   ],
   "source": [
    "all_data = load_training_data()\n",
    "en_data = all_data['english_kd']\n",
    "print(set(en_data['relation']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a2e92c170780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pattern'"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "#import pattern.en\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#from pattern.en import tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def pos_tag_text(text):\n",
    "    \n",
    "    def penn_to_wn_tags(pos_tag):\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    tagged_text = tag(text)\n",
    "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
    "                         for word, pos_tag in\n",
    "                         tagged_text]\n",
    "    return tagged_lower_text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [wnl.lemmatize(word, pos_tag) if pos_tag\n",
    "                         else word                     \n",
    "                         for word, pos_tag in pos_tagged_text]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "lemmatized = lemmatize_text(en_data['def1'][0])\n",
    "lemmatized\n",
    "\n",
    "#stopwords = remove_stopwords(en_data['def1'][0])\n",
    "\n",
    "#tokens = tokenize_text(lemma_stopwords)\n",
    "#tokens\n",
    "\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Text Classifier to the pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print only narrower relations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word          pos  \\\n",
      "0    off        preposition   \n",
      "3    off        preposition   \n",
      "8    off        preposition   \n",
      "13   off        preposition   \n",
      "15   off        adverb        \n",
      "..   ...           ...        \n",
      "530  on         preposition   \n",
      "551  on         preposition   \n",
      "552  one        number        \n",
      "553  one        number        \n",
      "554  offspring  noun          \n",
      "\n",
      "                                                    def1  \\\n",
      "0    away from and no longer touching                      \n",
      "3    in a position away from                               \n",
      "8    not inside a large vehicle used by the public         \n",
      "13   not eating or taking                                  \n",
      "15   away from a place                                     \n",
      "..                 ...                                     \n",
      "530  indicates sth or sb uses a type of food, fuel, etc.   \n",
      "551  immediately following                                 \n",
      "552  the number 1                                          \n",
      "553  the number 1                                          \n",
      "554  a person's child or an animal's baby                  \n",
      "\n",
      "                                               def2  relation  \n",
      "0    away from; down from                            narrower  \n",
      "3    away from; down from                            narrower  \n",
      "8    out of (a vehicle, train etc)                   exact     \n",
      "13   not wanting or allowed to have (food etc)       exact     \n",
      "15   away (from a place, time etc)                   narrower  \n",
      "..                             ...                        ...  \n",
      "530  receiving, taking                               exact     \n",
      "551  followed by                                     related   \n",
      "552  the number or figure 1                          exact     \n",
      "553  the age of 1                                    related   \n",
      "554  (formal, humorous) someone's child or children  broader   \n",
      "\n",
      "[108 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#df['def1']=df['def1'].str.wrap(20)\n",
    "is_narrower = en_data['relation']=='narrower'\n",
    "def is_not_none(df):\n",
    "    return df['relation']!='none'\n",
    "def is_none(df):\n",
    "    return df['relation']=='none'\n",
    "\n",
    "print(en_data[is_not_none])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Spacy NLP Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacyDocForVec(sentence):\n",
    "    return nlp(sentence)\n",
    "\n",
    "modDfObj = pd.DataFrame()\n",
    "en_data['processed_1'] = en_data['def1'].map(spacyDocForVec)\n",
    "en_data['processed_2'] = en_data['def2'].map(spacyDocForVec)\n",
    "#doc_list = spacyDocForVec(en_data['def1'])\n",
    "#doc_list2 = spacyDocForVec(en_data['def2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7fe2b83aec10>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7fe28ba5e360>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7fe28ba5e600>)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>def1</th>\n",
       "      <th>def2</th>\n",
       "      <th>relation</th>\n",
       "      <th>processed_1</th>\n",
       "      <th>processed_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>away from; down from</td>\n",
       "      <td>narrower</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(away, from, ;, down, from)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>not wanting or allowed to have (food etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(not, wanting, or, allowed, to, have, (, food, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>out of (a vehicle, train etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(out, of, (, a, vehicle, ,, train, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in a position away from</td>\n",
       "      <td>away from; down from</td>\n",
       "      <td>narrower</td>\n",
       "      <td>(in, a, position, away, from)</td>\n",
       "      <td>(away, from, ;, down, from)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in a position away from</td>\n",
       "      <td>not wanting or allowed to have (food etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(in, a, position, away, from)</td>\n",
       "      <td>(not, wanting, or, allowed, to, have, (, food, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>on</td>\n",
       "      <td>preposition</td>\n",
       "      <td>immediately following</td>\n",
       "      <td>followed by</td>\n",
       "      <td>related</td>\n",
       "      <td>(immediately, following)</td>\n",
       "      <td>(followed, by)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>one</td>\n",
       "      <td>number</td>\n",
       "      <td>the number 1</td>\n",
       "      <td>the number or figure 1</td>\n",
       "      <td>exact</td>\n",
       "      <td>(the, number, 1)</td>\n",
       "      <td>(the, number, or, figure, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>one</td>\n",
       "      <td>number</td>\n",
       "      <td>the number 1</td>\n",
       "      <td>the age of 1</td>\n",
       "      <td>related</td>\n",
       "      <td>(the, number, 1)</td>\n",
       "      <td>(the, age, of, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>offspring</td>\n",
       "      <td>noun</td>\n",
       "      <td>a person's child or an animal's baby</td>\n",
       "      <td>(formal, humorous) someone's child or children</td>\n",
       "      <td>broader</td>\n",
       "      <td>(a, person, 's, child, or, an, animal, 's, baby)</td>\n",
       "      <td>((, formal, ,, humorous, ), someone, 's, child, or, children)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>offspring</td>\n",
       "      <td>noun</td>\n",
       "      <td>a person's child or an animal's baby</td>\n",
       "      <td>an animal's baby or babies</td>\n",
       "      <td>none</td>\n",
       "      <td>(a, person, 's, child, or, an, animal, 's, baby)</td>\n",
       "      <td>(an, animal, 's, baby, or, babies)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word          pos                                  def1  \\\n",
       "0    off        preposition  away from and no longer touching       \n",
       "1    off        preposition  away from and no longer touching       \n",
       "2    off        preposition  away from and no longer touching       \n",
       "3    off        preposition  in a position away from                \n",
       "4    off        preposition  in a position away from                \n",
       "..   ...                ...                      ...                \n",
       "551  on         preposition  immediately following                  \n",
       "552  one        number       the number 1                           \n",
       "553  one        number       the number 1                           \n",
       "554  offspring  noun         a person's child or an animal's baby   \n",
       "555  offspring  noun         a person's child or an animal's baby   \n",
       "\n",
       "                                               def2  relation  \\\n",
       "0    away from; down from                            narrower   \n",
       "1    not wanting or allowed to have (food etc)       none       \n",
       "2    out of (a vehicle, train etc)                   none       \n",
       "3    away from; down from                            narrower   \n",
       "4    not wanting or allowed to have (food etc)       none       \n",
       "..                                         ...        ...       \n",
       "551  followed by                                     related    \n",
       "552  the number or figure 1                          exact      \n",
       "553  the age of 1                                    related    \n",
       "554  (formal, humorous) someone's child or children  broader    \n",
       "555  an animal's baby or babies                      none       \n",
       "\n",
       "                                          processed_1  \\\n",
       "0    (away, from, and, no, longer, touching)            \n",
       "1    (away, from, and, no, longer, touching)            \n",
       "2    (away, from, and, no, longer, touching)            \n",
       "3    (in, a, position, away, from)                      \n",
       "4    (in, a, position, away, from)                      \n",
       "..                             ...                      \n",
       "551  (immediately, following)                           \n",
       "552  (the, number, 1)                                   \n",
       "553  (the, number, 1)                                   \n",
       "554  (a, person, 's, child, or, an, animal, 's, baby)   \n",
       "555  (a, person, 's, child, or, an, animal, 's, baby)   \n",
       "\n",
       "                                                       processed_2  \n",
       "0    (away, from, ;, down, from)                                    \n",
       "1    (not, wanting, or, allowed, to, have, (, food, etc, ))         \n",
       "2    (out, of, (, a, vehicle, ,, train, etc, ))                     \n",
       "3    (away, from, ;, down, from)                                    \n",
       "4    (not, wanting, or, allowed, to, have, (, food, etc, ))         \n",
       "..                                                      ...         \n",
       "551  (followed, by)                                                 \n",
       "552  (the, number, or, figure, 1)                                   \n",
       "553  (the, age, of, 1)                                              \n",
       "554  ((, formal, ,, humorous, ), someone, 's, child, or, children)  \n",
       "555  (an, animal, 's, baby, or, babies)                             \n",
       "\n",
       "[556 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import collections\n",
    "\n",
    "en_data['processed_1']\n",
    "print(nlp.pipeline)\n",
    "en_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['def1_nlp']=doc_list\n",
    "#df['def2_nlp']=doc_list2\n",
    "nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "     pos_count                                        lemmatized  \\\n",
      "0    4          (away, from, and, no, longer, touching)            \n",
      "1    4          (away, from, and, no, longer, touching)            \n",
      "2    4          (away, from, and, no, longer, touching)            \n",
      "3    4          (in, a, position, away, from)                      \n",
      "4    4          (in, a, position, away, from)                      \n",
      "..  ..                                    ...                      \n",
      "551  2          (immediately, follow)                              \n",
      "552  3          (the, number, 1)                                   \n",
      "553  3          (the, number, 1)                                   \n",
      "554  4          (a, person, 's, child, or, an, animal, 's, baby)   \n",
      "555  4          (a, person, 's, child, or, an, animal, 's, baby)   \n",
      "\n",
      "                        sw_removed  \n",
      "0    [away, longer, touching]       \n",
      "1    [away, longer, touching]       \n",
      "2    [away, longer, touching]       \n",
      "3    [position, away]               \n",
      "4    [position, away]               \n",
      "..                ...               \n",
      "551  [immediately, following]       \n",
      "552  [number, 1]                    \n",
      "553  [number, 1]                    \n",
      "554  [person, child, animal, baby]  \n",
      "555  [person, child, animal, baby]  \n",
      "\n",
      "[556 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "deps = collections.defaultdict(set)\n",
    "\n",
    "        \n",
    "def count_pos(row):\n",
    "    pos = []\n",
    "    for token in row['processed_1']:\n",
    "        pos.append(token.pos)\n",
    "        \n",
    "    \n",
    "    return len(list(set(pos)))\n",
    "    \n",
    "def remove_stopwords(row):\n",
    "    tokens = row['processed_1']\n",
    "    temp = ''\n",
    "    for token in tokens:\n",
    "        #print(type(row))\n",
    "        if token.is_stop == False:\n",
    "            temp = temp + token.lemma_ + ' '\n",
    "            \n",
    "    return temp\n",
    "    \n",
    "\n",
    "def filter_sw(lemmatized):\n",
    "    result = []\n",
    "    for token in lemmatized:\n",
    "        #print(type(row))\n",
    "        if token.is_stop == False:\n",
    "            result.append(token)\n",
    "            \n",
    "    return result\n",
    "    \n",
    "def lemmatize(row):\n",
    "    return ' '.join([token.lemma_ for token in row['processed_1']])\n",
    "\n",
    "\n",
    "def is_lemmatized(df):\n",
    "    return df['def1']!=df['lemmatized']\n",
    "\n",
    "def lemmatizer(doc):\n",
    "    # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "    # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)\n",
    "    \n",
    "def remove_stopwords(doc):\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc\n",
    "\n",
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "\n",
    "temp['pos_count'] = en_data.apply(lambda row: count_pos(row),axis=1)\n",
    "\n",
    "\n",
    "print(type(en_data['processed_1'][0]))\n",
    "temp['lemmatized'] = en_data.apply(lambda row: lemmatizer(row['processed_1']),axis=1)\n",
    "temp['sw_removed'] = en_data.apply(lambda row: remove_stopwords(row),axis=1)\n",
    "\n",
    "print(temp)\n",
    "#lemmatized_processed = temp['lemmatized'].map(spacyDocForVec)\n",
    "\n",
    "#sw_processed = lemmatized_processed.map(remove_stopwords['lemmatized'])\n",
    "\n",
    "#print(lemmatized_processed)\n",
    "#print(sw_processed)\n",
    "\n",
    "temp['def1'] = en_data['def1']\n",
    "\n",
    "#print_all_rows(temp[is_lemmatized(temp)])\n",
    "\n",
    "#for token in test:\n",
    "#    print(token.lemma_)\n",
    "\n",
    "#print(en_data['processed_1'])\n",
    "#nlp.vocab['a'].is_stop\n",
    "#en_data\n",
    "#print(len(count_distinct_pos))\n",
    "        #features['similarities'] = en_data.apply(lambda row: sentence2vec(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#modDfObj['def1'][0].sents\n",
    "label_count = en_data.groupby('relation').count().word.sort_values(ascending=False)\n",
    "\n",
    "label_count.plot(kind = 'bar')\n",
    "label_count[1]\n",
    "#label_count.plot(kind = 'bar', x = 'relation', y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word           off                                    \n",
       "pos            preposition                            \n",
       "def1           away from and no longer touching       \n",
       "def2           away from; down from                   \n",
       "relation       narrower                               \n",
       "processed_1    (away, from, and, no, longer, touching)\n",
       "processed_2    (away, from, ;, down, from)            \n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t1 = doc_list2[0]\n",
    "#for token in doc_list2[0]\n",
    "#    print(token.text, \"| lemma:\", token.lemma_, \"| norm:\" , token.norm_, \"| pos:\" ,token.pos_, \"| tag:\", token.tag_, \"| dep:\", token.dep_, \"| sentiment:\", token.sentiment)\n",
    "en_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     similarities  first_word_same  len_diff   jaccard  pos_diff\n",
      "0    0.856918      True             2         0.250000  0       \n",
      "1    0.776428      False            3         0.000000  0       \n",
      "2    0.732969      False            3         0.000000  0       \n",
      "3    0.836521      False            1         0.285714  0       \n",
      "4    0.689816      False            2         0.000000  0       \n",
      "..        ...        ...           ..              ... ..       \n",
      "551  0.615553      False            6         0.000000  0       \n",
      "552  0.915048      True             0         0.600000  0       \n",
      "553  0.822070      True             0         0.400000  0       \n",
      "554  0.850947      False            1         0.181818  0       \n",
      "555  0.934649      False            5         0.500000  0       \n",
      "\n",
      "[556 rows x 5 columns]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-38b9226a06c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jaccard'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'len_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#for i, row in en_data.iterrows():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#    similarities.append(sentence2Vec(row))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mkde\u001b[0;34m(self, bw_method, ind, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \"\"\"\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kde\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_legend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/hist.py\u001b[0m in \u001b[0;36m_make_plot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0martists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacking_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacking_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_legend_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/hist.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(cls, ax, y, style, bw_method, ind, column_num, stacking_id, **kwds)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_na_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mgkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgkde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m                                                \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                                                aweights=self.weights))\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0minv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         raise ValueError('illegal value in %d-th argument of internal '\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sentence2vec(row):\n",
    "    return row['processed_1'].similarity(row['processed_2'])\n",
    "\n",
    "    \n",
    "def first_word_same(row):\n",
    "    return row['def1'].split(' ')[0].lower() == row['def2'].split(' ')[0].lower()\n",
    "\n",
    "def difference_in_length(row):\n",
    "    return abs(len(row['def1'].split(' ')) - len(row['def2'].split(' ')[0]))\n",
    "\n",
    "def jaccard_sim(row):\n",
    "    return get_jaccard_sim(row['def1'], row['def2'])\n",
    "\n",
    "\n",
    "def cosine(row):\n",
    "    return get_cosine_sim(row['def1'], row['def2'])[0, 1]\n",
    "\n",
    "def get_jaccard_sim(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def pos_count(column):\n",
    "    pos = []\n",
    "    \n",
    "    for token in column:\n",
    "        pos.append(token.pos)\n",
    "    return list(set(pos))\n",
    "        \n",
    "    \n",
    "def diff_pos_count(row):\n",
    "    pos_def1 = pos_count(row['processed_1'])\n",
    "    pos_def1 = pos_count(row['processed_2'])\n",
    "    \n",
    "    return  len(pos_def1) - len(pos_def1)\n",
    "    \n",
    "\n",
    "\n",
    "features = pd.DataFrame()\n",
    "\n",
    "similarities = []\n",
    "first_word = []\n",
    "length = []\n",
    "\n",
    "features['similarities'] = en_data.apply(lambda row: sentence2vec(row), axis = 1)\n",
    "features['first_word_same'] = en_data.apply(lambda row: first_word_same(row), axis=1)\n",
    "features['len_diff'] = en_data.apply(lambda row: difference_in_length(row), axis=1)\n",
    "features['jaccard'] = en_data.apply(lambda row: jaccard_sim(row), axis=1)\n",
    "features['pos_diff'] = en_data.apply(lambda row: diff_pos_count(row), axis=1)\n",
    "print(features)\n",
    "#features['len_diff'].plot(kind = 'hist')\n",
    "features['similarities'].plot.kde()\n",
    "features['jaccard'].plot.kde()\n",
    "features['len_diff'].plot.kde()\n",
    "features['pos_diff'].plot.kde()\n",
    "#for i, row in en_data.iterrows():\n",
    "#    similarities.append(sentence2Vec(row))\n",
    "#    first_word.append(first_word_same(row))\n",
    "#    length.append(difference_in_length(row)) \n",
    "\n",
    "#features['similarities'] = similarities\n",
    "#features['first_word_same'] = first_word\n",
    "#features['length'] = length\n",
    "#Add Token Count using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#none = features[is_none(features)==True]\n",
    "\n",
    "#label_count = en_data.groupby('relation').count().word.sort_values(ascending=False)\n",
    "#second_biggest = label_count[1]\n",
    "#to_drop = none.index[second_biggest:]\n",
    "\n",
    "#balanced = features.drop(to_drop) \n",
    "#balanced\n",
    "#label_count = balanced.groupby('relation').count().similarities.sort_values(ascending=False)\n",
    "\n",
    "#label_count.plot(kind = 'bar')\n",
    "#label_count[1]\n",
    "#second_biggest\n",
    "#label_count.plot(kind = 'bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarities</th>\n",
       "      <th>first_word_same</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.856918</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.776428</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.732969</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.836521</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.689816</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>0.615553</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>0.915048</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>0.822070</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>0.850948</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>0.934649</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarities  first_word_same  len_diff   jaccard\n",
       "0    0.856918      True             2         0.250000\n",
       "1    0.776428      False            3         0.000000\n",
       "2    0.732969      False            3         0.000000\n",
       "3    0.836521      False            1         0.285714\n",
       "4    0.689816      False            2         0.000000\n",
       "..        ...        ...           ..              ...\n",
       "551  0.615553      False            6         0.000000\n",
       "552  0.915048      True             0         0.600000\n",
       "553  0.822070      True             0         0.400000\n",
       "554  0.850948      False            1         0.181818\n",
       "555  0.934649      False            5         0.500000\n",
       "\n",
       "[556 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#en_data['similarities'] = similarities\n",
    "labels = en_data['relation']\n",
    "features = features.drop(['relation'], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarities</th>\n",
       "      <th>first_word_same</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.689137</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.765570</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.800568</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.756537</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.863854</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.710593</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>0.566016</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.736717</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>0.850948</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.616458</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarities  first_word_same  len_diff   jaccard\n",
       "69   0.689137      False            1         0.000000\n",
       "253  0.765570      False            9         0.058824\n",
       "139  0.800568      False            4         0.000000\n",
       "286  0.756537      False            2         0.000000\n",
       "221  0.863854      False            9         0.000000\n",
       "..        ...        ...           ..              ...\n",
       "346  0.710593      False            4         0.000000\n",
       "443  0.566016      False            0         0.000000\n",
       "295  0.736717      False            2         0.100000\n",
       "554  0.850948      False            1         0.181818\n",
       "208  0.616458      False            3         0.000000\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2)\n",
    "X_train_scaled = X_train.copy(deep = True)\n",
    "X_test_scaled = X_test.copy(deep = True)\n",
    "\n",
    "X_train_scaled['similarities'] = preprocessing.scale(X_train['similarities'])\n",
    "X_train_scaled['len_diff'] = preprocessing.scale(X_train['len_diff'])\n",
    "X_train_scaled['jaccard'] = preprocessing.scale(X_train['jaccard'])\n",
    "#X_train_scaled['length'] = preprocessing.scale(X_train['length'])\n",
    "#X_test_scaled['similarities'] = preprocessing.scale(X_test['similarities'])\n",
    "#X_test_scaled['length'] = preprocessing.scale(X_test['length'])\n",
    "#features['similarities'].plot.kde()\n",
    "#X_train_scaled['similarities'].plot.kde()\n",
    "X_train_scaled['jaccard'].plot.kde()\n",
    "#X_train_scaled['len_diff'].plot.kde()\n",
    "\n",
    "X_train_set = {}\n",
    "X_train_set['unscaled'] = X_train\n",
    "X_train_set['scaled'] = X_train_scaled\n",
    "\n",
    "X_test_set = {}\n",
    "X_test_set['unscaled'] = X_test\n",
    "X_test_set['scaled'] = X_test_scaled\n",
    "\n",
    "X_test_set['unscaled']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.7857142857142857\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelLogisticRegression\n",
      "Accuracy: 0.8224 (+/- 0.0373)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelLinearSVC\n",
      "Accuracy: 0.8157 (+/- 0.0440)\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "Accuracy: 0.8133 (+/- 0.0611)\n",
      "Cross validation scores for modelLogisticRegression\n",
      "Accuracy: 0.8156 (+/- 0.0381)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelLinearSVC\n",
      "Accuracy: 0.8179 (+/- 0.0419)\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "Accuracy: 0.8133 (+/- 0.0611)\n",
      "Model Evaluation on Testset: \n",
      "\n",
      "\tBASELINE: 0.7857142857142857\n",
      "\n",
      "\tLogisticRegression\n",
      "\t\tAccuracy: 0.7857 (+/- 0.0000)\n",
      "\n",
      "\tLinearSVC\n",
      "\t\tAccuracy: 0.7768 (+/- 0.0000)\n",
      "\n",
      "\tRandomForestClassifier\n",
      "\t\tAccuracy: 0.7857 (+/- 0.0000)\n",
      "\n",
      "\tLogisticRegression\n",
      "\t\tAccuracy for scaled featureset: 0.7857 (+/- 0.0000)\n",
      "\n",
      "\tLinearSVC\n",
      "\t\tAccuracy for scaled featureset: 0.7857 (+/- 0.0000)\n",
      "\n",
      "\tRandomForestClassifier\n",
      "\t\tAccuracy for scaled featureset: 0.7857 (+/- 0.0000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_baseline(test_set):\n",
    "    TP = 0\n",
    "    for index in test_set.index:\n",
    "        if test_set[index]=='none':\n",
    "            TP+=1\n",
    "\n",
    "    return float(TP/len(test_set))\n",
    "\n",
    "\n",
    "def run_cv_with_dataset(model, trainset, y_train):\n",
    "    scores = cross_val_score(model, trainset, y_train, cv = 5)        \n",
    "    print('Cross validation scores for model' + model.__class__.__name__)\n",
    "    #scores\n",
    "    print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "def cross_val_models(models, all_training_set, y_train):\n",
    "    for estimator in models['unscaled']:\n",
    "        run_cv_with_dataset(estimator, all_training_set['unscaled'], y_train)\n",
    "    \n",
    "    for estimator in models['scaled']:\n",
    "        run_cv_with_dataset(estimator, all_training_set['scaled'], y_train)\n",
    "\n",
    "def compare_on_testset(models, testset_x, testset_y, testset_x_scaled):\n",
    "    print('Model Evaluation on Testset: ' + '\\n')\n",
    "    print('\\t' + 'BASELINE: ' + str(get_baseline(testset_y)) + '\\n')\n",
    "    \n",
    "    for estimator in models['unscaled']:\n",
    "        estimator.predict(testset_x)\n",
    "        print('\\t' + estimator.__class__.__name__)\n",
    "        score = estimator.score(testset_x, testset_y)\n",
    "        print('\\t\\t' + \"Accuracy: %0.4f (+/- %0.4f)\" % (score.mean(), score.std() * 2) + '\\n')\n",
    "    \n",
    "    for estimator in models['scaled']:\n",
    "        estimator.predict(testset_x_scaled)\n",
    "        print('\\t' + estimator.__class__.__name__)\n",
    "        score = estimator.score(testset_x_scaled, testset_y)\n",
    "        print('\\t\\t' + \"Accuracy for scaled featureset: %0.4f (+/- %0.4f)\" % (score.mean(), score.std() * 2) + '\\n')\n",
    "\n",
    "def train_models(X_train, y_train, X_train_scaled):\n",
    "    print('baseline: ', str(get_baseline(y_test)) + '\\n')\n",
    "\n",
    "    LR = LogisticRegression( solver = 'lbfgs', multi_class = 'multinomial').fit(X_train, y_train)\n",
    "    LR_scaled = LogisticRegression( solver = 'lbfgs', multi_class = 'multinomial').fit(X_train_scaled, y_train)\n",
    "\n",
    "    ## Linear kernal won't work very well, experiment with nonlinear ones.\n",
    "    SVM = svm.LinearSVC(C=10.0).fit(X_train, y_train)\n",
    "    SVM_scaled = svm.LinearSVC().fit(X_train_scaled, y_train)\n",
    "\n",
    "    RF = RandomForestClassifier(max_depth = 5, random_state=0).fit(X_train, y_train)\n",
    "    RF_scaled = RandomForestClassifier(max_depth = 5, random_state=0).fit(X_train_scaled, y_train)\n",
    "    \n",
    "    models = {}\n",
    "    models['unscaled'] = [LR, SVM, RF]\n",
    "    models['scaled'] = [LR_scaled, SVM_scaled, RF_scaled]\n",
    "    \n",
    "    return models\n",
    "\n",
    "models = train_models(X_train, y_train, X_train_scaled)\n",
    "cross_val_models(models, X_train_set, y_train)\n",
    "#print(models)\n",
    "compare_on_testset(models, X_test, y_test, X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp_en = English()\n",
    "nlp_en.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\n",
    "        \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"}\n",
    "    )\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")\n",
    "    \n",
    "textcat.add_label('related')\n",
    "textcat.add_label('exact')\n",
    "textcat.add_label('broader')\n",
    "textcat.add_label('narrower')\n",
    "textcat.add_label('none')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "## Experiment with NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(doc):\n",
    "        # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "    # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc\n",
    "\n",
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "#nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "#nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
