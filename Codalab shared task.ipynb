{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Task\n",
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/seungbinyim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pprint import pprint\n",
    "from spacy import displacy\n",
    "from enum import Enum\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "def print_all_rows(df):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = 'data/train'\n",
    "\n",
    "def load_and_preprocess():\n",
    "\n",
    "    all_data = load_training_data()\n",
    "    en_data = all_data['english_nuig']\n",
    "    balanced = balance_dataset(en_data)\n",
    "\n",
    "    balanced['processed_1'] = balanced['def1'].map(nlp)\n",
    "    balanced['processed_2'] = balanced['def2'].map(nlp)\n",
    "\n",
    "    return balanced\n",
    "\n",
    "def load_training_data():\n",
    "    combined_set = {}\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".tsv\"):\n",
    "            combined_set[filename.split('.')[0]] = load_data(folder + '/' + filename)\n",
    "\n",
    "    return combined_set\n",
    "\n",
    "def load_data(file_path):\n",
    "    loaded_data = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "    add_column_names(loaded_data)\n",
    "\n",
    "    return loaded_data\n",
    "\n",
    "def add_column_names(df):\n",
    "    column_names = ['word', 'pos', 'def1', 'def2', 'relation']\n",
    "    df.columns = column_names\n",
    "\n",
    "    \n",
    "def balance_dataset(imbalanced_set):\n",
    "    none = imbalanced_set[is_none(imbalanced_set) == True]\n",
    "    second_biggest = imbalanced_set.groupby('relation').count().word.sort_values(ascending=False)[1]\n",
    "    result = imbalanced_set.drop(none.index[second_biggest:])\n",
    "\n",
    "    return result.sample(frac=1, random_state=7)\n",
    "\n",
    "def is_not_none(df):\n",
    "    return df['relation'] != 'none'\n",
    "\n",
    "\n",
    "def is_none(df):\n",
    "    return df['relation'] == 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_en_data = load_and_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Feature Extraction related functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  word        pos  \\\n",
      "1371  attentiveness     noun        \n",
      "1290  contemporize      verb        \n",
      "204   horn              noun        \n",
      "694   fret              verb        \n",
      "5858  forward           adjective   \n",
      "...       ...                 ...   \n",
      "5182  distribute        verb        \n",
      "502   incontrovertible  adjective   \n",
      "537   perennial         adjective   \n",
      "2409  establish         verb        \n",
      "175   allow             verb        \n",
      "\n",
      "                                                               def1  \\\n",
      "1371  paying particular notice (as to children or helpless people)    \n",
      "1290  happen at the same time                                         \n",
      "204   a device on an automobile for making a warning noise            \n",
      "694   wear away or erode                                              \n",
      "5858  used of temperament or behavior; lacking restraint or modesty   \n",
      "...                                                             ...   \n",
      "5182  cause be distributed                                            \n",
      "502   necessarily or demonstrably true                                \n",
      "537   lasting three seasons or more                                   \n",
      "2409  set up or found                                                 \n",
      "175   consent to, give permission                                     \n",
      "\n",
      "                                                                                                                                                          def2  \\\n",
      "1371  paying particular notice (as to children or helpless people).                                                                                              \n",
      "1290  to happen at the same time.                                                                                                                                \n",
      "204   one of the curved ends of a crescent; esp., an extremity or cusp of the moon when crescent-shaped.                                                         \n",
      "694   to ornament with raised work; to variegate; to diversify.                                                                                                  \n",
      "5858  ready; prompt; strongly inclined; in an ill sense, overready; too hasty.                                                                                   \n",
      "...                                                                        ...                                                                                   \n",
      "5182  to make distribution.                                                                                                                                      \n",
      "502   not controvertible; too clear or certain to admit of dispute; indisputable.                                                                                \n",
      "537   lasting or continuing through the year; .                                                                                                                  \n",
      "2409  to originate and secure the permanent existence of; to found; to institute; to create and regulate; -- said of a colony, a state, or other institutions.   \n",
      "175   to sanction; to invest; to intrust.                                                                                                                        \n",
      "\n",
      "      relation  \\\n",
      "1371  exact      \n",
      "1290  exact      \n",
      "204   none       \n",
      "694   none       \n",
      "5858  broader    \n",
      "...       ...    \n",
      "5182  narrower   \n",
      "502   none       \n",
      "537   none       \n",
      "2409  narrower   \n",
      "175   none       \n",
      "\n",
      "                                                                     processed_1  \\\n",
      "1371  (paying, particular, notice, (, as, to, children, or, helpless, people, ))   \n",
      "1290  (happen, at, the, same, time)                                                \n",
      "204   (a, device, on, an, automobile, for, making, a, warning, noise)              \n",
      "694   (wear, away, or, erode)                                                      \n",
      "5858  (used, of, temperament, or, behavior, ;, lacking, restraint, or, modesty)    \n",
      "...                                                                         ...    \n",
      "5182  (cause, be, distributed)                                                     \n",
      "502   (necessarily, or, demonstrably, true)                                        \n",
      "537   (lasting, three, seasons, or, more)                                          \n",
      "2409  (set, up, or, found)                                                         \n",
      "175   (consent, to, ,, give, permission)                                           \n",
      "\n",
      "                                                                                                                                                                                            processed_2  \n",
      "1371  (paying, particular, notice, (, as, to, children, or, helpless, people, ), .)                                                                                                                      \n",
      "1290  (to, happen, at, the, same, time, .)                                                                                                                                                               \n",
      "204   (one, of, the, curved, ends, of, a, crescent, ;, esp, ., ,, an, extremity, or, cusp, of, the, moon, when, crescent, -, shaped, .)                                                                  \n",
      "694   (to, ornament, with, raised, work, ;, to, variegate, ;, to, diversify, .)                                                                                                                          \n",
      "5858  (ready, ;, prompt, ;, strongly, inclined, ;, in, an, ill, sense, ,, overready, ;, too, hasty, .)                                                                                                   \n",
      "...                                                                                                ...                                                                                                   \n",
      "5182  (to, make, distribution, .)                                                                                                                                                                        \n",
      "502   (not, controvertible, ;, too, clear, or, certain, to, admit, of, dispute, ;, indisputable, .)                                                                                                      \n",
      "537   (lasting, or, continuing, through, the, year, ;, .)                                                                                                                                                \n",
      "2409  (to, originate, and, secure, the, permanent, existence, of, ;, to, found, ;, to, institute, ;, to, create, and, regulate, ;, --, said, of, a, colony, ,, a, state, ,, or, other, institutions, .)  \n",
      "175   (to, sanction, ;, to, invest, ;, to, intrust, .)                                                                                                                                                   \n",
      "\n",
      "[2000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def first_word_same(row):\n",
    "    return row['def1'].split(' ')[0].lower() == row['def2'].split(' ')[0].lower()\n",
    "\n",
    "\n",
    "def difference_in_length(row):\n",
    "    return abs(len(row['def1'].split(' ')) - len(row['def2'].split(' ')[0]))\n",
    "\n",
    "\n",
    "def jaccard_sim(row):\n",
    "    return get_jaccard_sim(row['def1'], row['def2'])\n",
    "\n",
    "\n",
    "def cosine(row):\n",
    "    return get_cosine_sim(row['def1'], row['def2'])[0, 1]\n",
    "\n",
    "\n",
    "\n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    vectorizer = CountVectorizer(text)\n",
    "    vectorizer.fit(text)\n",
    "    return vectorizer.transform(text).toarray()\n",
    "\n",
    "def pos_count(column):\n",
    "    pos = []\n",
    "    \n",
    "    for token in column:\n",
    "        pos.append(token.pos)\n",
    "    return list(set(pos))\n",
    "        \n",
    "    \n",
    "def diff_pos_count(row):\n",
    "    pos_def1 = pos_count(row['processed_1'])\n",
    "    pos_def2 = pos_count(row['processed_2'])\n",
    "    \n",
    "    return  len(pos_def1) - len(pos_def2)\n",
    "    \n",
    "\n",
    "\n",
    "def extract_features(data, feats_to_scale):\n",
    "    def sentence2vec(row):\n",
    "        return row['processed_1'].similarity(row['processed_2'])\n",
    "\n",
    "    feat = pd.DataFrame()\n",
    "    print(data)\n",
    "    feat['similarities'] = data.apply(lambda row: sentence2vec(row), axis=1)\n",
    "    feat['first_word_same'] = data.apply(lambda row: first_word_same(row), axis=1)\n",
    "    feat['len_diff'] = data.apply(lambda row: difference_in_length(row), axis=1)\n",
    "    feat['jaccard'] = data.apply(lambda row: jaccard_sim(row), axis=1)\n",
    "    feat['cos'] = data.apply(lambda row: cosine(row), axis=1)\n",
    "    feat['diff_pos_count'] = data.apply(lambda row: diff_pos_count(row), axis = 1)\n",
    "\n",
    "    for c_name in feats_to_scale:\n",
    "        feat[c_name] = preprocessing.scale(feat[c_name])\n",
    "\n",
    "    return feat\n",
    "\n",
    "\n",
    "def get_cosine_sim(*strs):\n",
    "    vectors = [t for t in get_vectors(*strs)]\n",
    "    return cosine_similarity(vectors)\n",
    "\n",
    "\n",
    "def get_jaccard_sim(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "\n",
    "features = extract_features(balanced_en_data, ['similarities', 'len_diff','diff_pos_count'])\n",
    "#features['diff_pos_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarities</th>\n",
       "      <th>first_word_same</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>cos</th>\n",
       "      <th>diff_pos_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1371</td>\n",
       "      <td>1.744584</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.615278</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.578844</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.615278</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.912871</td>\n",
       "      <td>-0.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>-0.091787</td>\n",
       "      <td>False</td>\n",
       "      <td>0.164542</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>-1.607323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694</td>\n",
       "      <td>-1.112255</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.810232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5858</td>\n",
       "      <td>-0.080702</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.615278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.462506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5182</td>\n",
       "      <td>-0.273052</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.005187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>-0.082190</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.005187</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.150756</td>\n",
       "      <td>-1.225717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537</td>\n",
       "      <td>0.326806</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.810232</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.365148</td>\n",
       "      <td>0.300705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2409</td>\n",
       "      <td>0.422741</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.810232</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.160128</td>\n",
       "      <td>-1.225717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.022423</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.810232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.300705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      similarities  first_word_same  len_diff   jaccard       cos  \\\n",
       "1371  1.744584      True            -0.615278  0.800000  1.000000   \n",
       "1290  1.578844      False           -0.615278  0.571429  0.912871   \n",
       "204  -0.091787      False            0.164542  0.090909  0.066815   \n",
       "694  -1.112255      False           -0.810232  0.000000  0.000000   \n",
       "5858 -0.080702      False           -0.615278  0.000000  0.000000   \n",
       "...        ...        ...                 ...       ...       ...   \n",
       "5182 -0.273052      False           -1.005187  0.000000  0.000000   \n",
       "502  -0.082190      False           -1.005187  0.071429  0.150756   \n",
       "537   0.326806      True            -0.810232  0.200000  0.365148   \n",
       "2409  0.422741      False           -0.810232  0.041667  0.160128   \n",
       "175   0.022423      False           -0.810232  0.000000  0.433013   \n",
       "\n",
       "      diff_pos_count  \n",
       "1371  0.682311        \n",
       "1290 -0.080900        \n",
       "204  -1.607323        \n",
       "694  -0.080900        \n",
       "5858 -0.462506        \n",
       "...        ...        \n",
       "5182  0.300705        \n",
       "502  -1.225717        \n",
       "537   0.300705        \n",
       "2409 -1.225717        \n",
       "175   0.300705        \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_data(df_features, labels):\n",
    "    data_holder = {'nltk': {}, 'pd': {}}\n",
    "\n",
    "    features_nltk = convert_to_nltk_dataset(df_features, labels)\n",
    "    data_holder['nltk']['trainset'], data_holder['nltk']['testset'] = split_data(features_nltk)\n",
    "    data_holder['pd']['x_trainset'], data_holder['pd']['x_testset'] = split_data(df_features)\n",
    "    data_holder['pd']['y_trainset'], data_holder['pd']['y_testset'] = split_data(labels)\n",
    "\n",
    "    return data_holder\n",
    "\n",
    "\n",
    "def convert_to_nltk_dataset(feats, labels):\n",
    "    converted = []\n",
    "    for index, row in feats.iterrows():\n",
    "        converted.append((row.to_dict(), labels[index]))\n",
    "    return converted\n",
    "\n",
    "\n",
    "def split_data(featuresets):\n",
    "    f = int(len(featuresets) / 5)\n",
    "    return featuresets[f:], featuresets[:f]\n",
    "\n",
    "all_train_and_testset = prepare_data(features, balanced_en_data['relation'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, with_testset=False):\n",
    "    #train_and_test_classifiers(data['nltk']['trainset'], data['nltk']['testset'])\n",
    "    trained_models = train_models_sklearn(data['pd']['x_trainset'],\n",
    "                                          data['pd']['y_trainset'])\n",
    "    cross_val_models(trained_models, data['pd']['x_trainset'],\n",
    "                     data['pd']['y_trainset'])\n",
    "\n",
    "    if with_testset:\n",
    "        compare_on_testset(trained_models, data['pd']['x_testset'],\n",
    "                           data['pd']['y_testset'])\n",
    "\n",
    "        \n",
    "\n",
    "def cross_val_models(models, x_train, y_train):\n",
    "    for estimator in models:\n",
    "        run_cv_with_dataset(estimator, x_train, y_train)\n",
    "\n",
    "        \n",
    "#def train_and_test_classifiers(train_set, test_set):\n",
    "    #decision_tree = nltk.DecisionTreeClassifier.train(train_set)\n",
    "    #naive_bayes = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    #metrics([decision_tree, naive_bayes], test_set)\n",
    "    # naive_bayes.show_most_informative_features(5)\n",
    "\n",
    "    # quite slow\n",
    "    # max_ent = nltk.MaxentClassifier.train(train_set, trace=-1)\n",
    "    # print(nltk.classify.accuracy(max_ent, test_set))\n",
    "    # max_ent.show_most_informative_features(5)\n",
    "    # print('\\n')\n",
    "\n",
    "    \n",
    "def run_cv_with_dataset(model, trainset, y_train):\n",
    "    scores = cross_val_score(model, trainset, y_train, cv=5)\n",
    "    print('Cross validation scores for model' + model.__class__.__name__ + '\\n')\n",
    "    print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2) + '\\n')\n",
    "\n",
    "        \n",
    "def train_models_sklearn(x_train, y_train):\n",
    "    lr = {'estimator': LogisticRegression(), 'parameters': {}}\n",
    "    svm_model = {\n",
    "        'estimator': SVC(),\n",
    "        'parameters': {\n",
    "            'C': [3, 5, 10],\n",
    "            'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        }\n",
    "    }\n",
    "    rf = {\n",
    "        'estimator': RandomForestClassifier(),\n",
    "        'parameters': {\n",
    "            'bootstrap': [True],\n",
    "            'max_depth': [2, 3, 5, 7, 10],\n",
    "            'max_features': [2, 3],\n",
    "            'min_samples_leaf': [3, 4, 5],\n",
    "            'min_samples_split': [2, 5, 8, 10, 12],\n",
    "            'n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    }\n",
    "    dt = {'estimator': DecisionTreeClassifier(), 'parameters': {}}\n",
    "\n",
    "    models = {'unscaled': [svm_model,rf]}\n",
    "\n",
    "    tuned_models = tune_hyperparams(models, x_train, y_train)\n",
    "\n",
    "    return tuned_models\n",
    "\n",
    "\n",
    "def tune_hyperparams(estimators, x_train, y_train):\n",
    "    result = []\n",
    "    for estimator in estimators['unscaled']:\n",
    "        params = estimator['parameters']\n",
    "\n",
    "        scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "        for score in scores:\n",
    "            print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "            print()\n",
    "\n",
    "            grid_search = GridSearchCV(estimator=estimator['estimator'], param_grid=params,\n",
    "                                       scoring='%s_weighted' % score, cv=5,\n",
    "                                       n_jobs=-1, verbose=1)\n",
    "\n",
    "            print(\"Performing grid search...\")\n",
    "            print(\"parameters:\")\n",
    "            pprint(params)\n",
    "            grid_search.fit(x_train, y_train)\n",
    "            print()\n",
    "\n",
    "            means = grid_search.cv_results_['mean_test_score']\n",
    "            stds = grid_search.cv_results_['std_test_score']\n",
    "            print('Precision: \\n')\n",
    "            #for mean, std, parameters in zip(means, stds, grid_search.cv_results_['params']):\n",
    "            #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            #                      % (mean, std * 2, parameters) + '\\n')\n",
    "\n",
    "            print(\"Best score: %0.3f\" % grid_search.best_score_ + '\\n')\n",
    "            print(\"Best parameters set:\\n\")\n",
    "            best_parameters = grid_search.best_estimator_.get_params()\n",
    "            for param_name in sorted(params.keys()):\n",
    "                print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]) + '\\n')\n",
    "\n",
    "            result.append(grid_search.best_estimator_)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'C': [3, 5, 10], 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    3.4s finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.460\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tC: 3\n",
      "\n",
      "\tkernel: 'rbf'\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'C': [3, 5, 10], 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.8s finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.579\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tC: 3\n",
      "\n",
      "\tkernel: 'rbf'\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'C': [3, 5, 10], 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.9s finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.511\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tC: 3\n",
      "\n",
      "\tkernel: 'rbf'\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  1.2min finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.507\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 10\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 5\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2075 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.576\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 5\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 3\n",
      "\n",
      "\tmin_samples_split: 10\n",
      "\n",
      "\tn_estimators: 100\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Performing grid search...\n",
      "parameters:\n",
      "{'bootstrap': [True],\n",
      " 'max_depth': [2, 3, 5, 7, 10],\n",
      " 'max_features': [2, 3],\n",
      " 'min_samples_leaf': [3, 4, 5],\n",
      " 'min_samples_split': [2, 5, 8, 10, 12],\n",
      " 'n_estimators': [50, 100, 200]}\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  1.1min finished\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: \n",
      "\n",
      "Best score: 0.511\n",
      "\n",
      "Best parameters set:\n",
      "\n",
      "\tbootstrap: True\n",
      "\n",
      "\tmax_depth: 5\n",
      "\n",
      "\tmax_features: 2\n",
      "\n",
      "\tmin_samples_leaf: 4\n",
      "\n",
      "\tmin_samples_split: 12\n",
      "\n",
      "\tn_estimators: 50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelSVC\n",
      "\n",
      "Accuracy: 0.5787 (+/- 0.0463)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelSVC\n",
      "\n",
      "Accuracy: 0.5787 (+/- 0.0463)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelSVC\n",
      "\n",
      "Accuracy: 0.5787 (+/- 0.0463)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5669 (+/- 0.0364)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5688 (+/- 0.0509)\n",
      "\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "\n",
      "Accuracy: 0.5737 (+/- 0.0500)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(all_train_and_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      similarities  first_word_same  len_diff   jaccard       cos  \\\n",
      "5923  0.716651      True            -0.810232  0.142857  0.572078   \n",
      "13    0.590948      False           -0.225368  0.125000  0.408248   \n",
      "389  -1.417187      False           -0.030413  0.083333  0.167248   \n",
      "946   0.578868      False           -1.005187  0.066667  0.396059   \n",
      "596  -0.043193      False           -0.420323  0.000000  0.000000   \n",
      "...        ...        ...                 ...       ...       ...   \n",
      "5182 -0.273052      False           -1.005187  0.000000  0.000000   \n",
      "502  -0.082190      False           -1.005187  0.071429  0.150756   \n",
      "537   0.326806      True            -0.810232  0.200000  0.365148   \n",
      "2409  0.422741      False           -0.810232  0.041667  0.160128   \n",
      "175   0.022423      False           -0.810232  0.000000  0.433013   \n",
      "\n",
      "      diff_pos_count  \n",
      "5923 -0.462506        \n",
      "13    0.300705        \n",
      "389   1.445522        \n",
      "946   0.682311        \n",
      "596   0.682311        \n",
      "...        ...        \n",
      "5182  0.300705        \n",
      "502  -1.225717        \n",
      "537   0.300705        \n",
      "2409 -1.225717        \n",
      "175   0.300705        \n",
      "\n",
      "[1600 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungbinyim/opt/anaconda3/lib/python3.7/site-packages/yellowbrick/features/rankd.py:216: YellowbrickWarning: RankD plots may be clipped when using matplotlib v3.1.1, upgrade to matplotlib v3.1.2 or later to fix the plots.\n",
      "  warnings.warn(msg, YellowbrickWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe27a50cfd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.features import Rank2D\n",
    "from yellowbrick.datasets import load_credit\n",
    "\n",
    "# Instantiate the visualizer with the Pearson ranking algorithm\n",
    "visualizer = Rank2D(algorithm='pearson')\n",
    "\n",
    "X = all_train_and_testset['pd']['x_trainset']\n",
    "print(X)\n",
    "X = X[['similarities','len_diff','jaccard','cos','diff_pos_count']]\n",
    "\n",
    "visualizer.fit(X, all_train_and_testset['pd']['y_trainset'])  \n",
    "visualizer.transform(X) \n",
    "visualizer.show()\n",
    "# Fit the data to the visualizer\n",
    "#visualizer.transform(X)        # Transform the data\n",
    "#visualizer.show()              # Finalize and render the figure         # Finalize and render the figure\n",
    "\n",
    "#visualizer = Rank2D(algorithm=\"pearson\")\n",
    "#visualizer.fit_transform(all_train_and_testset['pd']['x_trainset'])\n",
    "#visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-79b766c869ff>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-79b766c869ff>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    eaf=4, min_samples_split=5, n_estimators=50)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = RandomForestClassifier(max_depth=10, max_features=3, min_samples_la\n",
    "                               eaf=4, min_samples_split=5, n_estimators=50)\n",
    "visualizer = ClassificationReport(model)\n",
    "visualizer.fit(all_train_and_testset['pd']['x_trainset'], all_train_and_testset['pd']['y_trainset'])\n",
    "visualizer.score(all_train_and_testset['pd']['x_testset'], all_train_and_testset['pd']['y_testset'])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'narrower', 'exact', 'related', 'none', 'broader'}\n"
     ]
    }
   ],
   "source": [
    "all_data = load_training_data()\n",
    "en_data = all_data['english_kd']\n",
    "print(set(en_data['relation']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a2e92c170780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pattern'"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "#import pattern.en\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#from pattern.en import tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def pos_tag_text(text):\n",
    "    \n",
    "    def penn_to_wn_tags(pos_tag):\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    tagged_text = tag(text)\n",
    "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
    "                         for word, pos_tag in\n",
    "                         tagged_text]\n",
    "    return tagged_lower_text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [wnl.lemmatize(word, pos_tag) if pos_tag\n",
    "                         else word                     \n",
    "                         for word, pos_tag in pos_tagged_text]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "lemmatized = lemmatize_text(en_data['def1'][0])\n",
    "lemmatized\n",
    "\n",
    "#stopwords = remove_stopwords(en_data['def1'][0])\n",
    "\n",
    "#tokens = tokenize_text(lemma_stopwords)\n",
    "#tokens\n",
    "\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Text Classifier to the pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print only narrower relations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word          pos  \\\n",
      "0    off        preposition   \n",
      "3    off        preposition   \n",
      "8    off        preposition   \n",
      "13   off        preposition   \n",
      "15   off        adverb        \n",
      "..   ...           ...        \n",
      "530  on         preposition   \n",
      "551  on         preposition   \n",
      "552  one        number        \n",
      "553  one        number        \n",
      "554  offspring  noun          \n",
      "\n",
      "                                                    def1  \\\n",
      "0    away from and no longer touching                      \n",
      "3    in a position away from                               \n",
      "8    not inside a large vehicle used by the public         \n",
      "13   not eating or taking                                  \n",
      "15   away from a place                                     \n",
      "..                 ...                                     \n",
      "530  indicates sth or sb uses a type of food, fuel, etc.   \n",
      "551  immediately following                                 \n",
      "552  the number 1                                          \n",
      "553  the number 1                                          \n",
      "554  a person's child or an animal's baby                  \n",
      "\n",
      "                                               def2  relation  \n",
      "0    away from; down from                            narrower  \n",
      "3    away from; down from                            narrower  \n",
      "8    out of (a vehicle, train etc)                   exact     \n",
      "13   not wanting or allowed to have (food etc)       exact     \n",
      "15   away (from a place, time etc)                   narrower  \n",
      "..                             ...                        ...  \n",
      "530  receiving, taking                               exact     \n",
      "551  followed by                                     related   \n",
      "552  the number or figure 1                          exact     \n",
      "553  the age of 1                                    related   \n",
      "554  (formal, humorous) someone's child or children  broader   \n",
      "\n",
      "[108 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#df['def1']=df['def1'].str.wrap(20)\n",
    "is_narrower = en_data['relation']=='narrower'\n",
    "def is_not_none(df):\n",
    "    return df['relation']!='none'\n",
    "def is_none(df):\n",
    "    return df['relation']=='none'\n",
    "\n",
    "print(en_data[is_not_none])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Spacy NLP Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacyDocForVec(sentence):\n",
    "    return nlp(sentence)\n",
    "\n",
    "modDfObj = pd.DataFrame()\n",
    "en_data['processed_1'] = en_data['def1'].map(spacyDocForVec)\n",
    "en_data['processed_2'] = en_data['def2'].map(spacyDocForVec)\n",
    "#doc_list = spacyDocForVec(en_data['def1'])\n",
    "#doc_list2 = spacyDocForVec(en_data['def2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x7fe2b83aec10>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x7fe28ba5e360>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x7fe28ba5e600>)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>def1</th>\n",
       "      <th>def2</th>\n",
       "      <th>relation</th>\n",
       "      <th>processed_1</th>\n",
       "      <th>processed_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>away from; down from</td>\n",
       "      <td>narrower</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(away, from, ;, down, from)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>not wanting or allowed to have (food etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(not, wanting, or, allowed, to, have, (, food, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>out of (a vehicle, train etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(out, of, (, a, vehicle, ,, train, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in a position away from</td>\n",
       "      <td>away from; down from</td>\n",
       "      <td>narrower</td>\n",
       "      <td>(in, a, position, away, from)</td>\n",
       "      <td>(away, from, ;, down, from)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in a position away from</td>\n",
       "      <td>not wanting or allowed to have (food etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(in, a, position, away, from)</td>\n",
       "      <td>(not, wanting, or, allowed, to, have, (, food, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>on</td>\n",
       "      <td>preposition</td>\n",
       "      <td>immediately following</td>\n",
       "      <td>followed by</td>\n",
       "      <td>related</td>\n",
       "      <td>(immediately, following)</td>\n",
       "      <td>(followed, by)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>one</td>\n",
       "      <td>number</td>\n",
       "      <td>the number 1</td>\n",
       "      <td>the number or figure 1</td>\n",
       "      <td>exact</td>\n",
       "      <td>(the, number, 1)</td>\n",
       "      <td>(the, number, or, figure, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>one</td>\n",
       "      <td>number</td>\n",
       "      <td>the number 1</td>\n",
       "      <td>the age of 1</td>\n",
       "      <td>related</td>\n",
       "      <td>(the, number, 1)</td>\n",
       "      <td>(the, age, of, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>offspring</td>\n",
       "      <td>noun</td>\n",
       "      <td>a person's child or an animal's baby</td>\n",
       "      <td>(formal, humorous) someone's child or children</td>\n",
       "      <td>broader</td>\n",
       "      <td>(a, person, 's, child, or, an, animal, 's, baby)</td>\n",
       "      <td>((, formal, ,, humorous, ), someone, 's, child, or, children)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>offspring</td>\n",
       "      <td>noun</td>\n",
       "      <td>a person's child or an animal's baby</td>\n",
       "      <td>an animal's baby or babies</td>\n",
       "      <td>none</td>\n",
       "      <td>(a, person, 's, child, or, an, animal, 's, baby)</td>\n",
       "      <td>(an, animal, 's, baby, or, babies)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word          pos                                  def1  \\\n",
       "0    off        preposition  away from and no longer touching       \n",
       "1    off        preposition  away from and no longer touching       \n",
       "2    off        preposition  away from and no longer touching       \n",
       "3    off        preposition  in a position away from                \n",
       "4    off        preposition  in a position away from                \n",
       "..   ...                ...                      ...                \n",
       "551  on         preposition  immediately following                  \n",
       "552  one        number       the number 1                           \n",
       "553  one        number       the number 1                           \n",
       "554  offspring  noun         a person's child or an animal's baby   \n",
       "555  offspring  noun         a person's child or an animal's baby   \n",
       "\n",
       "                                               def2  relation  \\\n",
       "0    away from; down from                            narrower   \n",
       "1    not wanting or allowed to have (food etc)       none       \n",
       "2    out of (a vehicle, train etc)                   none       \n",
       "3    away from; down from                            narrower   \n",
       "4    not wanting or allowed to have (food etc)       none       \n",
       "..                                         ...        ...       \n",
       "551  followed by                                     related    \n",
       "552  the number or figure 1                          exact      \n",
       "553  the age of 1                                    related    \n",
       "554  (formal, humorous) someone's child or children  broader    \n",
       "555  an animal's baby or babies                      none       \n",
       "\n",
       "                                          processed_1  \\\n",
       "0    (away, from, and, no, longer, touching)            \n",
       "1    (away, from, and, no, longer, touching)            \n",
       "2    (away, from, and, no, longer, touching)            \n",
       "3    (in, a, position, away, from)                      \n",
       "4    (in, a, position, away, from)                      \n",
       "..                             ...                      \n",
       "551  (immediately, following)                           \n",
       "552  (the, number, 1)                                   \n",
       "553  (the, number, 1)                                   \n",
       "554  (a, person, 's, child, or, an, animal, 's, baby)   \n",
       "555  (a, person, 's, child, or, an, animal, 's, baby)   \n",
       "\n",
       "                                                       processed_2  \n",
       "0    (away, from, ;, down, from)                                    \n",
       "1    (not, wanting, or, allowed, to, have, (, food, etc, ))         \n",
       "2    (out, of, (, a, vehicle, ,, train, etc, ))                     \n",
       "3    (away, from, ;, down, from)                                    \n",
       "4    (not, wanting, or, allowed, to, have, (, food, etc, ))         \n",
       "..                                                      ...         \n",
       "551  (followed, by)                                                 \n",
       "552  (the, number, or, figure, 1)                                   \n",
       "553  (the, age, of, 1)                                              \n",
       "554  ((, formal, ,, humorous, ), someone, 's, child, or, children)  \n",
       "555  (an, animal, 's, baby, or, babies)                             \n",
       "\n",
       "[556 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import collections\n",
    "\n",
    "en_data['processed_1']\n",
    "print(nlp.pipeline)\n",
    "en_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['def1_nlp']=doc_list\n",
    "#df['def2_nlp']=doc_list2\n",
    "nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "     pos_count                                        lemmatized  \\\n",
      "0    4          (away, from, and, no, longer, touching)            \n",
      "1    4          (away, from, and, no, longer, touching)            \n",
      "2    4          (away, from, and, no, longer, touching)            \n",
      "3    4          (in, a, position, away, from)                      \n",
      "4    4          (in, a, position, away, from)                      \n",
      "..  ..                                    ...                      \n",
      "551  2          (immediately, follow)                              \n",
      "552  3          (the, number, 1)                                   \n",
      "553  3          (the, number, 1)                                   \n",
      "554  4          (a, person, 's, child, or, an, animal, 's, baby)   \n",
      "555  4          (a, person, 's, child, or, an, animal, 's, baby)   \n",
      "\n",
      "                        sw_removed  \n",
      "0    [away, longer, touching]       \n",
      "1    [away, longer, touching]       \n",
      "2    [away, longer, touching]       \n",
      "3    [position, away]               \n",
      "4    [position, away]               \n",
      "..                ...               \n",
      "551  [immediately, following]       \n",
      "552  [number, 1]                    \n",
      "553  [number, 1]                    \n",
      "554  [person, child, animal, baby]  \n",
      "555  [person, child, animal, baby]  \n",
      "\n",
      "[556 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "deps = collections.defaultdict(set)\n",
    "\n",
    "        \n",
    "def count_pos(row):\n",
    "    pos = []\n",
    "    for token in row['processed_1']:\n",
    "        pos.append(token.pos)\n",
    "        \n",
    "    \n",
    "    return len(list(set(pos)))\n",
    "    \n",
    "def remove_stopwords(row):\n",
    "    tokens = row['processed_1']\n",
    "    temp = ''\n",
    "    for token in tokens:\n",
    "        #print(type(row))\n",
    "        if token.is_stop == False:\n",
    "            temp = temp + token.lemma_ + ' '\n",
    "            \n",
    "    return temp\n",
    "    \n",
    "\n",
    "def filter_sw(lemmatized):\n",
    "    result = []\n",
    "    for token in lemmatized:\n",
    "        #print(type(row))\n",
    "        if token.is_stop == False:\n",
    "            result.append(token)\n",
    "            \n",
    "    return result\n",
    "    \n",
    "def lemmatize(row):\n",
    "    return ' '.join([token.lemma_ for token in row['processed_1']])\n",
    "\n",
    "\n",
    "def is_lemmatized(df):\n",
    "    return df['def1']!=df['lemmatized']\n",
    "\n",
    "def lemmatizer(doc):\n",
    "    # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "    # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)\n",
    "    \n",
    "def remove_stopwords(doc):\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc\n",
    "\n",
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "\n",
    "temp['pos_count'] = en_data.apply(lambda row: count_pos(row),axis=1)\n",
    "\n",
    "\n",
    "print(type(en_data['processed_1'][0]))\n",
    "temp['lemmatized'] = en_data.apply(lambda row: lemmatizer(row['processed_1']),axis=1)\n",
    "temp['sw_removed'] = en_data.apply(lambda row: remove_stopwords(row['processed_1']),axis=1)\n",
    "\n",
    "print(temp)\n",
    "#lemmatized_processed = temp['lemmatized'].map(spacyDocForVec)\n",
    "\n",
    "#sw_processed = lemmatized_processed.map(remove_stopwords['lemmatized'])\n",
    "\n",
    "#print(lemmatized_processed)\n",
    "#print(sw_processed)\n",
    "\n",
    "temp['def1'] = en_data['def1']\n",
    "\n",
    "#print_all_rows(temp[is_lemmatized(temp)])\n",
    "\n",
    "#for token in test:\n",
    "#    print(token.lemma_)\n",
    "\n",
    "#print(en_data['processed_1'])\n",
    "#nlp.vocab['a'].is_stop\n",
    "#en_data\n",
    "#print(len(count_distinct_pos))\n",
    "        #features['similarities'] = en_data.apply(lambda row: sentence2vec(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#modDfObj['def1'][0].sents\n",
    "label_count = en_data.groupby('relation').count().word.sort_values(ascending=False)\n",
    "\n",
    "label_count.plot(kind = 'bar')\n",
    "label_count[1]\n",
    "#label_count.plot(kind = 'bar', x = 'relation', y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>def1</th>\n",
       "      <th>def2</th>\n",
       "      <th>relation</th>\n",
       "      <th>processed_1</th>\n",
       "      <th>processed_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>away from; down from</td>\n",
       "      <td>narrower</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(away, from, ;, down, from)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>not wanting or allowed to have (food etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(not, wanting, or, allowed, to, have, (, food, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>away from and no longer touching</td>\n",
       "      <td>out of (a vehicle, train etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(away, from, and, no, longer, touching)</td>\n",
       "      <td>(out, of, (, a, vehicle, ,, train, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in a position away from</td>\n",
       "      <td>away from; down from</td>\n",
       "      <td>narrower</td>\n",
       "      <td>(in, a, position, away, from)</td>\n",
       "      <td>(away, from, ;, down, from)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>off</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in a position away from</td>\n",
       "      <td>not wanting or allowed to have (food etc)</td>\n",
       "      <td>none</td>\n",
       "      <td>(in, a, position, away, from)</td>\n",
       "      <td>(not, wanting, or, allowed, to, have, (, food, etc, ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>on</td>\n",
       "      <td>preposition</td>\n",
       "      <td>immediately following</td>\n",
       "      <td>followed by</td>\n",
       "      <td>related</td>\n",
       "      <td>(immediately, following)</td>\n",
       "      <td>(followed, by)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>one</td>\n",
       "      <td>number</td>\n",
       "      <td>the number 1</td>\n",
       "      <td>the number or figure 1</td>\n",
       "      <td>exact</td>\n",
       "      <td>(the, number, 1)</td>\n",
       "      <td>(the, number, or, figure, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>one</td>\n",
       "      <td>number</td>\n",
       "      <td>the number 1</td>\n",
       "      <td>the age of 1</td>\n",
       "      <td>related</td>\n",
       "      <td>(the, number, 1)</td>\n",
       "      <td>(the, age, of, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>offspring</td>\n",
       "      <td>noun</td>\n",
       "      <td>a person's child or an animal's baby</td>\n",
       "      <td>(formal, humorous) someone's child or children</td>\n",
       "      <td>broader</td>\n",
       "      <td>(a, person, 's, child, or, an, animal, 's, baby)</td>\n",
       "      <td>((, formal, ,, humorous, ), someone, 's, child, or, children)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>offspring</td>\n",
       "      <td>noun</td>\n",
       "      <td>a person's child or an animal's baby</td>\n",
       "      <td>an animal's baby or babies</td>\n",
       "      <td>none</td>\n",
       "      <td>(a, person, 's, child, or, an, animal, 's, baby)</td>\n",
       "      <td>(an, animal, 's, baby, or, babies)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word          pos                                  def1  \\\n",
       "0    off        preposition  away from and no longer touching       \n",
       "1    off        preposition  away from and no longer touching       \n",
       "2    off        preposition  away from and no longer touching       \n",
       "3    off        preposition  in a position away from                \n",
       "4    off        preposition  in a position away from                \n",
       "..   ...                ...                      ...                \n",
       "551  on         preposition  immediately following                  \n",
       "552  one        number       the number 1                           \n",
       "553  one        number       the number 1                           \n",
       "554  offspring  noun         a person's child or an animal's baby   \n",
       "555  offspring  noun         a person's child or an animal's baby   \n",
       "\n",
       "                                               def2  relation  \\\n",
       "0    away from; down from                            narrower   \n",
       "1    not wanting or allowed to have (food etc)       none       \n",
       "2    out of (a vehicle, train etc)                   none       \n",
       "3    away from; down from                            narrower   \n",
       "4    not wanting or allowed to have (food etc)       none       \n",
       "..                                         ...        ...       \n",
       "551  followed by                                     related    \n",
       "552  the number or figure 1                          exact      \n",
       "553  the age of 1                                    related    \n",
       "554  (formal, humorous) someone's child or children  broader    \n",
       "555  an animal's baby or babies                      none       \n",
       "\n",
       "                                          processed_1  \\\n",
       "0    (away, from, and, no, longer, touching)            \n",
       "1    (away, from, and, no, longer, touching)            \n",
       "2    (away, from, and, no, longer, touching)            \n",
       "3    (in, a, position, away, from)                      \n",
       "4    (in, a, position, away, from)                      \n",
       "..                             ...                      \n",
       "551  (immediately, following)                           \n",
       "552  (the, number, 1)                                   \n",
       "553  (the, number, 1)                                   \n",
       "554  (a, person, 's, child, or, an, animal, 's, baby)   \n",
       "555  (a, person, 's, child, or, an, animal, 's, baby)   \n",
       "\n",
       "                                                       processed_2  \n",
       "0    (away, from, ;, down, from)                                    \n",
       "1    (not, wanting, or, allowed, to, have, (, food, etc, ))         \n",
       "2    (out, of, (, a, vehicle, ,, train, etc, ))                     \n",
       "3    (away, from, ;, down, from)                                    \n",
       "4    (not, wanting, or, allowed, to, have, (, food, etc, ))         \n",
       "..                                                      ...         \n",
       "551  (followed, by)                                                 \n",
       "552  (the, number, or, figure, 1)                                   \n",
       "553  (the, age, of, 1)                                              \n",
       "554  ((, formal, ,, humorous, ), someone, 's, child, or, children)  \n",
       "555  (an, animal, 's, baby, or, babies)                             \n",
       "\n",
       "[556 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t1 = doc_list2[0]\n",
    "#for token in doc_list2[0]\n",
    "#    print(token.text, \"| lemma:\", token.lemma_, \"| norm:\" , token.norm_, \"| pos:\" ,token.pos_, \"| tag:\", token.tag_, \"| dep:\", token.dep_, \"| sentiment:\", token.sentiment)\n",
    "en_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     similarities  first_word_same  len_diff   jaccard  pos_diff\n",
      "0    0.856918      True             2         0.250000  0       \n",
      "1    0.776428      False            3         0.000000  0       \n",
      "2    0.732969      False            3         0.000000  0       \n",
      "3    0.836521      False            1         0.285714  0       \n",
      "4    0.689816      False            2         0.000000  0       \n",
      "..        ...        ...           ..              ... ..       \n",
      "551  0.615553      False            6         0.000000  0       \n",
      "552  0.915048      True             0         0.600000  0       \n",
      "553  0.822070      True             0         0.400000  0       \n",
      "554  0.850947      False            1         0.181818  0       \n",
      "555  0.934649      False            5         0.500000  0       \n",
      "\n",
      "[556 rows x 5 columns]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-38b9226a06c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jaccard'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'len_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#for i, row in en_data.iterrows():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#    similarities.append(sentence2Vec(row))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mkde\u001b[0;34m(self, bw_method, ind, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \"\"\"\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kde\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_legend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/hist.py\u001b[0m in \u001b[0;36m_make_plot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0martists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacking_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacking_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_legend_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/plotting/_matplotlib/hist.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(cls, ax, y, style, bw_method, ind, column_num, stacking_id, **kwds)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_na_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mgkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgkde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m                                                \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                                                aweights=self.weights))\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0minv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         raise ValueError('illegal value in %d-th argument of internal '\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFJCAYAAAChG+XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3xU9Z3/8feZa+4JV0VQBITSGqwlble7aLVdquvDVqXSqi3ulq62Xh7IVm2VsqxVFPpQ99eu7kp/du2F9ddKrbV2feh2tVbFW+0IaJCbBVQgQoCQkNvczvn9MclkkkxOjsg5czLzej4eMZmTmTkfv4958M73cr7HsCzLEgAA8I1AoQsAAAD9Ec4AAPgM4QwAgM8QzgAA+AzhDACAz4QKXYAkmaapjo4OhcNhGYZR6HIAAHCVZVlKJpOqrKxUIDC4n+yLcO7o6NDWrVsLXQYAAJ6aMWOGqqurBx33RTiHw2FJmSIjkUiBqzlyjY2Nqq+vL3QZvkYb2aN9hkcb2aN97PmlfRKJhLZu3ZrNv4F8Ec69Q9mRSETRaLTA1Xw4I71+L9BG9mif4dFG9mgfe35qn6GmclkQBgCAz7jWc04mk7r55pu1e/duBQIB3X777Zo2bZpbpwMAoGi41nN+7rnnlEql9Mtf/lLXXnutfvCDH7h1KgAAiopr4TxlyhSl02mZpqn29naFQr6Y3gYAwPcMt+5K1dTUpGuuuUadnZ1qaWnRqlWrNHv27LzPjcfjamxsdKMMAAB8q76+Pu8CNde6sz/96U81Z84c3XDDDWpqatLf//3f63e/+53tKrmhihwpYrGYGhoaCl2Gr9FG9mif4dFG9mgfe35pn+E6pa6Fc01NTfb6rdraWqVSKaXTabdOBwBA0XAtnP/hH/5BS5Ys0eWXX65kMql/+qd/UkVFhVunAwCgaLgWzpWVlfrhD3/o1tsDAFC0WEINT1iWpe3N65Wy4oUuBQB8jx3C4Il3D2zUC1sf1s74C4UuBQB8j3CGJ9rjLZKkLqulwJUAgP8RzvCEabFSHwCcIpzhCdMyC10CAIwYhDM8YSj/bdEAAIMRzvAI4QwAThHO8MQQ9xMHAORBOMMTDGsDgHOEMzxCOAOAU4QzPGEwrg0AjhHOAAD4DOEMj9BzBgCnCGd4gmgGAOcIZ3iDOWcAcIxwBgDAZwhnAAB8hnAGAMBnCGd4ghlnAHCOcAYAwGcIZwAAfIZwBgDAZwhnAAB8hnAGAMBnCGcAAHyGcAYAwGdCbr3xo48+qt/85jeSpHg8rk2bNunFF19UTU2NW6cEAKAouBbO8+bN07x58yRJ3/ve9/TFL36RYAYAwAHXh7XffPNNvf322/ryl7/s9qkAACgKhmVZlpsnuO666/TVr35Vp59++pDPicfjamxsdLMMFNj+1DY1JddLkmaVzy9wNQDgD/X19YpGo4OOuzasLUltbW3avn27bTDnGqrIkSIWi6mhoaHQZfjSpj3datqeCWfaaGh8hoZHG9mjfez5pX2G65S6Oqz92muv6VOf+pSbpwAAoOi4Gs47duzQpEmT3DwFRghX504AoMi4Oqz9j//4j26+PUYSd5c2AEBRYRMSeIJoBgDnCGd4hHgGAKcIZwAAfIZwhidcvpweAIoK4QwAgM8QzvAIPWcAcIpwhieIZgBwjnCGJ5hzBgDnCGd4hHAGAKcIZwAAfIZwhicses4A4BjhDG8w5wwAjhHOAAD4DOEMTzCsDQDOEc4AAPgM4QxPcJ0zADhHOAMA4DOEMzxCzxkAnCKc4QmiGQCcI5zhEeIZAJwinOENshkAHCOc4QmucwYA5whneIJwBgDnCGd4g2wGAMcIZ3iEdAYApwhneIJoBgDnCGd4hHgGAKdCbr75j370I/3hD39QMpnUZZddpvnz57t5OvgZe2sDgGOuhfOrr76qdevW6Re/+IW6urr04IMPunUqjABEMwA451o4r127VjNmzNC1116r9vZ2ffvb33brVBgRiGcAcMqwXLqX39KlS7Vnzx6tWrVKu3bt0tVXX62nnnpKhmEMem48HldjY6MbZcAn9iTW60B6myRpVjnTGwAgSfX19YpGo4OOu9Zzrqur09SpUxWJRDR16lRFo1EdPHhQY8aM+cBFjhSxWEwNDQ2FLsOXUn/ZrQNNmXCmjYbGZ2h4tJE92seeX9pnuE6pa6u1Gxoa9MILL8iyLO3du1ddXV2qq6tz63QAABQN13rO55xzjl577TVdcsklsixLy5YtUzAYdOt08Dm27wQA51y9lIpFYAAAfHBsQgKP0HMGAKcIZ3jCpYsCAKAoEc7wBNEMAM4RzvAI8QwAThHO8AbZDACOEc7wBJdSAYBzhDM8QjgDgFOEMwAAPkM4wxNcSgUAzhHOAAD4DOEMT7AgDACcI5wBAPAZwhneYM4ZABwjnOEJohkAnCOc4RHiGQCcIpzhCRaEAYBzhDO8QTYDgGOEMzyR23NmQxIAsEc4w3MMcQOAPcIZHrGG+BkAMBDhDE9YZDMAOEY4wyM5c86kMwDYIpzhEcIZAJwinOEJa8gHAICBCGd4g0lnAHCMcIYniGYAcI5whkdyIplNSADAVsjNN7/oootUXV0tSZo0aZJWrFjh5ukwQrAgDADsuRbO8XhckrR69Wq3ToERhC07AcA514a1N2/erK6uLi1cuFBXXHGF1q9f79apMMJYMgtdAgD4mmG51KXZsmWLNmzYoPnz52vnzp268sor9dRTTykUGtxZj8fjamxsdKMM+MTO+As6bL4vSfpo2YUKGZECVwQAhVdfX69oNDrouGvD2lOmTNHkyZNlGIamTJmiuro6NTc3a8KECR+4yJEiFoupoaGh0GX4UsvGN3S4JRPOH//4KSoLVxa4In/iMzQ82sge7WPPL+0zXKfUtWHtRx55RCtXrpQk7d27V+3t7Ro3bpxbp4PPMeMMAM651nO+5JJLdMstt+iyyy6TYRi688478w5po1RwP2cAcMq1tIxEIrrnnnvcenuMMBb7dwKAY2xCAo9YeX4CAORDOMN7DGsDgC3CGZ5jhzAAsEc4wxMEMgA4RzjDGywIAwDHCGd4hEupAMApwhmesPqt1iacAcAO4QwAgM8QzigAes4AYIdwhidy55mZcwYAe4QzAAA+QzjDIywIAwCnCGd4IjeOGdYGAHuEMzxCIAOAU4QzvMEOYQDgGOEMzzGqDQD2CGd4ov8iMNIZAOw4Cucf//jHam5udrsWlAhWawOAPUfh3N3drQULFuiqq67Sk08+qWQy6XZdKDL9AplxbQCw5Sicr7vuOj311FO66qqr9Oqrr+rCCy/Ubbfdpk2bNrldH4pFbjbTcwYAW47nnDs7O7Vr1y699957CgQCqq2t1R133KF77rnHzfpQNAhkAHAq5ORJN954o1555RWdddZZuvrqq3XaaadJkhKJhObMmaMbbrjB1SJRXOg5A4A9R+F8+umn67bbblNFRUX2WCKRUCQS0RNPPOFacSgeXOYMAM45Gtb+1a9+1S+YTdPUF7/4RUnSuHHj3KkMRYa9tQHAKdue8xVXXKE//elPkqSZM2f2vSgU0mc+8xl3K0NxoesMAI7ZhvPPf/5zSdLy5cu1dOlSTwpCccrtLXMlFQDYsw3nZ599Vuecc45OPvlkPfbYY4N+f9FFF7lWGIoNO4QBgFO24fzmm2/qnHPOyQ5tDzRcOB84cEDz5s3Tgw8+qGnTph15lSgqzDkDgD3bcF60aJEkacWKFdlj7e3tampq0vTp023fOJlMatmyZSorKzsKZWKkY8oZAJxzvFr75ptv1sGDB3X++edr0aJFWrVqle1rvv/97+vSSy/V+PHjj0qhGOEshrUBwCnDsoZfnjNv3jytWrVKTz31lHbs2KHvfve7+tKXvqRHH3007/MfffRRvf/++7rmmmu0YMEC3XrrrbbD2vF4XI2NjUf+fwHf29b9e3VbrZKkKZGzVRXkEjwAqK+vVzQaHXTc0SYkkjR+/Hg999xzuuKKKxQKhRSPx4d87q9//WsZhqGXX35ZmzZt0ne+8x3df//9w14TPVSRI0UsFlNDQ0Ohy/Cl915/Xt2dmXCeMWO6JtSxBiEfPkPDo43s0T72/NI+w3VKHYXzSSedpG984xvatWuXzjjjDC1evFizZs0a8vkPPfRQ9ufenjOblQAA4IyjcL7zzju1bt06TZ8+XZFIRF/4whf06U9/2u3aUFSYcwYApxyFc2dnp7Zu3ao//elP6p2ifuutt3TdddcN+9rVq1d/uApRdLiUCgDsOQrn66+/XtXV1Zo+fboMw3C7JhQhFmsDgHOOwnn//v36yU9+4nYtKGrc+AIAnHJ0nfNHP/pRbd682e1aUMSIYwBwzlHPedu2bbr44os1ZswYRaNRWZYlwzD0zDPPuF0fikbujS+IagCw4yic77vvPrfrQLFj/04AcMzRsPbEiRP1+uuva82aNRo9erRee+01TZw40e3aUKSIZgCw5yic7777bj333HP6/e9/r3Q6rV//+tdauXKl27WhiPRbBGaZhSsEAEYAR+G8du1a3XXXXYpGo6qqqtJPfvITPf/8827XhiJFzxkA7DkK50Cg/9MSicSgY4A9LnQGAKccLQg777zztHjxYrW1temnP/2pfvvb3+qCCy5wuzYUkdwF2kQzANhzFM5nn322xo8fr/fee0+xWEzXX3+9zj77bJdLQ3HJTWfiGQDs2IbzgQMHtGjRIr399tuaPHmyQqGQXnnlFXV3d6uhoUHV1dVe1Ykiwg5hAGDPduL4nnvuUUNDg9auXas1a9ZozZo1eumllzRz5kzdcccdXtWIIkAgA4Bztj3ndevW6cknn+x3LBwO61vf+pYuvPBCVwtD8WKHMACwZ9tzjkajeY8bhsFqbXxArNYGAKdsE9bu9pDcOhIfBKu1AcA522Htbdu26bOf/eyg45Zlqbm52bWiUIzoOQOAU7bh/D//8z9e1YESwpwzANizDWdubgEAgPdY1QVPWAxrA4BjhDO80W+DMMIZAOwQzvBEbs+ZDUkAwB7hDACAzxDO8Ag3vgAApwhneI5hbQCwRzjDE3SWAcA5whkeyVkQRlIDgC3bTUg+jHQ6raVLl2rHjh0KBoNasWKFTjjhBLdOhxHEklnoEgDA11zrOT/77LOSpF/+8pdatGiRVqxY4dapMALkzjObFuEMAHZc6zn/7d/+rc4++2xJ0p49ezR27Fi3ToWRwMod1iacAcCOYbk8Afid73xH//u//6t/+7d/05w5c/I+Jx6Pq7Gx0c0yUGAbux6TqaQk6djQLI0LzyxwRQBQePX19YpGo4OOux7OktTc3KwvfelLeuKJJ1RRUTHo973hPFSRI0UsFlNDQ0Ohy/Clh16+Vcl0tyRp9uRzdcrx5xS4In/iMzQ82sge7WPPL+0zXO65Nuf82GOP6Uc/+pEkqby8XIZhKBgMunU6+F7unHO6gHUAgP+5Nuf8uc99Trfccou+8pWvKJVKacmSJSO6V4yjhzlnALDnWjhXVFTohz/8oVtvjxGG1doA4BybkMAb/bbWJpwBwA7hDI9YkgxJ9JwBYDiEMzwTMDIfN3rOAGCPcIYnLPWFMz1nALBHOMMjlgwjcykdPWcAsEc4wxOWJQV6wpnrnAHAHuEMj1gKBJhzBgAnCGd4JttzHuaWkfFUWpetfl4///NfvCgLAHyHcIZnAg7nnNfvPqg169/R137xkhdlAYDvEM7whCVLRu9qbdN+znnv4W4vSgIA3yKc4Q1LCjpcELavvS+c4ykWjwEoPYQzPGIpGAhLktLDhHNzTjgf6kq4WhUA+BHhDE9YkgKBnp6zmbJ9bnNHXzi3dBLOAEoP4QyPWDIkGQooPcyc876cOecWes4AShDhDA8ZMhSQadn3nHPnnFu7CWcApYdwhqec9Jyb2+PZn7uSLAgDUHoIZ7jOsvpu5mwo+IF6zh0J++cCQDEinOGBTDgbhiHDsO85m6bVb0FYJ+EMoAQRznCdlfNzYJg555auhNKmJcPIPCacAZQiwhke6Ok59ywIS9tcSvX+4S5J0omjqiRJncw5AyhBhDPcl+06GzIUtB3WbmrLhPO0sdWS6DkDKE2EM7xjSIYRkGml+y0Sy9Ubzif1hDMLwgCUIsIZrrOUu1o7kDkyxJ2pmto6JfWFc2eScAZQeghneCYz45z5yKWHWBTW23OeOqan5xwnnAGUHsIZrhvccx76tpEDh7VZEAagFBHOcF/ugrCe20YO1XN+/3CXAoah4+sqJHHLSAClKeTWGyeTSS1ZskS7d+9WIpHQ1Vdfrc9+9rNunQ6+1rsJSV/PeajLqQ52xlVXHlZFOPPRTKTyz00DQDFzLZwff/xx1dXV6a677lJLS4suvvhiwrnkGcMOax/qSqquPKJQMKCAYdBzBlCSXAvn8847T+eee272cTAYdOtU8Lnci6ay4WwNFc4JzRxfI0kqCwfUTTgDKEGuhXNlZaUkqb29XYsWLdLixYvdOhV8r3eHMCnQO+ecZ1g7mTbVkUiprjwiSYoGg4ozrA2gBLkWzpLU1NSka6+9Vpdffrk+//nPD/v8xsZGN8vxRCwWK3QJvpO2kpKk1tY2lQVqJUlvbdqoyuDefs871J0JbKu7Q7FYTAHLVGtHZ8m1aan9/x4J2sge7WNvJLSPa+G8f/9+LVy4UMuWLdMZZ5zh6DX19fWKRqNuleS6WCymhoaGQpfhO4lUt9565THV1tYqcTgzrD19xkmaUDet3/Pe3t8maatOnHCMGhoaVPXkO7KkkmpTPkPDo43s0T72/NI+8XjctkPq2qVUq1atUltbm/7jP/5DCxYs0IIFC9Td3T38C1G0DKNvQVi+S6kOdWV62Nlh7VCQBWEASpJrPeelS5dq6dKlbr09RihDmTlnM8+c86GuhCSprjwsSSoLBbWPOWcAJYhNSOC6fjuEGUOv1u4L596ec4CeM4CSRDjDA73hnLO3dp7rnHvDuTZnWLs7NfQdrACgWBHOcF1vuPabc84zrN2ap+dsWVLKJJwBlBbCGZ4xZPTNOedbENbdE85lmXCOhDLPZWgbQKkhnOG6vmFpIzvnnH9Yu3e1dt+CMElsRAKg5Li6CQmQ0Tesrez2nXartfuGtSV6zgBKDz1nuC53tXbAZs55cDgzrA2gNBHOcF9PNucuCMt3KVVrV0LBgKHKSGZAp6/nzLA2gNJCOMN1VvbGF4aM7I0vBodzS1dCdWWRnuHvvp4zd6YCUGoIZ3ggZ0FY9n7O+Ye1e4e0pdwFYYQzgNJCOMN1+a5zzrtDWHciu1JbYlgbQOkinOG6ftt3DhHOiVRanYl0v54zC8IAlCrCGR7ImXMeYvvO1u7MNc61OeEcCfb0nNP0nAGUFsIZrus3rG3kv845exlVWW7PmeucAZQmwhkeGvrGFwOvcZZyt++k5wygtBDOcF2256yhF4QNvJezJEWDzDkDKE2EM1xn9e1CknMp1YBw7u7dVzvfsDY9ZwClhXCGB3p7zr3/NYacc67Ns1o7Qc8ZQIkhnOE6K3f7TsNQwAgOXq2dZ86ZnjOAUkU4wwN9O4RJUjAQdLhau2fOOU3PGUBpIZzhuty9tSUpYASdLQjjUioAJYpwhut6V2v3CgZCji6linIpFYASRTjDA32bkEhD9Jx7VmuPyjPnnGCHMAAlhnCG6wYNaweCgy6lau1KKBQwVNFzL2eJ65wBlC7CGe7rW64tKdNzTudZEFZX3ncvZ4nV2gBKF+EM1+XezVmSgkZo8CYkA+7lLHFXKgCli3CG6/oWhOUMaw+ac7YLZ3rOAEqLq+G8YcMGLViwwM1TYETIvyCsN7R77+VcWxbu9youpQJQqkLDP+XIPPDAA3r88cdVXl7u1ikwQmT31u4RDGQ+dqaVVtAI5b2MSmJYG0Dpcq3nfMIJJ+jee+916+0xkuRs3ylles5S380v8t30QpJCAUOGwaVUAEqPaz3nc889V7t27fpAr2lsbHSpGu/EYrFCl+A7HelmSVJT0/s6NjxWba2HJUmvr48pZES1cX+XJCne1jKo/SIBQwdb20qqXUvp//VI0Ub2aB97I6F9XAvnI1FfX69oNFroMo5YLBZTQ0NDocvwnfdbt2v7m3/UcROOk7lfGj16jNr279asU+pVEanRgS17JO3QR048Xg0Ns/q9tuzRbQpFy0umXfkMDY82skf72PNL+8TjcdsOKau14bp823dKOcPaeW560SsaCjLnDKDkEM7wwODV2pKyl1P13cs5POiV0VCAS6kAlBxXw3nSpElas2aNm6fACDBw+85gIBPOaTOzS1hrV/4FYRI9ZwCliZ4zXGfl2b5TUnYLz0Pd+S+lkug5AyhNhDM809tzDgUzIZxOZ3rMQ13nLPX0nNP0nAGUFsIZrhu4fWcokAnhpJkJ5eycc1meOedgkJ4zgJJDOMMD/ReEhXt6zql0JpQPdma+j64YfBldNBRQMm3KNK1BvwOAYkU4w3V9C8IyQsFMCCfTcUnSoa64oqGAysPBQa+N9GzhyS5hAEoJ4QzXDTWsneqZcz7YmdCo8mi/ezn3igS5+QWA0kM4w3WWlen1Gkbm45Yd1jYzPeeWzoRGVwxeDCZxZyoApYlwhut6h7UDPeEcyplzNk1LLV2JvPPNEvd0BlCaCGe4zhzQc+4N52Q6ocPxpEzLynsZlZTTc+ZyKgAlhHCG6/qGtXtXa/cuCOvWwc7M0PbQw9r0nAGUHsIZrsuGc8/HrTxcLUnqSrSrpeca51HMOQNAlq9uGYniNHDOORyMKhSIqDPRJtlc4yxlNiGR6DkDKC2EM1zXf7W2KcMwVBGpUWeiTe1WtyRpTOVwC8LoOQMoHQxrw3XmgDlnSaqM1qk72a69hw9LkiZUl+d9bVk48xHtJpwBlBDCGa7r3YTEyPm4VZeNliQdbN8vSTq2Jn84V0cz+20fjqfcLBEAfIVwhussZXrOvXPOklRdngnnjsRBSUP3nKt6w7k76WaJAOArhDNcN/BSKkmqLhsjSUqlWiVJxwwRzjVlvT1nwhlA6SCc4brssLYxeFg7bbbpmOoyleW56YWUO6xNOAMoHYQzXDdwhzBJqojUSpKCRqc+Mq5myNdWRzMXFDCsDaCUEM5wXXbOOefjVhaukBRQXVlKp04cPeRra8oym5O00XMGUEK4zhmuyzfnbBgBdSQiqitPan79SUO+lp4zgFJEzxmuyzesva25TXsOG6orS+vkY2uHfG3vgjB6zgBKCeEM15lm5hrlUCCcPfbAK9t0qCusgGGpO9E+5GurImEFDEOHerb5BIBSwLA2XJfuCedAoO/j9ruNu/TJ4zLzyZ2JVlVEBy8Ks0xTZkuLZicOqHbjuzr42y6lDuyX2X5YZldX5qu7S2Z3XOpZEa6eofPeIXQjEpZRVqZAtEyBsjIZPd8zX+UK1tYoWFOrYG2dgrW1CtXWySgr6zcEDwBeI5zhut5wDvaE87stHdra3Ka/mzFasprV9vZbCu5ep+5tWxTfuVPxd3Yo8c5Oxd/ZKSuR0H097/OX//KmXiMcVrC2TqExYxUeP17h8ccoNP6Y7M/hY47pOzZ2nAJlZd4UBqBkEM5wXdrMzBcb3UlZm95S7Le/1w1r/6jz1japYsfbOtB5jw4MeE1ozFhVzDpF4eMm6Q/743qjO6ib5p2lqgnHKFhVrUB5pucbKC+XES2TEQz29Z57vluWJSuZkNndLSselxnvltUdl9ndLTPeLbOzU+nDbUq3HlL6UKvSba1KtR7KPk4271X3lk3D/v8Fa2oUGjde4XHjFBo7XuFx4xUaN67n+3iFx45VsKZGweoaBaqrM98rKuidAxgS4YyjzrIsJZv2qPPNDep88w2FXvydTtq8TVt2/6tkmpokab4kKxBQYmKdOj55rI79q8/omE+cqYqpMxSdfKKC1dXZ9/vXR17R/315m7556QU6ccIoT/9fzERCqf3NSu7bq+S+vUrt25f9OblvX+Z3zc1KNe9T+84dUtrhDToCAQWrqxWoqs78sVFZqWBlpcxUSm9POE7BykoFKqsUqKxQsKKy5/dVClRWKlBRmTleWdXzc2XmOVVVmT9WAiwlAUY618LZNE3deuut2rJliyKRiJYvX67Jkye7dToUSKq1VV2bNqprY2PP15vqfKtR6ZaW7HNCkoyKiCpPP0Ptx0zQve2jtOuYE/X7u6/R2vce03sHNuo9SdJrOtY6oL8JT1R1zjnqj61SRTitDXtaNMvjcA5EIoocN1GR4yYO+1zLNJVuaVGyeZ+SzfuUam7OfN/fnOmht7cr3dYms/1w5vHhdqUPtynVvE/pdzpkdWdun9kyzHmGrbmiQoGKSgWrMuGdO68e6plbz3z1PK7rmXOvqe15XKdANP8tPAF4w7Vwfvrpp5VIJPTwww9r/fr1Wrlype6//363ToejzDJNpVtbe3qG+5Tav1/J5n1KvPeu4jt3KL5zu+I7dih1YH//FxqGotNOUs2ZZ6t81imqmPVxvRxYp4O1SX31b5Zr+SPP6P+9vEdXnj5d4apqnfPRBdp/eJc27nlBO5o36P3W7frtuh/oEyd8TidPnKOUmdSo0JP6/rktev3difpqw9TCNIgDRiCg0JgxCo0Zo/KZH/3Ar7fSacVeXKtTZsyQ2dEhs7ND6Y4OmR3tMjs6le7s6Dve3i6zs0NmR+eA53Uo3dmZfV6iabfSWzY579H3/r+UlWUCvbJSgbLyzKK6ni+jZzFd76K6zIK7iIxQWEYoJCMc7vsa6lg4LCMU7P84+/uQFAhmXhcMSsG+n41gSNahQ0q1tGSel/M7BQJMFaBouBbOsVhMZ555piTp1FNPVWNjo1unGqT12afV/OCPM3OPvfOQUr+frbzH8z932Nf1fDdbW7W1psb+dUO8b76f89f4IV6X5//PsixZiaTMzsw/8tnvXV2yY0Qiik6eosrZDSr7yEyVnzxL5rSJ2lKxRweDlt7a26JEOiVDmzW+skut3RX65P95QrFdBxUNBXTdnI9k32ts9SR9+iOX6RMnzNWug5v1xq5n9dqO/9aug5vUnexQInVAFWHp+KrndMeTjQrk/AMcMAx9fOIEzf3YvOyCs5HKCAZlVFYpcuyEo/q+lmVlQpvkyuYAAAfeSURBVLv1kFKHDind1pqZV29t7f/4UM+ce87v052dSre2Zubou7ok0zyqtR2pdUP9IhjsCfGglBPo2eO9QR4KyQhkAr3XoGDPfezgZ+MDPr//ax2cN8/vDMPoOWZkH5sdHdpcXZ05nvucnK9hj2mI5xUBs6VFb486shG4URd8QWO+fPlRrig/1/41a29vV1VVVfZxMBhUKpVSKDT0KY9WgJv/9XPpN48clff6oFoLctY8nPzj0CsclsrKpbIyqapKGjs287iiUho9WqobJaNulFRXJ40/RjpuojR2nBKBgBKSDve8zaHUu3qvPbOAalTOAuaUaei/N9do3e6Dqh9Trpv+6ljF92xXbE++wst1fGCOdhrPq6n1L5KkisAYHews16jyXRqlvYNe0dSyV6+9fpzCRv47W400sVjM3RNEyqRxx2a+PgDDsqRUSkrEpXhcSiQy3+NxKZXM9M5TqcxXuvd7zrHex+kBj1MpWemUlMr5nWlKaTPzezPd893s+znv70wpnZKVNmX1Hhv4nGRS6u7u+12+P8ylAX/0DnHcwR/z/d/2Qzw/32ty/+Af0BE5LNg50qmjln17tfOkjwz/xKPAtXCuqqpSR0dH9rFpmrbBLEn19fWKHoW5LuvHP1Nq5T19B470r9sP8jrD0Lp16/SJT3xi+Ncd6V/hTp5bUA1KpP5Olkx1J0wlTSkaCiscDGrhnKACAUOxWEwNDQ3DvtOnrE8rke5WwAgpHMxcD92V6NKhrk6l0n3/CEVCAY2urMo+Z6Rz2j6ljDay9+c//1kNs2dnA9vKDe8Pc6xIbHhjgz5+yseP6LWhsWOP2oLLeDxu2yF1LZxnz56tZ599Vueff77Wr1+vGTNmuHWqQQzDUHjcOM/Olz1vebmClZWen9dPIqFMlzn6IT9ZhhFQNFTR71h5pFzlkeLoHQNuMQyjX4D45U93vzBGjVZ4/PhClzEs18J57ty5evHFF3XppZfKsizdeeedbp0KAICi4lo4BwIB3XbbbW69PQAARYvdCgAA8BnCGQAAnyGcAQDwGcIZAACfIZwBAPAZwhkAAJ8hnAEA8BnCGQAAn/HFbXx676KUSCQKXMmHF4/HC12C79FG9mif4dFG9mgfe35on968s4bYt9ywhvqNhw4fPqytW7cWugwAADw1Y8YMVVdXDzrui3A2TVMdHR0Kh8M+usMSAADusCxLyWRSlZWVCuS505UvwhkAAPRhQRgAAD5DOAMA4DOEMwAAPkM4AwDgM764zrlYWJals846SyeeeKIk6dRTT9UNN9xQ2KJ8wDRN3XrrrdqyZYsikYiWL1+uyZMnF7os37nooouyl1RMmjRJK1asKHBF/rBhwwbdfffdWr16td555x3dfPPNMgxD06dP17/8y7/kXelaanLbaOPGjfrmN7+Z/Xfosssu0/nnn1/YAgskmUxqyZIl2r17txKJhK6++mqddNJJI+IzRDgfRe+++65OPvlkrVq1qtCl+MrTTz+tRCKhhx9+WOvXr9fKlSt1//33F7osX+ndFGH16tUFrsRfHnjgAT3++OMqLy+XJK1YsUKLFy/WX//1X2vZsmV65plnNHfu3AJXWVgD2+itt97S1772NS1cuLDAlRXe448/rrq6Ot11111qaWnRxRdfrJkzZ46Iz5D//lwYwTZu3Ki9e/dqwYIFuvLKK7V9+/ZCl+QLsVhMZ555pqTMaEJjY2OBK/KfzZs3q6urSwsXLtQVV1yh9evXF7okXzjhhBN07733Zh9v3LhRn/zkJyVJZ511ll566aVCleYbA9uosbFRf/zjH/WVr3xFS5YsUXt7ewGrK6zzzjtP119/ffZxMBgcMZ8hwvkI/epXv9IFF1zQ72vs2LG66qqrtHr1an3jG9/QTTfdVOgyfaG9vV1VVVXZx8FgUKlUqoAV+U9ZWZm+/vWv6z//8z/1ve99TzfeeCNtJOncc89VKNQ3wGdZVnajosrKSh0+fLhQpfnGwDY65ZRT9O1vf1sPPfSQjj/+eP37v/97AasrrMrKSlVVVam9vV2LFi3S4sWLR8xniGHtIzR//nzNnz+/37Guri4Fg0FJ0mmnnaa9e/f2+yCUqqqqKnV0dGQfm6bZ7x8TSFOmTNHkyZNlGIamTJmiuro6NTc3a8KECYUuzVdy5wY7OjpUU1NTwGr8ae7cudl2mTt3rm6//fYCV1RYTU1Nuvbaa3X55Zfr85//vO66667s7/z8GaLnfBTdd999+tnPfiYpM0x53HHHlXwwS9Ls2bP1/PPPS5LWr1+vGTNmFLgi/3nkkUe0cuVKSdLevXvV3t6ucePGFbgq//nYxz6mV199VZL0/PPP67TTTitwRf7z9a9/XW+88YYk6eWXX9bJJ59c4IoKZ//+/Vq4cKFuuukmXXLJJZJGzmeI7TuPotbWVt10003q7OxUMBjUsmXLNG3atEKXVXC9q7W3bt0qy7J055130i4DJBIJ3XLLLdqzZ48Mw9CNN96o2bNnF7osX9i1a5e+9a1vac2aNdqxY4f++Z//WclkUlOnTtXy5cuzo1WlLLeNNm7cqNtvv13hcFhjx47V7bff3m9aqZQsX75cTz75pKZOnZo99t3vflfLly/3/WeIcAYAwGcY1gYAwGcIZwAAfIZwBgDAZwhnAAB8hnAGAMBnCGcAAHyGcAYAwGcIZwAAfOb/A3Erqp6YXR5AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sentence2vec(row):\n",
    "    return row['processed_1'].similarity(row['processed_2'])\n",
    "\n",
    "    \n",
    "def first_word_same(row):\n",
    "    return row['def1'].split(' ')[0].lower() == row['def2'].split(' ')[0].lower()\n",
    "\n",
    "def difference_in_length(row):\n",
    "    return abs(len(row['def1'].split(' ')) - len(row['def2'].split(' ')[0]))\n",
    "\n",
    "def jaccard_sim(row):\n",
    "    return get_jaccard_sim(row['def1'], row['def2'])\n",
    "\n",
    "\n",
    "def cosine(row):\n",
    "    return get_cosine_sim(row['def1'], row['def2'])[0, 1]\n",
    "\n",
    "def get_jaccard_sim(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def pos_count(column):\n",
    "    pos = []\n",
    "    \n",
    "    for token in column:\n",
    "        pos.append(token.pos)\n",
    "    return list(set(pos))\n",
    "        \n",
    "    \n",
    "def diff_pos_count(row):\n",
    "    pos_def1 = pos_count(row['processed_1'])\n",
    "    pos_def1 = pos_count(row['processed_2'])\n",
    "    \n",
    "    return  len(pos_def1) - len(pos_def1)\n",
    "    \n",
    "\n",
    "\n",
    "features = pd.DataFrame()\n",
    "\n",
    "similarities = []\n",
    "first_word = []\n",
    "length = []\n",
    "\n",
    "features['similarities'] = en_data.apply(lambda row: sentence2vec(row), axis = 1)\n",
    "features['first_word_same'] = en_data.apply(lambda row: first_word_same(row), axis=1)\n",
    "features['len_diff'] = en_data.apply(lambda row: difference_in_length(row), axis=1)\n",
    "features['jaccard'] = en_data.apply(lambda row: jaccard_sim(row), axis=1)\n",
    "features['pos_diff'] = en_data.apply(lambda row: diff_pos_count(row), axis=1)\n",
    "print(features)\n",
    "#features['len_diff'].plot(kind = 'hist')\n",
    "features['similarities'].plot.kde()\n",
    "features['jaccard'].plot.kde()\n",
    "features['len_diff'].plot.kde()\n",
    "features['pos_diff'].plot.kde()\n",
    "#for i, row in en_data.iterrows():\n",
    "#    similarities.append(sentence2Vec(row))\n",
    "#    first_word.append(first_word_same(row))\n",
    "#    length.append(difference_in_length(row)) \n",
    "\n",
    "#features['similarities'] = similarities\n",
    "#features['first_word_same'] = first_word\n",
    "#features['length'] = length\n",
    "#Add Token Count using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#none = features[is_none(features)==True]\n",
    "\n",
    "#label_count = en_data.groupby('relation').count().word.sort_values(ascending=False)\n",
    "#second_biggest = label_count[1]\n",
    "#to_drop = none.index[second_biggest:]\n",
    "\n",
    "#balanced = features.drop(to_drop) \n",
    "#balanced\n",
    "#label_count = balanced.groupby('relation').count().similarities.sort_values(ascending=False)\n",
    "\n",
    "#label_count.plot(kind = 'bar')\n",
    "#label_count[1]\n",
    "#second_biggest\n",
    "#label_count.plot(kind = 'bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarities</th>\n",
       "      <th>first_word_same</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.856918</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.776428</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.732969</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.836521</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.689816</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>0.615553</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>0.915048</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>0.822070</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>0.850948</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>0.934649</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarities  first_word_same  len_diff   jaccard\n",
       "0    0.856918      True             2         0.250000\n",
       "1    0.776428      False            3         0.000000\n",
       "2    0.732969      False            3         0.000000\n",
       "3    0.836521      False            1         0.285714\n",
       "4    0.689816      False            2         0.000000\n",
       "..        ...        ...           ..              ...\n",
       "551  0.615553      False            6         0.000000\n",
       "552  0.915048      True             0         0.600000\n",
       "553  0.822070      True             0         0.400000\n",
       "554  0.850948      False            1         0.181818\n",
       "555  0.934649      False            5         0.500000\n",
       "\n",
       "[556 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#en_data['similarities'] = similarities\n",
    "labels = en_data['relation']\n",
    "features = features.drop(['relation'], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarities</th>\n",
       "      <th>first_word_same</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.689137</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.765570</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.800568</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.756537</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.863854</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.710593</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>0.566016</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.736717</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>0.850948</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.616458</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similarities  first_word_same  len_diff   jaccard\n",
       "69   0.689137      False            1         0.000000\n",
       "253  0.765570      False            9         0.058824\n",
       "139  0.800568      False            4         0.000000\n",
       "286  0.756537      False            2         0.000000\n",
       "221  0.863854      False            9         0.000000\n",
       "..        ...        ...           ..              ...\n",
       "346  0.710593      False            4         0.000000\n",
       "443  0.566016      False            0         0.000000\n",
       "295  0.736717      False            2         0.100000\n",
       "554  0.850948      False            1         0.181818\n",
       "208  0.616458      False            3         0.000000\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2)\n",
    "X_train_scaled = X_train.copy(deep = True)\n",
    "X_test_scaled = X_test.copy(deep = True)\n",
    "\n",
    "X_train_scaled['similarities'] = preprocessing.scale(X_train['similarities'])\n",
    "X_train_scaled['len_diff'] = preprocessing.scale(X_train['len_diff'])\n",
    "X_train_scaled['jaccard'] = preprocessing.scale(X_train['jaccard'])\n",
    "#X_train_scaled['length'] = preprocessing.scale(X_train['length'])\n",
    "#X_test_scaled['similarities'] = preprocessing.scale(X_test['similarities'])\n",
    "#X_test_scaled['length'] = preprocessing.scale(X_test['length'])\n",
    "#features['similarities'].plot.kde()\n",
    "#X_train_scaled['similarities'].plot.kde()\n",
    "X_train_scaled['jaccard'].plot.kde()\n",
    "#X_train_scaled['len_diff'].plot.kde()\n",
    "\n",
    "X_train_set = {}\n",
    "X_train_set['unscaled'] = X_train\n",
    "X_train_set['scaled'] = X_train_scaled\n",
    "\n",
    "X_test_set = {}\n",
    "X_test_set['unscaled'] = X_test\n",
    "X_test_set['scaled'] = X_test_scaled\n",
    "\n",
    "X_test_set['unscaled']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline:  0.7857142857142857\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelLogisticRegression\n",
      "Accuracy: 0.8224 (+/- 0.0373)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelLinearSVC\n",
      "Accuracy: 0.8157 (+/- 0.0440)\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "Accuracy: 0.8133 (+/- 0.0611)\n",
      "Cross validation scores for modelLogisticRegression\n",
      "Accuracy: 0.8156 (+/- 0.0381)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\syim\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores for modelLinearSVC\n",
      "Accuracy: 0.8179 (+/- 0.0419)\n",
      "Cross validation scores for modelRandomForestClassifier\n",
      "Accuracy: 0.8133 (+/- 0.0611)\n",
      "Model Evaluation on Testset: \n",
      "\n",
      "\tBASELINE: 0.7857142857142857\n",
      "\n",
      "\tLogisticRegression\n",
      "\t\tAccuracy: 0.7857 (+/- 0.0000)\n",
      "\n",
      "\tLinearSVC\n",
      "\t\tAccuracy: 0.7768 (+/- 0.0000)\n",
      "\n",
      "\tRandomForestClassifier\n",
      "\t\tAccuracy: 0.7857 (+/- 0.0000)\n",
      "\n",
      "\tLogisticRegression\n",
      "\t\tAccuracy for scaled featureset: 0.7857 (+/- 0.0000)\n",
      "\n",
      "\tLinearSVC\n",
      "\t\tAccuracy for scaled featureset: 0.7857 (+/- 0.0000)\n",
      "\n",
      "\tRandomForestClassifier\n",
      "\t\tAccuracy for scaled featureset: 0.7857 (+/- 0.0000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_baseline(test_set):\n",
    "    TP = 0\n",
    "    for index in test_set.index:\n",
    "        if test_set[index]=='none':\n",
    "            TP+=1\n",
    "\n",
    "    return float(TP/len(test_set))\n",
    "\n",
    "\n",
    "def run_cv_with_dataset(model, trainset, y_train):\n",
    "    scores = cross_val_score(model, trainset, y_train, cv = 5)        \n",
    "    print('Cross validation scores for model' + model.__class__.__name__)\n",
    "    #scores\n",
    "    print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "def cross_val_models(models, all_training_set, y_train):\n",
    "    for estimator in models['unscaled']:\n",
    "        run_cv_with_dataset(estimator, all_training_set['unscaled'], y_train)\n",
    "    \n",
    "    for estimator in models['scaled']:\n",
    "        run_cv_with_dataset(estimator, all_training_set['scaled'], y_train)\n",
    "\n",
    "def compare_on_testset(models, testset_x, testset_y, testset_x_scaled):\n",
    "    print('Model Evaluation on Testset: ' + '\\n')\n",
    "    print('\\t' + 'BASELINE: ' + str(get_baseline(testset_y)) + '\\n')\n",
    "    \n",
    "    for estimator in models['unscaled']:\n",
    "        estimator.predict(testset_x)\n",
    "        print('\\t' + estimator.__class__.__name__)\n",
    "        score = estimator.score(testset_x, testset_y)\n",
    "        print('\\t\\t' + \"Accuracy: %0.4f (+/- %0.4f)\" % (score.mean(), score.std() * 2) + '\\n')\n",
    "    \n",
    "    for estimator in models['scaled']:\n",
    "        estimator.predict(testset_x_scaled)\n",
    "        print('\\t' + estimator.__class__.__name__)\n",
    "        score = estimator.score(testset_x_scaled, testset_y)\n",
    "        print('\\t\\t' + \"Accuracy for scaled featureset: %0.4f (+/- %0.4f)\" % (score.mean(), score.std() * 2) + '\\n')\n",
    "\n",
    "def train_models(X_train, y_train, X_train_scaled):\n",
    "    print('baseline: ', str(get_baseline(y_test)) + '\\n')\n",
    "\n",
    "    LR = LogisticRegression( solver = 'lbfgs', multi_class = 'multinomial').fit(X_train, y_train)\n",
    "    LR_scaled = LogisticRegression( solver = 'lbfgs', multi_class = 'multinomial').fit(X_train_scaled, y_train)\n",
    "\n",
    "    ## Linear kernal won't work very well, experiment with nonlinear ones.\n",
    "    SVM = svm.LinearSVC(C=10.0).fit(X_train, y_train)\n",
    "    SVM_scaled = svm.LinearSVC().fit(X_train_scaled, y_train)\n",
    "\n",
    "    RF = RandomForestClassifier(max_depth = 5, random_state=0).fit(X_train, y_train)\n",
    "    RF_scaled = RandomForestClassifier(max_depth = 5, random_state=0).fit(X_train_scaled, y_train)\n",
    "    \n",
    "    models = {}\n",
    "    models['unscaled'] = [LR, SVM, RF]\n",
    "    models['scaled'] = [LR_scaled, SVM_scaled, RF_scaled]\n",
    "    \n",
    "    return models\n",
    "\n",
    "models = train_models(X_train, y_train, X_train_scaled)\n",
    "cross_val_models(models, X_train_set, y_train)\n",
    "#print(models)\n",
    "compare_on_testset(models, X_test, y_test, X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp_en = English()\n",
    "nlp_en.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\n",
    "        \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"}\n",
    "    )\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")\n",
    "    \n",
    "textcat.add_label('related')\n",
    "textcat.add_label('exact')\n",
    "textcat.add_label('broader')\n",
    "textcat.add_label('narrower')\n",
    "textcat.add_label('none')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "## Experiment with NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(doc):\n",
    "        # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "    # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc\n",
    "\n",
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "#nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "#nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}